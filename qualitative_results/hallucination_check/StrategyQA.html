
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Hallucination Detection Results</title>
        
    <style>
        :root {
            --bg-primary: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text-primary: #c9d1d9;
            --text-secondary: #8b949e;
            --border-color: #30363d;
            --accent-blue: #58a6ff;
            --accent-green: #3fb950;
            --accent-red: #f85149;
            --accent-yellow: #d29922;
            --accent-purple: #a371f7;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.6;
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            background: linear-gradient(135deg, var(--accent-blue), var(--accent-purple));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        h2 {
            font-size: 1.8em;
            margin: 30px 0 20px 0;
            color: var(--text-primary);
            border-bottom: 2px solid var(--accent-blue);
            padding-bottom: 10px;
        }
        
        h3 {
            font-size: 1.3em;
            margin: 20px 0 15px 0;
            color: var(--accent-blue);
        }
        
        .subtitle {
            color: var(--text-secondary);
            margin-bottom: 30px;
        }
        
        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .summary-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 20px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .summary-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.3);
        }
        
        .summary-card h4 {
            color: var(--text-secondary);
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 10px;
        }
        
        .summary-card .value {
            font-size: 2.5em;
            font-weight: bold;
            color: var(--accent-blue);
        }
        
        .summary-card .subtitle {
            font-size: 0.85em;
            color: var(--text-secondary);
            margin-top: 5px;
        }
        
        .dataset-section {
            background: var(--bg-secondary);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            margin-bottom: 30px;
            overflow: hidden;
        }
        
        .dataset-header {
            background: var(--bg-tertiary);
            padding: 20px;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .dataset-header:hover {
            background: #2d333b;
        }
        
        .dataset-title {
            font-size: 1.4em;
            color: var(--text-primary);
        }
        
        .dataset-stats {
            display: flex;
            gap: 20px;
        }
        
        .stat-badge {
            background: var(--bg-primary);
            padding: 8px 15px;
            border-radius: 20px;
            font-size: 0.9em;
        }
        
        .stat-badge.error {
            border: 1px solid var(--accent-red);
            color: var(--accent-red);
        }
        
        .stat-badge.success {
            border: 1px solid var(--accent-green);
            color: var(--accent-green);
        }
        
        .dataset-content {
            padding: 20px;
            display: none;
        }
        
        .dataset-content.active {
            display: block;
        }
        
        .mode-tabs {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }
        
        .mode-tab {
            padding: 10px 20px;
            background: var(--bg-tertiary);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            cursor: pointer;
            color: var(--text-secondary);
            transition: all 0.2s;
        }
        
        .mode-tab:hover, .mode-tab.active {
            background: var(--accent-blue);
            color: white;
            border-color: var(--accent-blue);
        }
        
        .type-distribution {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 15px 0;
        }
        
        .type-badge {
            padding: 6px 12px;
            border-radius: 15px;
            font-size: 0.85em;
            font-weight: 500;
        }
        
        .question-list {
            max-height: 600px;
            overflow-y: auto;
        }
        
        .question-item {
            background: var(--bg-primary);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            margin-bottom: 15px;
            overflow: hidden;
        }
        
        .question-header {
            padding: 15px;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            gap: 15px;
        }
        
        .question-header:hover {
            background: var(--bg-tertiary);
        }
        
        .question-text {
            flex: 1;
            font-size: 0.95em;
        }
        
        .question-id {
            color: var(--text-secondary);
            font-size: 0.8em;
            margin-bottom: 5px;
        }
        
        .hallucination-count {
            background: var(--accent-red);
            color: white;
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.85em;
            font-weight: bold;
            white-space: nowrap;
        }
        
        .hallucination-count.none {
            background: var(--accent-green);
        }
        
        .question-details {
            display: none;
            padding: 15px;
            border-top: 1px solid var(--border-color);
            background: var(--bg-tertiary);
        }
        
        .question-details.active {
            display: block;
        }
        
        .detail-section {
            margin-bottom: 20px;
        }
        
        .detail-label {
            font-weight: bold;
            color: var(--accent-blue);
            margin-bottom: 8px;
            font-size: 0.9em;
            text-transform: uppercase;
        }
        
        .detail-content {
            background: var(--bg-primary);
            padding: 12px;
            border-radius: 6px;
            font-size: 0.9em;
            white-space: pre-wrap;
            word-break: break-word;
        }
        
        .hallucination-item {
            background: var(--bg-primary);
            border-left: 4px solid var(--accent-red);
            padding: 15px;
            margin-bottom: 10px;
            border-radius: 0 8px 8px 0;
        }
        
        .hallucination-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }
        
        .hallucination-type {
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.8em;
            font-weight: bold;
            color: white;
        }
        
        .severity-badge {
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.75em;
            font-weight: bold;
            color: white;
        }
        
        .span-highlight {
            background: rgba(248, 81, 73, 0.2);
            border: 1px solid var(--accent-red);
            padding: 8px;
            border-radius: 4px;
            margin: 5px 0;
            font-family: monospace;
            font-size: 0.85em;
        }
        
        .span-label {
            font-size: 0.75em;
            color: var(--text-secondary);
            margin-bottom: 3px;
        }
        
        .toggle-icon {
            transition: transform 0.2s;
        }
        
        .toggle-icon.rotated {
            transform: rotate(180deg);
        }
        
        .filter-bar {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }
        
        .filter-input {
            background: var(--bg-primary);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 10px 15px;
            color: var(--text-primary);
            font-size: 0.9em;
            min-width: 200px;
        }
        
        .filter-input:focus {
            outline: none;
            border-color: var(--accent-blue);
        }
        
        .filter-select {
            background: var(--bg-primary);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 10px 15px;
            color: var(--text-primary);
            font-size: 0.9em;
        }
        
        .nav-links {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }
        
        .nav-link {
            color: var(--accent-blue);
            text-decoration: none;
            padding: 8px 15px;
            border: 1px solid var(--accent-blue);
            border-radius: 20px;
            font-size: 0.9em;
            transition: all 0.2s;
        }
        
        .nav-link:hover {
            background: var(--accent-blue);
            color: white;
        }
        
        .quality-bar {
            display: flex;
            height: 8px;
            border-radius: 4px;
            overflow: hidden;
            margin-top: 10px;
        }
        
        .quality-segment {
            transition: width 0.3s;
        }
        
        @media (max-width: 768px) {
            .summary-grid {
                grid-template-columns: 1fr;
            }
            
            .dataset-stats {
                flex-direction: column;
                gap: 10px;
            }
            
            .filter-bar {
                flex-direction: column;
            }
            
            .filter-input, .filter-select {
                width: 100%;
            }
        }
    </style>
    
    </head>
    <body>
        <div class="container">
            <h1>üîç Hallucination Detection Results</h1>
            <p class="subtitle">Generated on 2025-12-06 22:30:34</p>
            
            <div class="summary-grid">
                <div class="summary-card">
                    <h4>Datasets Analyzed</h4>
                    <div class="value">1</div>
                </div>
                <div class="summary-card">
                    <h4>Total Questions</h4>
                    <div class="value">400</div>
                </div>
                <div class="summary-card">
                    <h4>Total Issues Found</h4>
                    <div class="value" style="color: var(--accent-red)">141</div>
                </div>
                <div class="summary-card">
                    <h4>Avg Issues/Question</h4>
                    <div class="value" style="color: var(--accent-yellow)">0.35</div>
                </div>
            </div>
            
            <h2>Quick Navigation</h2>
            <div class="nav-links">
                <a class="nav-link" href="#" onclick="toggleDataset('dataset-0'); return false;">StrategyQA</a>
            </div>
            
            <h2>Dataset Results</h2>
            
    <div class="dataset-section">
        <div class="dataset-header" onclick="toggleDataset('dataset-0')">
            <div>
                <div class="dataset-title">StrategyQA</div>
                <div style="color: var(--text-secondary); font-size: 0.85em; margin-top: 5px;">
                    Judge Type: with_gt_explanation | Modes: cot, hot
                </div>
            </div>
            <div class="dataset-stats">
                <span class="stat-badge">400 questions</span>
                <span class="stat-badge error">136 with issues</span>
                <span class="toggle-icon" id="icon-dataset-0">‚ñº</span>
            </div>
        </div>
        <div class="dataset-content" id="content-dataset-0">
            <div class="mode-tabs" id="tabs-dataset-0">
                
        <div class="mode-tab" data-mode="cot" onclick="switchMode('dataset-0', 'cot')">COT</div>
        
        <div class="mode-tab" data-mode="hot" onclick="switchMode('dataset-0', 'hot')">HOT</div>
        
            </div>
            
    <div class="mode-content" id="mode-dataset-0-cot" style="display: none;">
        <div class="summary-grid">
            <div class="summary-card">
                <h4>Questions Analyzed</h4>
                <div class="value">200</div>
            </div>
            <div class="summary-card">
                <h4>With Issues</h4>
                <div class="value" style="color: var(--accent-red)">68</div>
                <div class="subtitle">34.0% of questions</div>
            </div>
            <div class="summary-card">
                <h4>Total Issues Found</h4>
                <div class="value" style="color: var(--accent-yellow)">72</div>
                <div class="subtitle">0.36 per question</div>
            </div>
        </div>
        
        <h3>Issue Type Distribution</h3>
        <div class="type-distribution">
            <span class="type-badge" style="background: #e74c3c">contradiction: 45</span><span class="type-badge" style="background: #3498db">logical_error: 18</span><span class="type-badge" style="background: #9b59b6">entity_swap: 9</span>
        </div>
        
        <h3>Question Analysis</h3>
        <div class="filter-bar">
            <input type="text" class="filter-input" id="search-dataset-0-cot" 
                   placeholder="Search questions..." oninput="filterQuestions('dataset-0', 'cot')">
            <select class="filter-select" id="type-dataset-0-cot" onchange="filterQuestions('dataset-0', 'cot')">
                <option value="">All Types</option>
                <option value="contradiction">contradiction</option><option value="logical_error">logical_error</option><option value="entity_swap">entity_swap</option>
            </select>
        </div>
        
        <div class="question-list">
            
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-0')">
            <div class="question-text">
                <div class="question-id">Question #0</div>
                Is it common to see frost during some college commencements?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-0">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it common to see frost during some college commencements?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. College commencement ceremonies often happen during the months of December, May, and sometimes June.  Frost isn't uncommon to see during the month of December, as it is the winter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: College commencements typically occur in the late spring or early summer (May/June). Frost is a weather phenomenon associated with temperatures at or below freezing (0¬∞C or 32¬∞F).  Late spring/early summer is generally well after the last frost in most regions, particularly those where colleges and universities are located.  While unusual weather can occasionally happen, frost is not common during the typical commencement season.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contradicts the reference explanation by omitting December as a month when college commencements occur. This omission leads to the incorrect conclusion that frost is not common during commencement season.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">College commencements typically occur in the late spring or early summer (May/June).</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that college commencement ceremonies often happen during the months of December, May, and sometimes June. The generated reasoning omits December.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">College commencements typically occur in the late spring or early summer (May/June).</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">College commencement ceremonies often happen during the months of December, May, and sometimes June.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-1')">
            <div class="question-text">
                <div class="question-id">Question #1</div>
                Hydrogen's atomic number squared exceeds number of Spice Girls?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-1">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Hydrogen's atomic number squared exceeds number of Spice Girls?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Hydrogen is the first element and has an atomic number of one. To square a number, you multiply it by itself. The Spice Girls has five members.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Hydrogen's atomic number is 1.  1 squared is 1.  There were 5 Spice Girls. 1 is less than 5.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-2')">
            <div class="question-text">
                <div class="question-id">Question #2</div>
                Would a pear sink in water?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-2">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a pear sink in water?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The density of a raw pear is about 0.59 g/cm^3. The density of water is about 1 g/cm^3. Objects only sink if they are denser than the surrounding fluid.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The density of a pear is slightly higher than the density of water.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning states that the density of a pear is higher than water, which is a contradiction of the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The density of a pear is slightly higher than the density of water.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The density of a pear is lower than the density of water, not higher.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">slightly higher than</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">0.59 g/cm^3</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-3')">
            <div class="question-text">
                <div class="question-id">Question #3</div>
                Do hamsters provide food for any animals?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-3">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do hamsters provide food for any animals?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Hamsters are prey animals. Prey animals provide food for predators.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Hamsters are prey animals.  Several animals, including snakes, owls, hawks, and foxes, prey on hamsters.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that hamsters are prey animals and providing examples of predators that eat them.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-4')">
            <div class="question-text">
                <div class="question-id">Question #4</div>
                Are all limbs required for jujutsu?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-4">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are all limbs required for jujutsu?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Jujutsu is a Japanese martial art that uses unarmed combat to subdue opponents. Nick Newell, a congenital amputee, got his black belt after two straight submission wins. Fighter Aaron LaPointe has succeeded in martial arts with a fully paralyzed arm.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Jujutsu is a Japanese martial art.  Many Jujutsu techniques involve grappling and joint manipulation, which can involve the use of limbs. However, adaptive Jujutsu techniques exist for practitioners with disabilities affecting limb use. So, while limbs are typically involved, they are not strictly *required* for all forms of the art.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly infers that limbs are not strictly required for jujutsu, based on the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-5')">
            <div class="question-text">
                <div class="question-id">Question #5</div>
                Could a llama birth twice during War in Vietnam (1945-46)?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-5">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a llama birth twice during War in Vietnam (1945-46)?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The War in Vietnam (1945-46) lasted around 6 months. The gestation period for a llama is 11 months.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Llamas have a gestation period of approximately 11 months.  The Vietnam War lasted from 1955 to 1975, much longer than two llama gestation periods. Therefore, a llama could give birth twice during the Vietnam War.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning hallucinates the dates of the Vietnam War, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Vietnam War lasted from 1955 to 1975, much longer than two llama gestation periods.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that the Vietnam War lasted from 1955 to 1975, but the reference states that the War in Vietnam lasted from 1945-46.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Vietnam War lasted from 1955 to 1975</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The War in Vietnam (1945-46)</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-6')">
            <div class="question-text">
                <div class="question-id">Question #6</div>
                Does Linus Torvalds make money off of DirectX?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-6">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Linus Torvalds make money off of DirectX?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. DirectX is a proprietary technology owned by Microsoft. Linus Torvalds is the creator and lead developer for the open-source Linux kernel. The Linux kernel is used in operating systems that are competitors of Microsoft Windows.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Linus Torvalds created the Linux kernel.  DirectX is a collection of application programming interfaces (APIs) developed by Microsoft for handling tasks related to multimedia, especially game programming and video, on Microsoft platforms.  These are entirely separate entities.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately identifies that Linus Torvalds created the Linux kernel and that DirectX is a Microsoft product, correctly concluding that they are separate entities.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-7')">
            <div class="question-text">
                <div class="question-id">Question #7</div>
                Could Brooke Shields succeed at University of Pennsylvania?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-7">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could Brooke Shields succeed at University of Pennsylvania?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Brooke Shields graduated from Princeton University. Princeton is ranked as the number 1 national college by US news. University of Pennsylvania is ranked as number 6 national college by US news. Princeton only admits around 6 percent of applicants as of 2018. University of Pennsylvania accepts around 9% of applicants as of 2018.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Brooke Shields attended Princeton University and graduated with a Bachelor of Arts in Romance Languages.  Success at one Ivy League institution suggests a likelihood of success at another, assuming similar levels of effort and commitment. University of Pennsylvania is also an Ivy League university, so the academic rigor would be comparable.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly uses the information provided in the reference explanation to support the conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-8')">
            <div class="question-text">
                <div class="question-id">Question #8</div>
                Could a silverfish reach the top of the Empire State Building?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-8">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a silverfish reach the top of the Empire State Building?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Silverfish cannot fly. Animals that cannot fly can only access objects at or near ground level without mechanical assistance. The top of the Empire State Building is 	1,454 ft high.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Silverfish are insects. Insects are capable of climbing. The Empire State Building is a building. Buildings can be climbed.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning makes a generalization about insects being able to climb, which is irrelevant to the specific limitation of silverfish not being able to fly to reach the top of the building.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Insects are capable of climbing.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that silverfish cannot fly and therefore cannot reach the top of the Empire State Building without assistance. The generated reasoning makes a generalization about insects being capable of climbing, which is irrelevant to the specific limitation of silverfish not being able to fly to reach the top of the building.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Insects are capable of climbing.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Silverfish cannot fly.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-9')">
            <div class="question-text">
                <div class="question-id">Question #9</div>
                Are the majority of Reddit users familiar with the Pledge of Allegiance?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-9">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are the majority of Reddit users familiar with the Pledge of Allegiance?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. 55% of the Reddit user base comes from the United States. Congressional sessions open with the recital of the Pledge, as do many government meetings at local levels, and meetings held by many private organizations. All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Reddit is an American social news aggregation, content rating, and discussion website.
The Pledge of Allegiance is recited by Americans.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Reddit is an American website and that the Pledge of Allegiance is recited by Americans. This supports the conclusion that the majority of Reddit users are familiar with the Pledge of Allegiance.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-10')">
            <div class="question-text">
                <div class="question-id">Question #10</div>
                Do the anchors on Rede Globo speak Chinese?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-10">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do the anchors on Rede Globo speak Chinese?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Rede Globo is a Brazilian television network. The official language of Brazil is Portuguese.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Rede Globo is a Brazilian television network.  The primary language of Brazil is Portuguese. Thus, the anchors on Rede Globo would speak Portuguese, not Chinese.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that Rede Globo is a Brazilian television network where the primary language is Portuguese, thus the anchors would speak Portuguese, not Chinese.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-11')">
            <div class="question-text">
                <div class="question-id">Question #11</div>
                Can Reiki be stored in a bottle?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-11">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can Reiki be stored in a bottle?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Reiki practitioners use a technique called palm healing or hands-on healing through which a "universal energy" is said to be transferred through the palms of the practitioner to the patient in order to encourage emotional or physical healing. Medications are typically stored in pill bottles.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reiki is a form of energy healing.  Proponents of Reiki believe it is a universal life force energy that can be channeled by practitioners.  However, the concept of "storing" Reiki, especially in a bottle, is not consistent with the core principles of Reiki practice.  Reiki is considered an active, flowing energy that is channeled, not a substance that can be contained.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation and correctly concludes that Reiki cannot be stored in a bottle.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-12')">
            <div class="question-text">
                <div class="question-id">Question #12</div>
                While viewing "Scary Movie" is the viewer likely to experience an increase in adrenaline?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-12">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">While viewing "Scary Movie" is the viewer likely to experience an increase in adrenaline?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Scary Movie is a film that is a comedy take on horror, intended to make viewers laugh but not afraid. Adrenaline is produced when a human is frightened or excited.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: "Scary Movie" is a parody film designed to elicit laughter, not fear.  While some scenes might contain startling elements, the overall tone is comedic, undermining genuine fear and the associated adrenaline rush. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that "Scary Movie" is a parody film designed to elicit laughter, not fear, and therefore would not cause an adrenaline rush.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-13')">
            <div class="question-text">
                <div class="question-id">Question #13</div>
                Would Marvel's Gateway be envious of the Doctor (Doctor Who)'s TARDIS machine?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-13">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Marvel's Gateway be envious of the Doctor (Doctor Who)'s TARDIS machine?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Doctor (Doctor Who) used the TARDIS, a largely unreliable time traveling machine, to travel through time and space. Gateway is a Marvel comic character linked to the X-Men comics. Gateway has the power to create wormholes that allow him to travel through time and space.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
Gateway's mutant ability allows him to create portals for teleportation.
The Doctor's TARDIS is a time and space machine that is larger on the inside and can travel anywhere in time and space.
Gateway's powers are limited to teleportation within his current timeline, while the TARDIS can traverse both space and time.  Thus, Gateway would likely be envious of the Doctor's superior technology.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly states that Gateway's powers are limited to teleportation within his current timeline, contradicting the reference explanation that he can travel through time and space.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Gateway's powers are limited to teleportation within his current timeline, while the TARDIS can traverse both space and time.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Gateway can travel through time and space, which contradicts the statement that his powers are limited to teleportation within his current timeline.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Gateway's powers are limited to teleportation within his current timeline</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Gateway has the power to create wormholes that allow him to travel through time and space.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-14')">
            <div class="question-text">
                <div class="question-id">Question #14</div>
                Is material from an aloe plant sometimes enclosed in petroleum-derived products?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-14">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is material from an aloe plant sometimes enclosed in petroleum-derived products?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Aloe vera gel is sometimes kept in plastic packaging. Plastic packaging is derived from petroleum.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Aloe vera is often sold in plastic bottles. Plastic is derived from petroleum.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that aloe vera is sold in plastic bottles, which are derived from petroleum. This aligns with the reference's point about aloe vera gel being kept in plastic packaging derived from petroleum.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-15')">
            <div class="question-text">
                <div class="question-id">Question #15</div>
                Could a bee hummingbird balance a scale with a single pea on it?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-15">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a bee hummingbird balance a scale with a single pea on it?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The average pea weighs between 0.1 and 0.36 grams. Female bee hummingbirds on average weigh 2.6 grams, while on average male bee hummingbirds weigh 1.95 grams.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A bee hummingbird weighs about 1.7 grams, or 0.06 ounces. A pea weighs between 0.1 and 0.36 grams, averaging around 0.23 grams.  This means a pea can weigh up to about 1/7th the weight of the bee hummingbird.  It is highly unlikely a hummingbird could balance a scale with something so comparatively heavy.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error about the weight of a bee hummingbird.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A bee hummingbird weighs about 1.7 grams, or 0.06 ounces.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that a bee hummingbird weighs about 1.7 grams, but the reference states that female bee hummingbirds weigh 2.6 grams and male bee hummingbirds weigh 1.95 grams.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">A bee hummingbird weighs about 1.7 grams</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Female bee hummingbirds on average weigh 2.6 grams, while on average male bee hummingbirds weigh 1.95 grams.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-16')">
            <div class="question-text">
                <div class="question-id">Question #16</div>
                Would a broadcast from Spirit make the news in 2020?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-16">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a broadcast from Spirit make the news in 2020?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In 2010, the Spirit rover sent what is recorded as its final transmission. In 2019, another rover made the news with its viral "final words".</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Spirit, the Mars rover, ceased communications in 2010. Any broadcast from it in 2020 would be highly unusual and newsworthy, likely making international headlines.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly infers that a broadcast from Spirit in 2020 would be newsworthy, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-17')">
            <div class="question-text">
                <div class="question-id">Question #17</div>
                Would characters in Harry Potter and the Philosopher's Stone be persecuted as pagans?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-17">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would characters in Harry Potter and the Philosopher's Stone be persecuted as pagans?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Pagans are defined as people that hold beliefs other than those of the major world religions (Christianity, Islam, and Judaism). The characters in Harry Potter and the Philosopher's Stone practice magic. Islam explicitly forbid the practice of magic and has harsh consequences for it. Jezebel in Hebrew scripture was a worshiper of pagan Baal and was thrown from a window for her beliefs. Women accused of being witches were burned alive by Christians during the Salem Witch Trials.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The characters in Harry Potter practice witchcraft.  Witchcraft is considered paganism. Historically, people accused of witchcraft have been persecuted. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that the characters in Harry Potter practice witchcraft, which is considered paganism, and that people accused of witchcraft have historically been persecuted. This aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-18')">
            <div class="question-text">
                <div class="question-id">Question #18</div>
                Can music be used as a weapon?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-18">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can music be used as a weapon?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Music is an art form whose medium is sound. Music can help elevate or subdue emotions. People connect to music through the sound. The military uses loud music to cause psychological disorientation and confusion . The military calls the use of loud disorienting music part of psychological operations.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Music can be used to incite violence, spread propaganda, and inflict psychological distress.  Think of war chants, national anthems used to stir up nationalistic fervor, or even songs with hateful lyrics designed to dehumanize a group of people.  Music has also been used as a form of torture, with loud, repetitive, or jarring music used to break down prisoners' resistance. While music often has positive effects, its power can be misused for harmful purposes.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that music can be used as a weapon, citing examples such as inciting violence, spreading propaganda, and inflicting psychological distress, which aligns with the reference explanation that music can be used to cause psychological disorientation and confusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-19')">
            <div class="question-text">
                <div class="question-id">Question #19</div>
                Can Harry Potter book a flight on Asiana Airlines?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-19">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can Harry Potter book a flight on Asiana Airlines?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Asiana Airlines is the second largest airline in South Korea. Harry Potter is a fictional character.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Asiana Airlines is a South Korean airline.  Harry Potter is a fictional character. Fictional characters cannot book flights.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Harry Potter is a fictional character and therefore cannot book a flight on Asiana Airlines, which aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-20')">
            <div class="question-text">
                <div class="question-id">Question #20</div>
                Karachi was a part of Alexander the Great's success?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-20">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Karachi was a part of Alexander the Great's success?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Karachi is a city in modern day Pakistan. Krokola was an ancient port located in what is now Karachi. Alexander the Great stationed his fleet in Krokola on his way to Babylon. Alexander the Great defeated Darius and conquered Babylon before expanding his empire.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Alexander the Great's empire stretched across parts of modern-day Greece, Egypt, Turkey, Iran, Afghanistan, and Pakistan. Karachi, however, is located in modern-day Pakistan. While Alexander's empire did reach the Indus Valley region (parts of modern-day Pakistan), Karachi wasn't specifically a significant city or part of his main conquests.  His campaign focused on the areas further north and east of Karachi.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference by stating that Karachi wasn't a significant city, while the reference indicates it was a location where Alexander stationed his fleet.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Karachi wasn't specifically a significant city or part of his main conquests.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Alexander the Great stationed his fleet in Krokola, which is now Karachi. This implies that Karachi (Krokola) was a significant location for his fleet, contradicting the statement that it wasn't a significant city or part of his main conquests.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Karachi wasn't specifically a significant city or part of his main conquests.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Alexander the Great stationed his fleet in Krokola on his way to Babylon.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-21')">
            <div class="question-text">
                <div class="question-id">Question #21</div>
                Was Jackson Pollock trained by Leonardo da Vinci?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-21">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Jackson Pollock trained by Leonardo da Vinci?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Leonardo lived during the Italian Renaissance in the 17th century. Jackson Pollock lived during the 20th century.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Jackson Pollock was an influential American painter of the 20th century and a major figure in the abstract expressionist movement. Leonardo da Vinci was an Italian polymath of the High Renaissance who died in 1519.  Given the vastly different time periods, da Vinci could not have trained Pollock.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning is correct, but it contains a factual error about the time period in which Leonardo da Vinci lived.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Leonardo lived during the Italian Renaissance in the 17th century.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Leonardo lived in the 15th/16th century, not the 17th century.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">17th century</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">17th century</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-22')">
            <div class="question-text">
                <div class="question-id">Question #22</div>
                Will The Exorcist stimulate limbic system?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-22">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will The Exorcist stimulate limbic system?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The limbic system of the brain contains regions that detect fear, control bodily functions and perceive sensory information. The Exorcist has been called one of the scariest movies of all time. The Exorcist ranked number 3 on the American Film Institute's 100 Years/100 Thrills list.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The limbic system is responsible for emotions, motivation, and memory formation.  Horror movies like The Exorcist are designed to evoke strong emotional responses, particularly fear and anxiety. These emotional responses are mediated by the limbic system. Therefore, watching The Exorcist would likely stimulate the limbic system.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why The Exorcist would stimulate the limbic system, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-23')">
            <div class="question-text">
                <div class="question-id">Question #23</div>
                Would World War II have been the same without Alan Turing?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-23">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would World War II have been the same without Alan Turing?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. During WW2, the German Military used something called the Engima device to send messages secretly.  Alan Turing broke the Enigma code, allowing German messages to be understood and intercepted.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Alan Turing was a British mathematician and computer scientist. He is widely considered to be the father of theoretical computer science and artificial intelligence. During World War II, Turing worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre. He played a crucial role in cracking the German Enigma code, which significantly impacted the war's outcome.  It is widely believed that Turing's work shortened the war by several years and saved countless lives. Without his contributions, the Allied efforts would have been severely hampered, and the war could have had a very different outcome.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, providing a clear and concise explanation of Alan Turing's role in World War II and the impact of his work on the war's outcome.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-24')">
            <div class="question-text">
                <div class="question-id">Question #24</div>
                Would a sophist use an √©p√©e?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-24">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a sophist use an √©p√©e?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A sophist is a specific kind of teacher in ancient Greece, in the fifth and fourth centuries BC. Sophists specialized in using the tools of philosophy and rhetoric, though other sophists taught subjects such as music, athletics and mathematics. An √©p√©e is a sword used in fencing. The √©p√©e was not developed until the 19th century.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A sophist is a person who reasons with clever but fallacious arguments.  An √©p√©e is a fencing sword.  The question is a play on words, since "sophism" and "√©p√©eism" are very similar.  While a sophist might *use* an √©p√©e, the question is about the more common usage of sophist related to rhetoric and logical fallacies.  There is nothing in the definition of sophist that dictates they would or would not use an √©p√©e.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning hallucinates a connection between "sophism" and "√©p√©eism" that does not exist in the reference, leading to a flawed interpretation of the question.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The question is a play on words, since "sophism" and "√©p√©eism" are very similar.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference does not mention any similarity between "sophism" and "√©p√©eism". This is a misinterpretation of the question.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The question is a play on words, since "sophism" and "√©p√©eism" are very similar.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">A sophist is a specific kind of teacher in ancient Greece, in the fifth and fourth centuries BC. ... An √©p√©e is a sword used in fencing.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-25')">
            <div class="question-text">
                <div class="question-id">Question #25</div>
                Did Dale Jr hug his dad after their last Daytona 500 together?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-25">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Dale Jr hug his dad after their last Daytona 500 together?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Dale Jr. and his father Dale Sr. last raced together at the Daytona 500 in 2001. During the 2001 Daytona 500 Dale Sr. suffered a basilar skull fracture and died.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Dale Earnhardt Jr. and Dale Earnhardt Sr. last raced together in the Daytona 500 in 2001.  Dale Sr. tragically died in a crash on the last lap of that race.  Therefore, there would have been no opportunity for a hug afterward.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that Dale Earnhardt Sr. died in the 2001 Daytona 500, making it impossible for Dale Jr. to hug him afterward.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-26')">
            <div class="question-text">
                <div class="question-id">Question #26</div>
                Can citrus grow in Ulaanbaatar?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-26">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can citrus grow in Ulaanbaatar?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Citrus can withstand short periods down to as cold as ‚àí10 ¬∞C (14 ¬∞F), but realistically temperatures not falling below ‚àí2 ¬∞C (28 ¬∞F) are required for successful cultivation. Ulaanbaatar has an average annual temperature of ‚àí0.4 ¬∞C or 31.3 ¬∞F.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Ulaanbaatar, Mongolia has a very harsh continental climate with short, hot summers and long, frigid winters.  Citrus fruits require a subtropical or tropical climate to thrive.  Ulaanbaatar's extreme cold would kill citrus trees.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why citrus cannot grow in Ulaanbaatar, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-27')">
            <div class="question-text">
                <div class="question-id">Question #27</div>
                Does New York Harbor sit on a craton without volcanic activity?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-27">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does New York Harbor sit on a craton without volcanic activity?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. New York Harbor is located on Laurentia craton.  The southwestern portion of Laurentia contains numerous large volcanic eruptions.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: New York Harbor is located on the eastern edge of the North American craton. Cratons are generally stable and lack volcanic activity.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly claims that cratons generally lack volcanic activity, contradicting the reference explanation that the southwestern portion of Laurentia (a craton) contains numerous large volcanic eruptions.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Cratons are generally stable and lack volcanic activity.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the southwestern portion of Laurentia contains numerous large volcanic eruptions, contradicting the statement that cratons generally lack volcanic activity.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Cratons are generally stable and lack volcanic activity.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The southwestern portion of Laurentia contains numerous large volcanic eruptions.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-28')">
            <div class="question-text">
                <div class="question-id">Question #28</div>
                Can the Palace of Westminster tell time in the dark?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-28">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can the Palace of Westminster tell time in the dark?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Palace of Westminster has Big Ben, a striking clock tower. Big Ben communicates the time via bells.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Palace of Westminster houses Big Ben, a famous clock with a large bell and illuminated clock faces.  Therefore, the Palace of Westminster can tell time in the dark.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning contains a logical error by stating that Big Ben has illuminated clock faces, implying that it tells time visually in the dark, while the reference explanation states that Big Ben communicates the time via bells.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Palace of Westminster houses Big Ben, a famous clock with a large bell and illuminated clock faces.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that Big Ben has illuminated clock faces, implying that it can tell time visually in the dark. However, the reference explanation states that Big Ben communicates the time via bells, which is how it tells time, especially in the dark. The generated reasoning misinterprets how Big Ben tells time.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">illuminated clock faces</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Big Ben communicates the time via bells.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-29')">
            <div class="question-text">
                <div class="question-id">Question #29</div>
                In teenagers and young adults with depression, are SSRI medications less safe than they are for adults?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-29">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">In teenagers and young adults with depression, are SSRI medications less safe than they are for adults?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In teens, SSRI medications may increase the risk of suicidal thinking. In adults over 25, SSRI medications are regarded as generally safe.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: SSRIs carry a black box warning for increased risk of suicidality in children, adolescents, and young adults up to age 24.  While they are still commonly prescribed and can be helpful, this population needs to be more closely monitored for worsening symptoms and suicidal thoughts/behaviors when starting or changing doses of SSRIs.  Therefore, while not necessarily *less* *safe*, there is more to consider regarding risk/benefit compared to older adults.

So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that SSRI medications may increase the risk of suicidal thinking in teens and young adults, while they are generally considered safe for adults over 25.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-30')">
            <div class="question-text">
                <div class="question-id">Question #30</div>
                Does Marco Rubio have a close relationship with Allah?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-30">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Marco Rubio have a close relationship with Allah?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Marco Rubio adheres to the religious sect of Christianity known as Catholicism. Catholics and other Christians worship God. Allah is worshiped by believers of Islam.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Marco Rubio is a practicing Catholic.  Catholicism is a Christian religion. Islam is a separate Abrahamic religion that reveres Allah. While both religions share some historical figures and narratives, they are distinct faiths with different central figures of worship.  It is unlikely for a practicing Catholic to have a close, personal relationship with a central figure of another religion.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Marco Rubio's religious affiliation and contrasts it with the worship of Allah in Islam, leading to a logical conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-31')">
            <div class="question-text">
                <div class="question-id">Question #31</div>
                Would Persephone be a good consultant to a landscape architect?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-31">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Persephone be a good consultant to a landscape architect?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Persephone is a vegetation goddess.  A vegetation deity is a nature deity whose disappearance and reappearance, or life, death and rebirth, embodies the growth cycle of plants. Landscape architects deal with planning and laying out gardens and other plant life.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Persephone is the Greek goddess of spring growth, so she would have extensive knowledge of plants and flowers.  Landscape architects design outdoor spaces using plants. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a sound justification for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-32')">
            <div class="question-text">
                <div class="question-id">Question #32</div>
                Is Argon near Neon on the periodic table of elements?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-32">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Argon near Neon on the periodic table of elements?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Argon is a noble gas. Neon is a noble gas.  The noble gases are all clumped together on the periodic table of elements.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Argon (Ar) has atomic number 18. Neon (Ne) has atomic number 10. They are both noble gases and in the same column (group 18) of the periodic table. Elements in the same group are arranged vertically and share similar chemical properties.  Therefore, Argon is in the same column and near Neon on the periodic table.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Argon and Neon as noble gases and their proximity on the periodic table.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-33')">
            <div class="question-text">
                <div class="question-id">Question #33</div>
                Did Thomas Greenhill's parents violate the concept of monogamy?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-33">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Thomas Greenhill's parents violate the concept of monogamy?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Thomas Greenhill was a surgeon born to William and Elizabeth Greenhill. William and Elizabeth Greenhill had 39 children. Monogamy is a committed relationship between two people where usually they remain together for life. Thomas Greenhill was the last of his parents 39 children and was born shortly after his father died.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Thomas Greenhill was the illegitimate son of painter Joshua Reynolds and his mistress.
Monogamy is defined as the practice or custom of having only one wife or husband at a time.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning hallucinates that Thomas Greenhill was the son of Joshua Reynolds, which is incorrect. The reference states that he was the son of William and Elizabeth Greenhill.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Thomas Greenhill was the illegitimate son of painter Joshua Reynolds and his mistress.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that Thomas Greenhill was the illegitimate son of Joshua Reynolds, but the reference states that Thomas Greenhill was the son of William and Elizabeth Greenhill.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Thomas Greenhill was the illegitimate son of painter Joshua Reynolds and his mistress.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Thomas Greenhill was a surgeon born to William and Elizabeth Greenhill.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-34')">
            <div class="question-text">
                <div class="question-id">Question #34</div>
                Would it be uncommon for a high schooler to use the yellow pages?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-34">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would it be uncommon for a high schooler to use the yellow pages?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. High school students are between 14-19 years old.  Teenagers now are considered 'digital natives'.  'Digital natives' are individuals who have grown up during the computer age, being exposed to technology from early childhood.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: High schoolers are generally members of Generation Z.  Generation Z has grown up with ubiquitous internet access.  The yellow pages are a print directory of businesses, largely supplanted by online search engines.  It would be uncommon for a high schooler to use the yellow pages.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that high schoolers are digital natives who are unlikely to use the yellow pages, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-35')">
            <div class="question-text">
                <div class="question-id">Question #35</div>
                Could an escapee swim nonstop from Alcatraz island to Siberia?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-35">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could an escapee swim nonstop from Alcatraz island to Siberia?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Alcatraz Island was a San Francisco Bay prison. Siberia is over 5,217 miles away from San Francisco. The longest continuous swim record was 139 miles.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Alcatraz is off the coast of San Francisco.  Siberia is across the Pacific Ocean.  No human could swim that distance. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Alcatraz is off the coast of San Francisco and Siberia is across the Pacific Ocean, leading to the correct conclusion that no human could swim that distance. This aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-36')">
            <div class="question-text">
                <div class="question-id">Question #36</div>
                Would the Titanic be well preserved at the bottom of the Gulf of Finland?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-36">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would the Titanic be well preserved at the bottom of the Gulf of Finland?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The bottom of the gulf is one of the world's largest ship cemeteries. Because of the low salinity and cold waters, and no shipworms, the ships are relatively well preserved. RMS Titanic was a British passenger ship.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Titanic sank in the Atlantic Ocean, not the Gulf of Finland.  The preservation of a shipwreck depends heavily on the environment in which it rests.  The Gulf of Finland, being part of the Baltic Sea, has brackish water (a mix of fresh and saltwater) which can be more corrosive to some materials than the deep ocean saltwater where the Titanic rests. The Titanic rests very deep in the Atlantic which also contributes to its preservation.  So even if the Titanic had sunk in the Gulf of Finland, the conditions there are less conducive to preservation than its actual resting place.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that the Titanic sank in the Atlantic Ocean and discusses the environmental factors affecting preservation, although it doesn't directly address whether the Titanic would be well-preserved in the Gulf of Finland based on the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-37')">
            <div class="question-text">
                <div class="question-id">Question #37</div>
                Could a snowy owl survive in the Sonoran?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-37">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a snowy owl survive in the Sonoran?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Snowy owl is a bird native to the Arctic regions of North America. Temperatures in the North American Arctic range from -36.4F to 50F. The Sonoran is one of the hottest deserts in the world. The Sonoran Desert can get as hot as 118F.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Snowy owls are adapted to cold, arctic climates. The Sonoran Desert is a hot, arid environment.  These are incompatible environments for the snowy owl's survival needs. {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that snowy owls are adapted to cold climates and the Sonoran Desert is a hot environment, making them incompatible.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-38')">
            <div class="question-text">
                <div class="question-id">Question #38</div>
                Would a rabbi worship martyrs Ranavalona I killed?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-38">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a rabbi worship martyrs Ranavalona I killed?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Rabbis are teachers of Judaism. Ranavalona I, ruler of Madagascar, killed many Christians that were later determined by the church to be martyrs. Judaism does not have a group of saints and martyrs that are prayed to like Christianity..</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Ranavalona I was the queen of the Merina Kingdom, which is located in Madagascar, and ruled during the 19th century. She is known for her persecution of Christians and is estimated to have killed thousands of people during her reign, some of whom were considered martyrs by Christians.  A rabbi is a Jewish religious leader and would adhere to the tenets of Judaism, not Christianity. Therefore, a rabbi would not worship the Christian martyrs killed by Ranavalona I.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-39')">
            <div class="question-text">
                <div class="question-id">Question #39</div>
                Would an oil painter avoid reds from scale insects that live on a cactus?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-39">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would an oil painter avoid reds from scale insects that live on a cactus?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Carmine is the product of an insect that lives on some cacti. Carmine is not stable in oil paints and its usage has been discontinued. Carmine is red.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Cochineal insects, which live on prickly pear cacti, are the source of carmine, a natural red pigment.  Oil painters frequently use carmine and other pigments derived from cochineal. Therefore, an oil painter would not necessarily avoid reds from scale insects that live on a cactus, as these can be a valuable source of pigment.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error regarding the use of carmine in oil paints, directly contradicting the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Oil painters frequently use carmine and other pigments derived from cochineal.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that carmine is not stable in oil paints and its usage has been discontinued, which contradicts the statement that oil painters frequently use carmine.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Oil painters frequently use carmine and other pigments derived from cochineal.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Carmine is not stable in oil paints and its usage has been discontinued.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-40')">
            <div class="question-text">
                <div class="question-id">Question #40</div>
                Was the Second Amendment to the United States Constitution written without consideration for black Americans?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-40">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was the Second Amendment to the United States Constitution written without consideration for black Americans?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The writers of the Constitutional Amendments did not view black people as legitimate human beings. The writers of the Constitutional Amendments believed that slavery benefited black slaves. The Constitutional Amendments were written for people that the writers considered human.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">The Second Amendment, ratified in 1791, was written during a time when slavery was legal in the United States.  The Founding Fathers, who drafted the Constitution and the Bill of Rights, largely held racist views and did not consider enslaved people to have the same rights as white citizens.  Therefore, while the Second Amendment speaks to the right to bear arms, this right was not intended for, nor extended to, Black Americans who were enslaved at the time.  Even after the abolition of slavery, systemic racism continued to restrict Black Americans' access to firearms ownership and other rights.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that the Second Amendment was written without consideration for black Americans due to the racist views of the Founding Fathers and the prevalence of slavery at the time.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-41')">
            <div class="question-text">
                <div class="question-id">Question #41</div>
                Are all the elements plants need for photosynthesis present in atmosphere of Mars?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-41">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are all the elements plants need for photosynthesis present in atmosphere of Mars?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Plants need three elements for photosynthesis: Hydrogen, Oxygen, and Carbon. The atmosphere of Mars is composed of carbon dioxide, nitrogen, argon, and trace levels of water vapor, oxygen, carbon monoxide, hydrogen and other noble gases.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Photosynthesis requires carbon dioxide, water, and sunlight. While Mars has sunlight and some carbon dioxide in its atmosphere, the amount of water vapor present is minimal.  Plants also require nutrients typically found in soil, which are not readily available in the Martian atmosphere. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces irrelevant information about soil nutrients, which are not part of the photosynthesis process described in the reference. This leads to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Plants also require nutrients typically found in soil, which are not readily available in the Martian atmosphere.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The question asks about elements needed for photosynthesis, not general plant nutrients. The reference explanation only discusses the elements needed for photosynthesis, which are present in the Martian atmosphere.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Plants also require nutrients typically found in soil, which are not readily available in the Martian atmosphere.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Plants need three elements for photosynthesis: Hydrogen, Oxygen, and Carbon.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-42')">
            <div class="question-text">
                <div class="question-id">Question #42</div>
                Can you find Bob Marley's face in most smoke shops?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-42">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you find Bob Marley's face in most smoke shops?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Bob Marley's face is on the packaging of a popular brand of rolling papers. Bob Marley is a popular graphic to print on t-shirts for sale to smokers.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Bob Marley is a cultural icon associated with cannabis use.  Images of him are frequently displayed in smoke shops that cater to that culture.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies Bob Marley's association with cannabis culture and the likelihood of his image being displayed in smoke shops, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-43')">
            <div class="question-text">
                <div class="question-id">Question #43</div>
                Did Pablo Escobar's nickname collection outshine Robert Moses Grove's?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-43">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Pablo Escobar's nickname collection outshine Robert Moses Grove's?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Robert Moses Grove was a baseball player nicknamed Lefty Grove. Pablo Escobar had several nicknames including: Don Pablo, El Padrino, and El Patr√≥n.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
Pablo Escobar's nicknames include "El Padrino" (The Godfather) and "El Patr√≥n" (The Boss).  Robert Moses Grove's nicknames include "Lefty," "Old Mose," and "Blackie."  While Escobar's nicknames are more evocative of power and notoriety, Grove's are more descriptive or based on appearance.  Whether Escobar's "outshine" Grove's is subjective, but it's fair to say they reflect different aspects of their respective personalities and public images.  One could argue Escobar's nicknames are more widely recognized due to his notoriety, but "outshine" is a matter of opinion.

{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain hallucinates nicknames for Robert Moses Grove that are not mentioned in the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Robert Moses Grove's nicknames include "Lefty," "Old Mose," and "Blackie."</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation only mentions that Robert Moses Grove was nicknamed Lefty Grove. The other nicknames are not mentioned and therefore are a hallucination.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Robert Moses Grove's nicknames include "Lefty," "Old Mose," and "Blackie."</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Robert Moses Grove was a baseball player nicknamed Lefty Grove.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-44')">
            <div class="question-text">
                <div class="question-id">Question #44</div>
                Has the Subway restaurant franchise had any connections with child abusers?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-44">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Has the Subway restaurant franchise had any connections with child abusers?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Subway hired Jared Fogle as a spokesman for their sandwich shops. Jared Fogle was convicted for having sex with minors and for possessing child pornography.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Jared Fogle, Subway's longtime spokesperson, was convicted of child pornography charges and traveling to engage in illicit sexual conduct with a minor. He was sentenced to over 15 years in prison. This created a significant scandal for the company.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. It correctly identifies Jared Fogle's connection to Subway and his conviction for child pornography charges and illicit sexual conduct with a minor.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-45')">
            <div class="question-text">
                <div class="question-id">Question #45</div>
                Does autopilot rely on fossil fuels?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-45">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does autopilot rely on fossil fuels?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Autopilot is used in vehicles. Vehicles are powered by engines. Engines rely on fossil fuels to operate.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Autopilot, as a feature in vehicles like Tesla cars, relies on electricity to power the car's systems.  While the electricity used to charge the car's batteries *might* be generated from fossil fuels, autopilot itself doesn't directly consume or rely on them. It relies on electricity, which can come from various sources, including renewable energy. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces the idea that autopilot relies on electricity, which is not mentioned in the reference. This is a misinterpretation of the reference fact that vehicles rely on fossil fuels.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Autopilot, as a feature in vehicles like Tesla cars, relies on electricity to power the car's systems.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that autopilot is used in vehicles, which are powered by engines that rely on fossil fuels. The generated reasoning introduces the idea that autopilot relies on electricity, which is not mentioned in the reference. This is a misinterpretation of the reference fact that vehicles rely on fossil fuels.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Autopilot, as a feature in vehicles like Tesla cars, relies on electricity to power the car's systems.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Vehicles are powered by engines. Engines rely on fossil fuels to operate.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-46')">
            <div class="question-text">
                <div class="question-id">Question #46</div>
                Are psychiatric patients welcome to join the United States Air Force?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-46">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are psychiatric patients welcome to join the United States Air Force?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Having a history of mental illness disqualifies most people from joining the Armed Forces. Psychiatric patients are being seen for management of mental illness.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Individuals with a history of severe mental disorders, including most psychotic disorders, are generally disqualified from serving in the United States Air Force.  This includes conditions like schizophrenia, bipolar disorder, and major depressive disorder with psychotic features. While waivers are sometimes possible, they are rarely granted for these conditions due to the demanding and stressful nature of military service. The Air Force requires its members to maintain a high level of mental stability and resilience.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that individuals with a history of mental illness are generally disqualified from serving in the United States Air Force.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-47')">
            <div class="question-text">
                <div class="question-id">Question #47</div>
                Does Nicole Kidman know any Scientologists?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-47">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Nicole Kidman know any Scientologists?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Nicole Kidman was married to Tom Cruise. Tom Cruise is a Scientologist.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Nicole Kidman was married to Tom Cruise, a prominent Scientologist, for over 10 years.  It is highly likely she knows other Scientologists through him, even if she herself is not one.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Nicole Kidman knows Scientologists because she was married to Tom Cruise, who is a Scientologist. The reasoning is sound and aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-48')">
            <div class="question-text">
                <div class="question-id">Question #48</div>
                Was John Lennon known to be a good friend to Sasha Obama?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-48">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was John Lennon known to be a good friend to Sasha Obama?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. John Lennon died in 1980. Sasha Obama was born in 2001.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: John Lennon died in 1980. Sasha Obama was born in 2001.  It is impossible for them to have been friends.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly states the facts and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-49')">
            <div class="question-text">
                <div class="question-id">Question #49</div>
                Would the tunnels at CERN fit onto the High Speed 1 rails?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-49">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would the tunnels at CERN fit onto the High Speed 1 rails?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. High Speed 1 (HS1), legally the Channel Tunnel Rail Link (CTRL), is a 67-mile (108 km) high-speed railway. The CERN collider is contained in a circular tunnel, with a circumference of 26.7 kilometres (16.6 mi). The circumference of a circle is the length of the enclosing boundary.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Large Hadron Collider at CERN has a circumference of 27 kilometers. High Speed 1, also known as the Channel Tunnel Rail Link, has a total length of 108 kilometers. The tunnels at CERN are much shorter than the rails of High Speed 1. Thus, they could easily fit onto the rails.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly compares the circumference of the CERN collider to the length of the High Speed 1 rails and concludes that the CERN tunnels could fit onto the rails. No hallucinations are present.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-50')">
            <div class="question-text">
                <div class="question-id">Question #50</div>
                Could an elephant easily defeat a male macaque?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-50">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could an elephant easily defeat a male macaque?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Male macaques range from 16 to 28 inches tall with a weight between 12.13 to 39.7 pounds. Elephants are between 7 to 11 feet tall and weigh several thousand pounds. Elephants contain large, sharp tusks that can injure or kill other animals.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Adult male macaques weigh between 10-15kg.  Adult elephants can weigh between 2,700 - 6,000kg.  An elephant is significantly larger and stronger than a macaque.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain contains a minor factual inaccuracy regarding the weight of male macaques.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Adult male macaques weigh between 10-15kg.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that male macaques weigh between 12.13 to 39.7 pounds, which is approximately 5.5 to 18 kg. The generated reasoning states that they weigh between 10-15kg, which is not entirely wrong but not as accurate as the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Adult male macaques weigh between 10-15kg.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">weight between 12.13 to 39.7 pounds</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-51')">
            <div class="question-text">
                <div class="question-id">Question #51</div>
                Do the Ubuntu people speak Ubuntu?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-51">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do the Ubuntu people speak Ubuntu?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Ubuntu is a of free and open-source software used on computers. The Ubuntu people are a tribe that lives in Africa. The Ubuntu people derive their language from Nguni Bantu. As of 2019 only 10% of households in Africa have a computer.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Ubuntu is a Nguni Bantu term meaning "humanity".  It is often translated as "I am because we are," or "humanity towards others".  While the term originates with the Nguni Bantu language family, Ubuntu itself is a philosophy and worldview, not a distinct language.  The Ubuntu people, if referring to those who adhere to the Ubuntu philosophy, would speak various languages, depending on their geographic and cultural background. Many Nguni Bantu languages are spoken in Southern Africa, including Zulu, Xhosa, Southern Ndebele, Swazi, and Northern Ndebele.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain misinterprets the reference fact that the Ubuntu people derive their language from Nguni Bantu.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Ubuntu is a Nguni Bantu term meaning "humanity".</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the Ubuntu people derive their language from Nguni Bantu. The generated reasoning states that Ubuntu is a Nguni Bantu term meaning "humanity". This is a misinterpretation of the reference fact.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Ubuntu is a Nguni Bantu term meaning "humanity".</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Ubuntu people derive their language from Nguni Bantu.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-52')">
            <div class="question-text">
                <div class="question-id">Question #52</div>
                Is cycling a high-risk activity for pelvis fractures?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-52">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is cycling a high-risk activity for pelvis fractures?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Cycling is a low-impact activity . Stress fractures in a pelvic bone often develop as a result of repetitive, high-impact activity that puts stress on the pelvis, such as long-distance running or ballet.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Cycling can involve falls, and in the event of a fall, the pelvis can be injured.  High-impact falls can result in pelvic fractures. However, cycling is not generally considered a high-risk activity for pelvic fractures when compared to activities like contact sports or motorcycling.  While fractures can occur, they are not common enough to classify cycling as inherently high-risk for this specific injury.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning introduces the possibility of falls, which is not the focus of the reference explanation. The reference focuses on stress fractures from the activity itself, not from external events like falls.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Cycling can involve falls, and in the event of a fall, the pelvis can be injured.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that cycling is a low-impact activity and that stress fractures in the pelvic bone are a result of repetitive, high-impact activity. The generated reasoning introduces the possibility of falls, which is not the focus of the reference explanation. The reference focuses on stress fractures from the activity itself, not from external events like falls.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Cycling can involve falls, and in the event of a fall, the pelvis can be injured.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Cycling is a low-impact activity</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-53')">
            <div class="question-text">
                <div class="question-id">Question #53</div>
                Is a platypus immune from cholera?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-53">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is a platypus immune from cholera?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Cholera is a bacteria that damages the small intestines in humans. The intestines are part of the stomach of humans. A platypus does not have a stomach.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Cholera is a bacterial infection that affects the intestines.  Platypuses are mammals, and mammals can be affected by bacterial infections. There's no reason to believe platypuses have a special immunity to cholera.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain fails to use the key fact from the reference explanation (platypuses lack a stomach) and instead makes a general statement about mammals and bacterial infections, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Platypuses are mammals, and mammals can be affected by bacterial infections.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that platypuses do not have a stomach, which is necessary for cholera to affect them. The generated reasoning makes a logical error by stating that platypuses are mammals and mammals can be affected by bacterial infections, which is irrelevant to the fact that platypuses lack a stomach.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Platypuses are mammals, and mammals can be affected by bacterial infections.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">A platypus does not have a stomach.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-54')">
            <div class="question-text">
                <div class="question-id">Question #54</div>
                Would a moose hypothetically be too much for a minotaur to devour whole?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-54">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a moose hypothetically be too much for a minotaur to devour whole?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A minotaur was a mythological beast with the head of a bull and body of a human. Human stomachs process about three to four pounds of food a day. A moose can weigh up to 1500 pounds. Bulls can consume around 33 pounds of food a day.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A moose can weigh up to 1,800 pounds.  A minotaur is a mythical creature, half man and half bull.  While bulls are large and strong, they don't typically swallow things whole, especially something the size of a large moose. Even allowing for the mythical strength of a minotaur, swallowing an entire moose seems improbable.

{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning contains a factual error regarding the weight of a moose, but the overall reasoning is sound.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A moose can weigh up to 1,800 pounds.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that a moose can weigh up to 1,800 pounds, but the reference states that a moose can weigh up to 1,500 pounds.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">1,800 pounds</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">1500 pounds</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-55')">
            <div class="question-text">
                <div class="question-id">Question #55</div>
                Are there bones in an anchovy pizza?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-55">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are there bones in an anchovy pizza?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Anchovies used on pizza are typically packed whole in oil or water.  Anchovies on pizza are not usually cut or filleted in any way.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Anchovies are small, common forage fish in the herring family.  While they do have bones, they are very small and often soften during the cooking process.  Therefore, an anchovy pizza would contain bones.
{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that anchovies on pizza contain bones because they are typically used whole and not filleted.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-56')">
            <div class="question-text">
                <div class="question-id">Question #56</div>
                Can a Bengal cat survive eating only pancakes?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-56">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a Bengal cat survive eating only pancakes?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Bengal cats are carnivores. Pancakes contain no meat. Carnivores eat only meat to survive.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Bengal cats, like all cats, are obligate carnivores. This means their bodies are designed to primarily process and obtain nutrients from animal-based protein.  Pancakes are made from grains and offer little to no nutritional value that a cat needs to survive. A diet lacking in animal protein will lead to severe health problems and eventual death for a Bengal cat. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why a Bengal cat cannot survive on a pancake-only diet, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap,contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-57')">
            <div class="question-text">
                <div class="question-id">Question #57</div>
                Can the original name of the zucchini be typed on the top row of a QWERTY keyboard?
            </div>
            <span class="hallucination-count ">2 issues</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-57">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can the original name of the zucchini be typed on the top row of a QWERTY keyboard?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The original name for the zucchini in Mexican language or Nahuatl is ayokonetl. The top row of a QWERTY keyboard contains the keys q, w, e, r, t, y, u, i , o, and p.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">The original name of the zucchini is "zucca."  The letters Z, U, C, and C are all on the top row of a QWERTY keyboard.  Therefore, the word "zucca" can be typed on the top row.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains multiple hallucinations. It incorrectly states the original name of the zucchini and incorrectly identifies the letters on the top row of a QWERTY keyboard.</div>
            </div>
            <h3>Detected Issues (2)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The original name of the zucchini is "zucca."</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The original name of the zucchini is ayokonetl, not zucca.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">"zucca"</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">ayokonetl</div>
        </div>
        
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The letters Z, U, C, and C are all on the top row of a QWERTY keyboard.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The top row of a QWERTY keyboard contains the letters q, w, e, r, t, y, u, i , o, and p. The letters Z and C are not on the top row.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Z, U, C, and C are all on the top row of a QWERTY keyboard</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">q, w, e, r, t, y, u, i , o, and p</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-58')">
            <div class="question-text">
                <div class="question-id">Question #58</div>
                Does The Hague border multiple bodies of water?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-58">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does The Hague border multiple bodies of water?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Hague is in the Netherlands.  The Hague is in the Western part of the Netherlands.  The Netherlands borders the North Sea to its west.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Hague is a city on the western coast of the Netherlands bordering the North Sea.  It doesn't border multiple bodies of water.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. It correctly states that The Hague is on the western coast of the Netherlands bordering the North Sea and that it does not border multiple bodies of water.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-59')">
            <div class="question-text">
                <div class="question-id">Question #59</div>
                Do people in middle school usually get breast exams?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-59">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do people in middle school usually get breast exams?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Women should begin giving themselves breast exams at the age of 20. Middle school students are usually preteens or young teens.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Middle school typically encompasses ages 11-14.  Breast exams are not a routine part of healthcare for this age group.  While some young girls may begin puberty during middle school, routine breast exams are typically recommended for adult women, starting later in life.  Doctors may perform a breast exam if a specific concern arises, but it's not standard practice.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that breast exams are not a routine part of healthcare for middle schoolers, who are typically preteens or young teens.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-60')">
            <div class="question-text">
                <div class="question-id">Question #60</div>
                Did people in Korea under Japanese Rule watch a lot of Iron Chef?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-60">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did people in Korea under Japanese Rule watch a lot of Iron Chef?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The first televisions were sold in 1946. Iron Chef started airing in 1993.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Iron Chef premiered in 1993.  Japanese rule in Korea ended in 1945. Therefore, people in Korea under Japanese rule would not have been able to watch Iron Chef.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly deduces that people in Korea under Japanese rule could not have watched Iron Chef, based on the timeline of Japanese rule ending in 1945 and Iron Chef premiering in 1993. This aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-61')">
            <div class="question-text">
                <div class="question-id">Question #61</div>
                Would  bald eagle deliver an urgent message before B-52?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-61">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would  bald eagle deliver an urgent message before B-52?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A bald eagle can travel up to 99 MPH. The B-52 is a US air bomber that can travel up to 650 MPH.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Bald eagles can fly at a maximum speed of 30-35 mph. The B-52 has a maximum speed of 650 mph.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contains a factual error regarding the speed of bald eagles, which contradicts the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Bald eagles can fly at a maximum speed of 30-35 mph.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that bald eagles can fly at a maximum speed of 30-35 mph, which contradicts the reference explanation that states they can travel up to 99 mph.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Bald eagles can fly at a maximum speed of 30-35 mph.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">A bald eagle can travel up to 99 MPH.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-62')">
            <div class="question-text">
                <div class="question-id">Question #62</div>
                Does Snoopy look like Chance from Homeward Bound?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-62">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Snoopy look like Chance from Homeward Bound?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Chance from Homeward Bound is a golden retriever.  Snoopy is black and white. Golden Retrievers are yellow in color.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Snoopy is a beagle. Chance from Homeward Bound is an American Bulldog.  They don't look alike.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly identifies Chance from Homeward Bound as an American Bulldog, when he is a golden retriever. This is a significant factual error.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Chance from Homeward Bound is an American Bulldog.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">Chance from Homeward Bound is a golden retriever, not an American Bulldog.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Chance from Homeward Bound is an American Bulldog</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Chance from Homeward Bound is a golden retriever</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-63')">
            <div class="question-text">
                <div class="question-id">Question #63</div>
                Was Dioskourides a lapidary?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-63">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Dioskourides a lapidary?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A lapidary is a person or machine who cuts gemstones; classically, it refers to a person who engraves gemstones. Dioskourides put his signature on a Roman amethyst ringstone with a portrait of Demosthenes circa late 1st century BC. Artists sign their work.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Dioskourides was a physician, pharmacologist, and botanist.  A lapidary is someone who cuts, polishes, or engraves gems. While Dioskourides studied minerals for their medicinal properties as described in *De materia medica*, this does not qualify him as a lapidary.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly claims that Dioskourides's study of minerals does not qualify him as a lapidary, contradicting the reference which states he signed a ringstone, thus qualifying him as a lapidary.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">While Dioskourides studied minerals for their medicinal properties as described in *De materia medica*, this does not qualify him as a lapidary.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Dioskourides signed a Roman amethyst ringstone, which qualifies him as a lapidary. The generated reasoning contradicts this by stating that studying minerals for medicinal properties does not qualify him as a lapidary.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">this does not qualify him as a lapidary</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Dioskourides put his signature on a Roman amethyst ringstone with a portrait of Demosthenes circa late 1st century BC.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-64')">
            <div class="question-text">
                <div class="question-id">Question #64</div>
                Do most middle class families have butlers?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-64">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do most middle class families have butlers?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Butlers make about $60,000 per year on average for their work. Middle class income is between $48,000 and $145,000.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">A butler is a live-in domestic worker, usually male, responsible for managing a household's staff and serving the needs of the family and guests.  Butlers are traditionally associated with wealthy families who can afford to employ a large household staff. Middle-class families typically do not have the resources to employ live-in domestic help, including butlers.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly explains why middle-class families typically do not have butlers, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-65')">
            <div class="question-text">
                <div class="question-id">Question #65</div>
                Was Hillary Clinton's deputy chief of staff in 2009 baptised?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-65">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Hillary Clinton's deputy chief of staff in 2009 baptised?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Huma Abedin was Hillary Clinton's deputy chief of staff in 2009. Huma Abedin is an American Muslim. Baptism is a Christian tradition.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Huma Abedin was Hillary Clinton's deputy chief of staff in 2009.  Huma Abedin is Muslim.  Muslim individuals are not typically baptized. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-66')">
            <div class="question-text">
                <div class="question-id">Question #66</div>
                Does the New York Public Library sell Alpo products?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-66">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does the New York Public Library sell Alpo products?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The New York Public Library is a public lending library system in New York City. Alpo produces pet food and related products.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The New York Public Library is a library system.  Libraries lend books and other media.  They do not typically sell pet food. Alpo is a brand of pet food.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that the New York Public Library is a library system that lends books and other media, and that libraries do not typically sell pet food. It also correctly identifies Alpo as a brand of pet food. Therefore, the New York Public Library does not sell Alpo products.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-67')">
            <div class="question-text">
                <div class="question-id">Question #67</div>
                Did Solomon make up bigger percentage of Islamic prophets than Kings of Judah?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-67">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Solomon make up bigger percentage of Islamic prophets than Kings of Judah?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. According to The Quran, Solomon was one of 25 prophets. According to some Islamic hadiths, there have been as many as 124,000 prophets. Solomon was one of 20 Kings of Judah.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Solomon was both a King of Judah and an Islamic prophet.  Since he's a member of both sets, he represents a larger percentage of the smaller set (Kings of Judah). There have been many more Islamic prophets than Kings of Judah.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error, stating that Solomon was both a King of Judah and an Islamic prophet, which contradicts the reference explanation. This error leads to incorrect reasoning and a wrong conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Solomon was both a King of Judah and an Islamic prophet.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Solomon was one of 20 Kings of Judah and one of 25 prophets according to The Quran. The generated reasoning incorrectly states that he was both.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Solomon was both a King of Judah and an Islamic prophet</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Solomon was one of 20 Kings of Judah. According to The Quran, Solomon was one of 25 prophets.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-68')">
            <div class="question-text">
                <div class="question-id">Question #68</div>
                Would Taylor Swift refer to Snoopy as oppa?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-68">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Taylor Swift refer to Snoopy as oppa?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Oppa is a Korean word used by women to address a man who is 10 or more years older than her. Snoopy is 47 years old. Taylor Swift is 30 years old.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Taylor Swift is American.  "Oppa" is a Korean honorific used by females to refer to older males with whom they are close.  It is unlikely Taylor Swift would use this term, especially for a cartoon dog.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain makes a logical error by stating that it is unlikely Taylor Swift would use the term oppa for Snoopy, when the reference explanation states that Snoopy is more than 10 years older than Taylor Swift, making it likely that she would use the term.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">It is unlikely Taylor Swift would use this term, especially for a cartoon dog.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that Taylor Swift is 30 and Snoopy is 47, meaning that Snoopy is more than 10 years older than Taylor Swift. Therefore, it is likely that Taylor Swift would refer to Snoopy as oppa.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">It is unlikely Taylor Swift would use this term, especially for a cartoon dog.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Oppa is a Korean word used by women to address a man who is 10 or more years older than her. Snoopy is 47 years old. Taylor Swift is 30 years old.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-69')">
            <div class="question-text">
                <div class="question-id">Question #69</div>
                Did Confederate States Army influence West Point fashion?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-69">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Confederate States Army influence West Point fashion?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Confederate States Army was clad in cadet gray uniforms. West Point uniforms are cadet gray and white. Confederate States Army uniforms contained Generally, the uniform jacket of the Confederate soldier was single breasted, made of gray or brown fabric, with a six to nine button front and hat.  West Point uniforms contain a standing collar, white trousers, and black shakos (known as a "tarbucket hat" in U.S. Army nomenclature).</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: West Point, the United States Military Academy, maintains a distinct military fashion tradition. The Confederate States Army, having seceded from the United States, would have had no influence over West Point's traditions or fashion after the secession.  {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain directly contradicts the reference explanation by stating that the Confederate States Army had no influence on West Point fashion, while the reference states that it did, specifically regarding the cadet gray uniforms.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Confederate States Army, having seceded from the United States, would have had no influence over West Point's traditions or fashion after the secession.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the Confederate States Army influenced West Point fashion, specifically the cadet gray uniforms.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">would have had no influence over West Point's traditions or fashion after the secession</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Yes. The Confederate States Army was clad in cadet gray uniforms. West Point uniforms are cadet gray and white.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-70')">
            <div class="question-text">
                <div class="question-id">Question #70</div>
                Does conservatism repulse Blaire White?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-70">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does conservatism repulse Blaire White?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Blaire White is a Youtuber. Blaire White posts content that leans towards conservative politics.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Blaire White is an American YouTuber who describes herself as a conservative.  Therefore, conservatism would not repulse her.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly infers that conservatism would not repulse Blaire White, based on the information that she identifies as a conservative. The reasoning aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-71')">
            <div class="question-text">
                <div class="question-id">Question #71</div>
                Do all parts of the aloe vera plant taste good?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-71">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do all parts of the aloe vera plant taste good?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. There is a layer of yellow latex liquid between the outside of an aloe leaf and the gel inside. The latex inside aloe tastes very bitter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Aloe vera is a succulent plant.  The inner gel of the aloe vera plant is commonly used for topical purposes due to its soothing properties. While generally considered safe for topical use, ingesting large amounts of aloe vera latex (the yellow sap) can be harmful.  Different parts of the plant have different properties and tastes. The gel is generally bitter.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that not all parts of the aloe vera plant taste good, specifically mentioning the bitter taste of the gel and the potential harm of ingesting large amounts of aloe vera latex, which aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-72')">
            <div class="question-text">
                <div class="question-id">Question #72</div>
                Does an individual oceanographer study many sciences?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-72">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does an individual oceanographer study many sciences?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Study of the oceans involve many fields or science. To properly study their specific topic of research, an oceanographer must understand how their science interacts with the other involved sciences.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Oceanography is an interdisciplinary science that draws on aspects of geology, chemistry, physics, biology, and meteorology. Individual oceanographers therefore study many sciences.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that oceanography is an interdisciplinary science and that oceanographers study many sciences.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-73')">
            <div class="question-text">
                <div class="question-id">Question #73</div>
                Did Kurt Cobain's music genre survive after his death?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-73">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Kurt Cobain's music genre survive after his death?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Kurt Cobain was the lead singer of Nirvana. Nirvana's music is classified as Grunge rock. Kurt Cobain died on April 5, 1994. Some of the major Grunge rock bands included Alice in Chains, Pearl Jam, and Soundgarden. Alice in Chains and Pearl Jam released their latest albums in 2018 and 2020 respectively.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Kurt Cobain was the lead singer, guitarist, and primary songwriter of the band Nirvana. Nirvana's music is widely considered grunge, a subgenre of alternative rock. Grunge music continued to be made and appreciated after Kurt Cobain's death in 1994.  Many other grunge artists and bands continued to perform and record.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that grunge music continued after Kurt Cobain's death, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-74')">
            <div class="question-text">
                <div class="question-id">Question #74</div>
                Did Immanuel Kant ever meet the 14th president of the United States?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-74">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Immanuel Kant ever meet the 14th president of the United States?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Immanuel Kant died on Feb 12, 1804. Franklin Pierce was the 14th president of the United States. Franklin PIerce was born Nov 23, 1804.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Immanuel Kant died in 1804.
Franklin Pierce, the 14th president of the United States, was born in 1804.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contains a factual error regarding the birthdate of Franklin Pierce, leading to a flawed conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Franklin Pierce, the 14th president of the United States, was born in 1804.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Franklin Pierce was born on Nov 23, 1804, after Immanuel Kant died on Feb 12, 1804. The generated reasoning incorrectly states that Franklin Pierce was born in 1804, implying he could have met Kant.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">was born in 1804</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">was born Nov 23, 1804</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-75')">
            <div class="question-text">
                <div class="question-id">Question #75</div>
                Would eliminating competition in the Japanese bulk carrier market be profitable for a steel company?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-75">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would eliminating competition in the Japanese bulk carrier market be profitable for a steel company?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. 62% of bulk carriers are built in Japan. Bulk carrier hulls are made of steel.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Eliminating competition would give the steel company a monopoly in the Japanese bulk carrier market.  This would allow them to set prices and potentially increase profits significantly. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning makes a logical leap that is not supported by the reference. The reference only provides facts about the construction of bulk carriers and the location of their construction, not about market monopolies.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Eliminating competition would give the steel company a monopoly in the Japanese bulk carrier market.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that 62% of bulk carriers are built in Japan and that bulk carrier hulls are made of steel. It does not imply that a steel company would gain a monopoly in the Japanese bulk carrier market by eliminating competition.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Eliminating competition would give the steel company a monopoly in the Japanese bulk carrier market.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">62% of bulk carriers are built in Japan.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-76')">
            <div class="question-text">
                <div class="question-id">Question #76</div>
                Would a geographer use biochemistry in their work?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-76">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a geographer use biochemistry in their work?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A geographer is a scientist whose area of study is geography, the study of Earth's natural environment and human society. Biochemistry is the study of chemical processes within and relating to living organisms.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Geography is the study of the physical features of the earth and its atmosphere, and of human activity as it affects and is affected by these, including the distribution of populations and resources, land use, and industries. Biochemistry is the branch of science concerned with the chemical and physicochemical processes and substances that occur within living organisms.  A geographer would not use biochemistry in their work.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately defines geography and biochemistry and correctly concludes that a geographer would not use biochemistry in their work, aligning perfectly with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-77')">
            <div class="question-text">
                <div class="question-id">Question #77</div>
                Is most coffee produced South of the Equator?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-77">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is most coffee produced South of the Equator?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The countries with the highest coffee production are in South America. Almost all of South America is in the Southern Hemisphere.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Coffee plants grow best in a band around the equator called the "Bean Belt," which lies between the tropics of Capricorn and Cancer.  Major coffee producers like Brazil, Colombia, Vietnam, Indonesia, and Ethiopia are located within this band.  The majority of these countries are south of the Equator.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain contains a factual error regarding the location of major coffee-producing countries relative to the Equator. While it correctly identifies the "Bean Belt" and some major producers, it incorrectly claims that the majority of the listed countries are south of the Equator.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The majority of these countries are south of the Equator.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning includes Vietnam and Ethiopia in the list of major coffee producers. Vietnam is in the Northern Hemisphere, and Ethiopia is very close to the Equator, but still in the Northern Hemisphere. Therefore, it is not true that the majority of the listed countries are south of the Equator.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The majority of these countries are south of the Equator.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Almost all of South America is in the Southern Hemisphere.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-78')">
            <div class="question-text">
                <div class="question-id">Question #78</div>
                Is it hard to get a BLT in Casablanca?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-78">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it hard to get a BLT in Casablanca?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A BLT is a sandwich consisting of bacon, lettuce and tomato. Casablanca is predominantly Muslim. Islam forbids the consumption of pork and pork products.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A BLT sandwich contains bacon, lettuce, and tomato.  Casablanca is a predominantly Muslim city in Morocco.  Pork products, including bacon, are not commonly consumed due to religious restrictions. Therefore, it would likely be difficult to find a traditional BLT in Casablanca.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a clear and logical argument for why it would be difficult to find a BLT in Casablanca.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-79')">
            <div class="question-text">
                <div class="question-id">Question #79</div>
                Could largest ship from Voyages of Christopher Columbus haul Statue of Liberty?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-79">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could largest ship from Voyages of Christopher Columbus haul Statue of Liberty?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The largest ship Christopher Columbus used was the Santa Maria. The Santa Maria has a cargo capacity of 108 tons. The Statue of Liberty weighs 225 tons.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The largest ship on Columbus' first voyage was the Santa Mar√≠a. Its cargo capacity was estimated at about 100 tons. The Statue of Liberty, including its pedestal and foundation, weighs over 225 tons.  So, no, the Santa Mar√≠a could not haul the Statue of Liberty.

{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-80')">
            <div class="question-text">
                <div class="question-id">Question #80</div>
                Would Jolly Green Giant's largest monument look impressive next to Pyrenees?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-80">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Jolly Green Giant's largest monument look impressive next to Pyrenees?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Jolly Green Giant monument in Blue Earth, Minnesota is 55.5 feet tall. The Pyrenees mountains are 11,168 feet high. The Pyrenees mountains are 305 miles wide.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Jolly Green Giant statue in Blue Earth Minnesota is 55 feet tall.  The Pyrenees mountains have peaks that are close to 11,000 feet. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-81')">
            <div class="question-text">
                <div class="question-id">Question #81</div>
                Did Karl Marx influence the communist party of China?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-81">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Karl Marx influence the communist party of China?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Communist ideology is the foundation of communist party of China. Marx produced a political pamphlet that has since come to be commonly known as the communist manifesto.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Karl Marx is the author of the Communist Manifesto, a foundational text for communist ideology.  The Communist Party of China is explicitly a communist party.  Their ideology is rooted in Marxism-Leninism, a development of Marxist thought.  Therefore, Karl Marx's ideas were a major influence on the CCP.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a clear and logical argument for Karl Marx's influence on the Communist Party of China. There are no hallucinations or errors in the reasoning.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-82')">
            <div class="question-text">
                <div class="question-id">Question #82</div>
                Does Soylent use Pea for their source of protein?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-82">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Soylent use Pea for their source of protein?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Soylent is a meal replacement drink that offers 20mg protein. The protein in Soylent is derived from Soy.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Soylent uses soy protein, not pea protein.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Soylent uses soy protein, not pea protein, which aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-83')">
            <div class="question-text">
                <div class="question-id">Question #83</div>
                Do most religious people in Quebec refer to the Quran?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-83">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do most religious people in Quebec refer to the Quran?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Christianity is the major religion in Quebec. Christians refer to the Bible as their book of reference.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Quebec is a province in Canada. The dominant religion in Quebec is Catholicism, a branch of Christianity.  The central religious text of Christianity is the Bible. The Quran is the central religious text of Islam.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Christianity as the major religion in Quebec and the Bible as its central text, contrasting it with the Quran, which is the central text of Islam. There are no hallucinations or logical errors.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-84')">
            <div class="question-text">
                <div class="question-id">Question #84</div>
                Does Family Guy take place on the American West Coast?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-84">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Family Guy take place on the American West Coast?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Family Guy takes place in the fictional town of Quahog, Rhode Island. Rhode Island is a state on the American East Coast.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Family Guy takes place in Quahog, Rhode Island. Rhode Island is a state on the East Coast of the United States.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that Family Guy takes place in Quahog, Rhode Island, which is on the East Coast of the United States.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-85')">
            <div class="question-text">
                <div class="question-id">Question #85</div>
                Are lengths measured in metres in the UK?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-85">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are lengths measured in metres in the UK?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Metres are part of the metric system. The UK uses the metric system for measurements.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The UK uses the metric system, which includes metres for length.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-86')">
            <div class="question-text">
                <div class="question-id">Question #86</div>
                Did the first Duke of Valentinois play a key role in the Hundred Years' War?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-86">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the first Duke of Valentinois play a key role in the Hundred Years' War?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Hundred Years' War was a conflict between England and France from 1337-1453. Cesare Borgia, the son of Pope Alexander VI, was the first Duke of Valentinois. Cesare Borgia was born in 1475.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Hundred Years' War took place from 1337 to 1453.  Cesare Borgia, the first Duke of Valentinois, was born in 1475. Therefore, he could not have played a role in the Hundred Years' War.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly uses the dates of the Hundred Years' War and Cesare Borgia's birth to conclude that he could not have played a role in the war.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-87')">
            <div class="question-text">
                <div class="question-id">Question #87</div>
                Do gorillas fight with panda bears?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-87">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do gorillas fight with panda bears?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Gorilla distribution is limited to areas of the continent of Africa. Panda bears are found in the wild only in China.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Gorillas live in the forests of central Africa.  Giant pandas live in a few mountain ranges in central China. Their natural habitats do not overlap, so they would not encounter each other in the wild.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that gorillas and pandas live in different regions and therefore would not encounter each other.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-88')">
            <div class="question-text">
                <div class="question-id">Question #88</div>
                Was Christina Aguilera born in the forgotten borough?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-88">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Christina Aguilera born in the forgotten borough?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Christina Maria Aguilera was born on December 18, 1980, in Staten Island, New York. Staten Island has sometimes been called "the forgotten borough" by inhabitants who feel neglected by the city government.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Christina Aguilera was born in Staten Island, New York.  Staten Island is one of the five boroughs of New York City. While it's sometimes referred to as the "forgotten borough," it is not forgotten in the sense that it's not officially recognized.  So, she was born in NYC, in a borough sometimes jokingly called "forgotten."

{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. There are no contradictions, entity swaps, or logical errors.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-89')">
            <div class="question-text">
                <div class="question-id">Question #89</div>
                Is H's most common two letter pair partner a freebie in Wheel of Fortune bonus round?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-89">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is H's most common two letter pair partner a freebie in Wheel of Fortune bonus round?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. H forms the most common two letter pair in the English language along with the letter T. The Wheel of Fortune bonus round gives the player six free letters: R, S, T, L, N, E.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">H's most common two-letter pair partner is E, forming HE.
The free letters in the bonus round of Wheel of Fortune are R, S, T, L, N, and E.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly identifies the most common two-letter pair partner of H, which is a critical factual error.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">H's most common two-letter pair partner is E, forming HE.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that H's most common two-letter pair partner is T, not E.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">H's most common two-letter pair partner is E, forming HE</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">H forms the most common two letter pair in the English language along with the letter T</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-90')">
            <div class="question-text">
                <div class="question-id">Question #90</div>
                Can a quarter fit inside of a human kidney?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-90">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a quarter fit inside of a human kidney?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Kidney stones are hard mineral deposits that can form in the kidneys. The largest kidney stone ever recorded was 13 cm wide. The diameter of a quarter is 2.4 cm.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
A quarter has a diameter of 0.955 inches.  Human kidneys are roughly 4-5 inches long, 2-3 inches wide, and 1 inch thick. Thus a quarter can easily fit inside of a human kidney.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning is mostly correct, but contains a minor factual inaccuracy regarding the diameter of a quarter.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A quarter has a diameter of 0.955 inches.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that a quarter has a diameter of 0.955 inches, but the reference explanation states that the diameter of a quarter is 2.4 cm, which is approximately 0.94 inches. While close, it is not exact and could lead to incorrect reasoning.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">A quarter has a diameter of 0.955 inches.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The diameter of a quarter is 2.4 cm.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-91')">
            <div class="question-text">
                <div class="question-id">Question #91</div>
                Does James Webb Space Telescope fail astronomer in locating planet Krypton?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-91">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does James Webb Space Telescope fail astronomer in locating planet Krypton?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The James Webb Space Telescope is the most powerful telescope created. Krypton is a planet in the fictional Superman comic book series.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The James Webb Space Telescope is a telescope that observes space.  Krypton is a fictional planet from DC Comics, the home world of Superman.  It was destroyed before the events of most Superman stories. Fictional planets cannot be located by telescopes.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Krypton is a fictional planet and therefore cannot be located by telescopes like the James Webb Space Telescope. This aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-92')">
            <div class="question-text">
                <div class="question-id">Question #92</div>
                Was P. G. Wodehouse's favorite book The Hunger Games?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-92">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was P. G. Wodehouse's favorite book The Hunger Games?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. P. G. Wodehouse died in 1975. The Hunger Games was published in 2008.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: P.G. Wodehouse died in 1975. The Hunger Games was published in 2008.  Therefore, The Hunger Games could not have been P.G. Wodehouse's favorite book.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly uses the information provided in the reference explanation to answer the question.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-93')">
            <div class="question-text">
                <div class="question-id">Question #93</div>
                Should a finished website have lorem ipsum paragraphs?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-93">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Should a finished website have lorem ipsum paragraphs?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Lorem Ipsum paragraphs are meant to be temporary. Web designers always remove lorem ipsum paragraphs before launch.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Lorem ipsum is placeholder text used in design and publishing to occupy space where real content will eventually be.  It's used so designers can focus on the visual layout and aesthetics without being distracted by actual content. A finished website, by definition, is ready for public viewing and should have final, polished content.  Using lorem ipsum indicates the site isn't complete.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why a finished website should not have lorem ipsum paragraphs, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-94')">
            <div class="question-text">
                <div class="question-id">Question #94</div>
                Did William Shaespeare read the Daily Mirror?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-94">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did William Shaespeare read the Daily Mirror?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Daily Mirror is a British tabloid founded in 1903. William Shakespeare died in 1616.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">William Shakespeare died in 1616. The Daily Mirror was founded in 1903.  Therefore, Shakespeare could not have read The Daily Mirror.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating the relevant dates and concluding that Shakespeare could not have read the Daily Mirror.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-95')">
            <div class="question-text">
                <div class="question-id">Question #95</div>
                Will more people go in and out of Taco Bell than a Roy Rogers each year?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-95">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will more people go in and out of Taco Bell than a Roy Rogers each year?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Taco Bell has over 7,072 restaurants as of 2018. Roy Rogers had over 600 restaurants at its peak. Roy Rogers has 48 locations as of 2019.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Roy Rogers Restaurants was a chain with 220 locations in 2023.
Taco Bell is a chain with over 7000 locations in the USA.
More people would realistically visit a restaurant with 7000 locations each year.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error regarding the number of Roy Rogers locations, which contradicts the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Roy Rogers Restaurants was a chain with 220 locations in 2023.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Roy Rogers has 48 locations as of 2019. The generated reasoning states that Roy Rogers has 220 locations in 2023, which contradicts the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Roy Rogers Restaurants was a chain with 220 locations in 2023.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Roy Rogers has 48 locations as of 2019.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-96')">
            <div class="question-text">
                <div class="question-id">Question #96</div>
                Is it safe to wear sandals in snow?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-96">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it safe to wear sandals in snow?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Sandals have open toes and don't completely cover the feet. Snow is very cold and direct exposure to skin can cause hypothermia. The feet need to be completely covered to walk through snow safely.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Sandals offer very little protection from the cold and snow. They also provide no traction on icy surfaces. Wearing sandals in the snow would be uncomfortable and possibly dangerous. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that sandals offer little protection from the cold and snow and provide no traction on icy surfaces, making them unsafe to wear in the snow.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-97')">
            <div class="question-text">
                <div class="question-id">Question #97</div>
                Was Nikola Tesla's home country involved in the American Civil War?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-97">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Nikola Tesla's home country involved in the American Civil War?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Nikola Tesla was born in the Austrian Empire. The American Civil War was a domestic American conflict.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Nikola Tesla was Serbian-American. Serbia was not involved in the American Civil War.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly states that Nikola Tesla was Serbian-American, contradicting the reference explanation that he was born in the Austrian Empire. The rest of the reasoning is based on this incorrect premise.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Nikola Tesla was Serbian-American.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Nikola Tesla was born in the Austrian Empire, not that he was Serbian-American.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Serbian-American</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Austrian Empire</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-98')">
            <div class="question-text">
                <div class="question-id">Question #98</div>
                Did Ada Lovelace die tragically young for her era?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-98">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Ada Lovelace die tragically young for her era?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Ada Lovelace died at the age of 36 in 1852. The life expectancy in the 1800s was between 35 and 39 years old. Tuberculosis was one of the leading causes of death in the 1800s and a vaccine was not made until the 1900s.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Ada Lovelace died at the age of 36 in 1852.  The average life expectancy for women in England at that time was around 40-42 years. While dying at 36 is certainly younger than the average, it's not dramatically so, especially considering she died of uterine cancer, a disease that was difficult to treat effectively at the time. Therefore, while her death was undoubtedly a loss, it wasn't drastically outside the norm for her era.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning contains a factual error regarding the life expectancy in the 1800s, which contradicts the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The average life expectancy for women in England at that time was around 40-42 years.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the life expectancy in the 1800s was between 35 and 39 years old. The generated reasoning states that the average life expectancy for women in England at that time was around 40-42 years, which contradicts the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The average life expectancy for women in England at that time was around 40-42 years.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The life expectancy in the 1800s was between 35 and 39 years old.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-99')">
            <div class="question-text">
                <div class="question-id">Question #99</div>
                Can an Asian black bear use chopsticks?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-99">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can an Asian black bear use chopsticks?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Asian black bear are a species of bear found in asia.  Asian black bear don't have opposable thumbs. Chopsticks are eating utensils use requires opposable thumbs.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Asian black bears, also known as moon bears, are native to Asia and have paws, not hands.  Chopsticks require the dexterity and opposable thumbs that bears lack.  So they cannot use chopsticks.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that Asian black bears lack the dexterity and opposable thumbs required to use chopsticks.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-100')">
            <div class="question-text">
                <div class="question-id">Question #100</div>
                Can someone sell their time through the Toronto Star?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-100">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can someone sell their time through the Toronto Star?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Toronto Star has a classifieds section. Readers can advertise their own labor or services and thus their time .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">The Toronto Star is a newspaper, primarily focused on news and advertising.  While they might have classified ads for services, selling one's time in a general sense isn't something typically done through a newspaper.  One might advertise specific services (tutoring, handyman work, etc.) but not time as a commodity itself.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference by stating that selling one's time isn't typically done through a newspaper, while the reference explicitly states that readers can advertise their labor or services, thus their time, in the classifieds section.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">While they might have classified ads for services, selling one's time in a general sense isn't something typically done through a newspaper.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">This contradicts the reference, which states that readers can advertise their own labor or services and thus their time.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">selling one's time in a general sense isn't something typically done through a newspaper.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Readers can advertise their own labor or services and thus their time</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-101')">
            <div class="question-text">
                <div class="question-id">Question #101</div>
                Were deaths from Apollo 13 mission eclipsed by other space missions?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-101">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Were deaths from Apollo 13 mission eclipsed by other space missions?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Apollo 13 was a failed Moon landing in which the crew had faulty oxygen resources. All of the Apollo 13 crew returned safely to earth. The Challenger was a space shuttle that malfunctioned, killing all seven passengers. The Space Shuttle Columbia disaster had seven casualties.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Apollo 13 did not have any deaths.  The Apollo 1 mission resulted in the deaths of three astronauts.  The Space Shuttle Challenger disaster resulted in the deaths of seven astronauts. The Space Shuttle Columbia disaster also resulted in the death of seven astronauts.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The reasoning chain introduces a new entity (Apollo 1) that is not mentioned in the reference explanation. This is used to justify the answer.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Apollo 1 mission resulted in the deaths of three astronauts.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reasoning chain introduces the Apollo 1 mission, which is not mentioned in the reference explanation. This is used to justify the answer.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Apollo 1 mission</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Apollo 13</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-102')">
            <div class="question-text">
                <div class="question-id">Question #102</div>
                Can you purchase a dish with injera at Taco Bell?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-102">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you purchase a dish with injera at Taco Bell?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Taco Bell serves a variety of Mexican and Tex-Mex foods that include tacos, burritos, quesadillas, and nachos. Injera is a sour fermented flatbread with a slightly spongy texture, traditionally made out of teff flour. Injera is part of Ethiopian cuisine.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Injera is a spongy flatbread made from teff flour and is a staple in Eritrean and Ethiopian cuisine. Taco Bell is a fast food chain that specializes in Tex-Mex style cuisine.  Their menu items are typically made with tortillas, not injera.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why you cannot purchase a dish with injera at Taco Bell, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction,contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-103')">
            <div class="question-text">
                <div class="question-id">Question #103</div>
                Is xenophobia hypothetically unimportant between Saladin and Ali Askari?
            </div>
            <span class="hallucination-count ">2 issues</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-103">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is xenophobia hypothetically unimportant between Saladin and Ali Askari?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Xenophobia is the dislike of someone that is foreign or from a different background. Saladin was a Kurdish leader that became sultan of Egypt. Ali Askari was a Kurdish politician.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Saladin was a Sunni Muslim.
Ali Askari is a Shia Muslim.
Xenophobia is the fear and hatred of strangers or foreigners or of anything that is strange or foreign.
While Sunni and Shia Islam are both branches of Islam, they have historical disagreements.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces details not present in the reference to justify a false conclusion. The reference states that both individuals are Kurdish, implying a shared background that would make xenophobia unimportant. The generated reasoning introduces religious differences to argue the opposite.</div>
            </div>
            <h3>Detected Issues (2)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Saladin was a Sunni Muslim.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference does not mention Saladin's religious affiliation. The generated reasoning introduces a detail not present in the reference, and uses it to justify a false conclusion.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Saladin was a Sunni Muslim.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Saladin was a Kurdish leader that became sultan of Egypt.</div>
        </div>
        
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Ali Askari is a Shia Muslim.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference does not mention Ali Askari's religious affiliation. The generated reasoning introduces a detail not present in the reference, and uses it to justify a false conclusion.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Ali Askari is a Shia Muslim.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Ali Askari was a Kurdish politician.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-104')">
            <div class="question-text">
                <div class="question-id">Question #104</div>
                Does Sockington enjoy onions?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-104">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Sockington enjoy onions?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Sockington is a domestic cat. Onions can cause toxicity in cats by breaking down their red blood cells.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Sockington is a cat.  Cats generally dislike onions.  Onions are toxic to cats.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Sockington as a cat and states that onions are toxic to cats, leading to the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-105')">
            <div class="question-text">
                <div class="question-id">Question #105</div>
                Was Raphael's paintings influenced by the country of Guam?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-105">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Raphael's paintings influenced by the country of Guam?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Raphael was a European painter that died in 1520. Magellan's 1521 voyage was Europe's first trip to Guam.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Raphael lived from 1483 to 1520.
Guam was claimed by Spain in 1565.
Raphael died before Guam was claimed by Spain.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly deduces that Raphael's paintings were not influenced by Guam, as Raphael died before Guam was claimed by Spain, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-106')">
            <div class="question-text">
                <div class="question-id">Question #106</div>
                Could Oscar Wilde have operated a motor vehicle?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-106">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could Oscar Wilde have operated a motor vehicle?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Motor vehicles were in use by the 1890s. Oscar Wilde lived until 1900.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Oscar Wilde died in 1900.
The first gasoline-powered automobile in the US was in 1893.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain contains an irrelevant fact about the first gasoline-powered automobile in the US, which is not necessary to answer the question.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The first gasoline-powered automobile in the US was in 1893.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The location of the first gasoline-powered automobile is irrelevant to whether Oscar Wilde could have operated a motor vehicle. The reference explanation only states that motor vehicles were in use by the 1890s and that Oscar Wilde lived until 1900.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The first gasoline-powered automobile in the US was in 1893.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Motor vehicles were in use by the 1890s.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-107')">
            <div class="question-text">
                <div class="question-id">Question #107</div>
                Does ontology require a scalpel?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-107">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does ontology require a scalpel?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A scalpel is used during surgery. Ontology is a philosophical domain, not a medical one.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Ontology is the branch of metaphysics dealing with the nature of being.  A scalpel is a surgical instrument.  Surgery and metaphysics are unrelated fields.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that ontology is a philosophical domain and a scalpel is a surgical instrument, thus concluding they are unrelated.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-108')">
            <div class="question-text">
                <div class="question-id">Question #108</div>
                Was King Arthur at the beheading of Anne Boleyn?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-108">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was King Arthur at the beheading of Anne Boleyn?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. King Arthur was a legendary British leader who, according to medieval histories and romances, led the defence of Britain against Saxon invaders in the late 5th and early 6th centuries. Anne Boleyn was beheaded May 19, 1536.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Anne Boleyn was beheaded in 1536. King Arthur is a legendary figure who is believed to have lived between the late 5th and early 6th centuries. Thus, King Arthur could not have been present at Anne Boleyn's beheading.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that King Arthur could not have been at Anne Boleyn's beheading because they lived in different time periods. The reasoning is sound and consistent with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-109')">
            <div class="question-text">
                <div class="question-id">Question #109</div>
                Would Alexander Graham Bell hypothetically support Nazi eugenics?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-109">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Alexander Graham Bell hypothetically support Nazi eugenics?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Eugenics was the idea of selective breeding or sterilization to rid the human populace of certain traits. Nazis used eugenics to justify mass sterilization and mass murder. Alexander Graham Bell Alexander Graham Bell advocated against the use of sign language and hoped to eradicate deafness through selective breeding.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Alexander Graham Bell was a prominent advocate of eugenics.  Nazi eugenics, while sharing some surface similarities with other eugenics movements, was particularly focused on racial purity and involved horrific human rights abuses.  While Bell's eugenics work was problematic, it's impossible to know with certainty what his reaction would have been to the specific practices of Nazi Germany.  However, given his known views, it is plausible to suggest he might have been sympathetic to some of the underlying ideas, though hopefully not the methods employed.

{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, acknowledging Bell's advocacy for eugenics and drawing a plausible connection to the underlying ideas of Nazi eugenics, while also acknowledging the differences in methods.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-110')">
            <div class="question-text">
                <div class="question-id">Question #110</div>
                Was Harry Truman's presidency unaffected by the twenty-third Amendment to the US Constitution?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-110">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Harry Truman's presidency unaffected by the twenty-third Amendment to the US Constitution?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The 23rd Amendment to the US Constitution was passed in 1961. Harry Truman was the President from 1945-1953.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Twenty-third Amendment grants the District of Columbia electors in the Electoral College.  This amendment was ratified in 1961. Harry Truman's presidency was from 1945-1953.  Therefore, his presidency predates the amendment and would not have been affected by it.

So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-111')">
            <div class="question-text">
                <div class="question-id">Question #111</div>
                Would the trees in Auburn, New York be changing colors in September?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-111">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would the trees in Auburn, New York be changing colors in September?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In New York, fall begins during the month of September.  When the weather gets cooler in the fall, leaves begin to change colors.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Auburn, New York experiences a temperate climate with four distinct seasons.  Leaf color change, or "fall foliage," begins in September in New York state. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that leaf color change begins in September in New York state, which aligns with the reference.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-112')">
            <div class="question-text">
                <div class="question-id">Question #112</div>
                Is Black Lives Matter connected with capsaicin?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-112">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Black Lives Matter connected with capsaicin?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Black Lives Matter has held numerous protests. Protesters at Black Lives Matter events have had pepper spray used against them by police. Capsaicin is the main ingredient of pepper spray.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Black Lives Matter movement is primarily focused on addressing systemic racism and police brutality against Black people.  Capsaicin is the active component of chili peppers, causing a burning sensation. While some protesters might carry pepper spray for self-defense, which contains capsaicin, there isn't a direct or inherent connection between the Black Lives Matter movement and capsaicin itself.  {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference explanation by denying a connection between Black Lives Matter and capsaicin, despite the reference stating that pepper spray (containing capsaicin) has been used against protesters at Black Lives Matter events.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">While some protesters might carry pepper spray for self-defense, which contains capsaicin, there isn't a direct or inherent connection between the Black Lives Matter movement and capsaicin itself.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states there isn't a direct connection between Black Lives Matter and capsaicin, but the reference explanation states that protesters at Black Lives Matter events have had pepper spray used against them by police, and capsaicin is the main ingredient of pepper spray, thus establishing a connection.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">there isn't a direct or inherent connection between the Black Lives Matter movement and capsaicin itself.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Protesters at Black Lives Matter events have had pepper spray used against them by police. Capsaicin is the main ingredient of pepper spray.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-113')">
            <div class="question-text">
                <div class="question-id">Question #113</div>
                Was Achilles a direct descendent of Gaia?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-113">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Achilles a direct descendent of Gaia?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Achilles was the son of a Nereid.  The Nereids were the 50 daughters of Nereus. Nereus was the eldest son of the union between Gaia and Pontus.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Achilles was the son of Peleus and Thetis.  Peleus was the son of Aeacus, who was the son of Zeus and Aegina.  Aegina was the daughter of the river god Asopus and the river nymph Metope. Asopus was the son of Oceanus and Tethys.  Oceanus and Tethys were the children of Uranus and Gaia. Therefore, Achilles was a descendant of Gaia.
{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a significant factual error regarding Achilles' parents, contradicting the reference explanation. The rest of the reasoning is based on this initial error.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Achilles was the son of Peleus and Thetis.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Achilles was the son of a Nereid, not Peleus and Thetis.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Achilles was the son of Peleus and Thetis</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Achilles was the son of a Nereid</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-114')">
            <div class="question-text">
                <div class="question-id">Question #114</div>
                Does Jerry Seinfeld hang out at the Budweiser Party Deck?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-114">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Jerry Seinfeld hang out at the Budweiser Party Deck?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Budweiser Party Deck is a social gathering spot in Yankee Stadium. Yankee Stadium is home to the New York Yankees baseball team. Jerry Seinfeld is a fan of the New York Mets.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Jerry Seinfeld is a comedian.  The Budweiser Party Deck is at Busch Stadium, the home of the St. Louis Cardinals baseball team.  There's no readily available information connecting Seinfeld to the Budweiser Party Deck or even a particular fondness for baseball, so it would be unlikely to find him hanging out there.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a significant factual error regarding the location of the Budweiser Party Deck, which is a critical element in determining the answer.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Budweiser Party Deck is at Busch Stadium, the home of the St. Louis Cardinals baseball team.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The Budweiser Party Deck is located in Yankee Stadium, not Busch Stadium. Yankee Stadium is the home of the New York Yankees, not the St. Louis Cardinals.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Busch Stadium, the home of the St. Louis Cardinals baseball team</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Yankee Stadium. Yankee Stadium is home to the New York Yankees baseball team</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-115')">
            <div class="question-text">
                <div class="question-id">Question #115</div>
                Can you hide a basketball in a sand cat's ear?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-115">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you hide a basketball in a sand cat's ear?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The diameter of a standard NBA basketball is around 9.5 inches. A sand cat's ear grows to 2.8 inches tall.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">A sand cat is a small wild cat, about the size of a large house cat.  While their ears are proportionately large, they are still nowhere near the size of a basketball. A basketball is simply too large to fit inside a sand cat's ear.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why a basketball cannot fit in a sand cat's ear, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-116')">
            <div class="question-text">
                <div class="question-id">Question #116</div>
                Could the Spice Girls compete against ≈ΩRK Kumanovo?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-116">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could the Spice Girls compete against ≈ΩRK Kumanovo?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Spice Girls had 5 members. ≈ΩRK Kumanovo is a women's handball club from Kumanovo in the Republic of Macedonia. Handball is a sport played by two teams of seven players each.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Spice Girls are a British pop group. ≈ΩRK Kumanovo is a women's handball club. These two entities are not comparable in a competitive setting.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that the Spice Girls and ≈ΩRK Kumanovo are not comparable in a competitive setting, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-117')">
            <div class="question-text">
                <div class="question-id">Question #117</div>
                Does the swastika have positive uses?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-117">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does the swastika have positive uses?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The swastika is used in the Hindu religion to represent the sun. People practicing Hindu believe the swastika represents prosperity and good luck.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The swastika has ancient origins and was used as a symbol of good fortune and well-being in various cultures, including Hinduism, Buddhism, and Jainism, long before its association with Nazism.  While its original meaning is positive, the swastika has become irrevocably tied to the horrors of the Holocaust and Nazi ideology in the West. This makes its use extremely controversial and often interpreted as a symbol of hate, regardless of intent.
{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation, without introducing any hallucinations or contradictions.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-118')">
            <div class="question-text">
                <div class="question-id">Question #118</div>
                Was Black fly upstaged by another insect in Jeff Goldblum's 1986 film?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-118">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Black fly upstaged by another insect in Jeff Goldblum's 1986 film?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Jeff Goldnlum starred in the 1986 movie The Fly. The fly used in the movie The Fly was a common Housefly. The Black fly is most closely related to Chironomidae since they both feed on mammals.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Jeff Goldblum starred in the 1986 film "The Fly".  The antagonist/monster in the film *is* a fly. There is no other insect that upstages the fly.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning fails to recognize the Black fly as another insect in the context of the question, leading to a logical error.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">There is no other insect that upstages the fly.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the fly used in the movie was a common Housefly and that the Black fly is most closely related to Chironomidae since they both feed on mammals. This implies that the Black fly is another insect in the context of the question.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">There is no other insect that upstages the fly.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The fly used in the movie The Fly was a common Housefly. The Black fly is most closely related to Chironomidae since they both feed on mammals.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-119')">
            <div class="question-text">
                <div class="question-id">Question #119</div>
                Did Linnaeus edit Darwin's draft of Origin of Species?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-119">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Linnaeus edit Darwin's draft of Origin of Species?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Linnaeus died in 1778. Origin of Species was published in 1859.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Carl Linnaeus died in 1778.
Charles Darwin published On the Origin of Species in 1859.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation, stating the death year of Carl Linnaeus and the publication year of Darwin's Origin of Species, which correctly implies that Linnaeus could not have edited Darwin's work.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-120')">
            <div class="question-text">
                <div class="question-id">Question #120</div>
                Do all cancer patients get disability?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-120">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do all cancer patients get disability?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. All forms of cancer qualify as diagnoses that can result in disability. Disability is not determined by diagnosis, but by degree of impairment. Some cancer patients do not experience major impairment.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Disability benefits are determined based on the impact of the illness on the individual's ability to work, not solely on the diagnosis.  Not all cancers have the same impact, and some people with cancer are able to continue working.  One must apply for disability and demonstrate their inability to work due to their illness.  Therefore, simply having cancer does not guarantee disability benefits.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that disability benefits are determined by the impact of the illness on the individual's ability to work, not solely on the diagnosis. It correctly points out that not all cancers have the same impact and that some people with cancer are able to continue working. The reasoning concludes that simply having cancer does not guarantee disability benefits, which aligns with the reference.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-121')">
            <div class="question-text">
                <div class="question-id">Question #121</div>
                Did the death of Helen Palmer have a significant effect on Dr. Seuss?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-121">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the death of Helen Palmer have a significant effect on Dr. Seuss?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Dr. Seuss's real name was Theodor Geisel. Theodor Geisel was married to Helen Palmer at the time of her suicide. Theodor Geisel is quoted having said he considered suicide after the death of his wife.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Helen Palmer Geisel was the first wife of Theodor Seuss Geisel, better known as Dr. Seuss. She suffered from multiple health problems and took her own life in 1967.  Dr. Seuss was deeply affected by her death and subsequently remarried.  His second wife, Audrey Stone Dimond, is often credited with revitalizing his work.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Helen Palmer as Dr. Seuss's first wife and acknowledges the impact of her death on him.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-122')">
            <div class="question-text">
                <div class="question-id">Question #122</div>
                Can fish get Tonsillitis?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-122">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can fish get Tonsillitis?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Tonsils are a pair of soft tissue masses located at the rear of the throat. Tonsillitis is the inflammation of tonsils. Fish do not have tonsils. Tonsils are only found in mammals.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Tonsillitis is the inflammation of the tonsils, which are part of the lymphatic system in mammals. Fish have a different immune system than mammals and lack tonsils.  Therefore, they cannot get tonsillitis.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that fish cannot get tonsillitis because they lack tonsils, which are only found in mammals.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-123')">
            <div class="question-text">
                <div class="question-id">Question #123</div>
                Would it be impossible to get to Burning Man on the Mayflower?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-123">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would it be impossible to get to Burning Man on the Mayflower?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Mayflower was a seafaring vessel. Burning Man is held in Black Rock Desert. There are no bodies of water flowing into the Black Rock Desert.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Burning Man is an annual event held in the Black Rock Desert of Nevada. The Mayflower was a 17th-century ship that transported the Pilgrims to North America. The Mayflower could not traverse land, and therefore could not reach a desert in Nevada.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why it would be impossible to get to Burning Man on the Mayflower, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-124')">
            <div class="question-text">
                <div class="question-id">Question #124</div>
                Does Lupita Nyongo have citizenship in paternal Family of Barack Obama's origin country?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-124">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Lupita Nyongo have citizenship in paternal Family of Barack Obama's origin country?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Actress Lupita Nyongo has dual citizenship in Kenya and Mexico. Barack Obama's father was born in Nyang‚Äôoma Kogelo, Rachuonyo District, Kenya Colony. Barack Obama's father was a Kenyan of the Luo tribe.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Lupita Nyong'o's parents are Kenyan.  Barack Obama's paternal family is from Kenya.  Therefore, Lupita Nyong'o has citizenship in the same country as Barack Obama's paternal family.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly infers that Lupita Nyong'o has citizenship in the same country as Barack Obama's paternal family based on the provided information.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-125')">
            <div class="question-text">
                <div class="question-id">Question #125</div>
                Are there enough Jonny Cash records in the world to give one to each French citizen?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-125">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are there enough Jonny Cash records in the world to give one to each French citizen?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Johnny Cash has sold about 90 million albums. The population of France is around 66 million .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
The population of France is about 65 million.  It's highly unlikely that 65 million Johnny Cash records exist across all formats (vinyl, CD, etc.) throughout the world.  While he was popular, that number is extremely high for physical record production, especially considering many people consume music digitally now.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference explanation by stating that it's unlikely that 65 million Johnny Cash records exist, while the reference states that he has sold about 90 million albums.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">It's highly unlikely that 65 million Johnny Cash records exist across all formats (vinyl, CD, etc.) throughout the world.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that it's unlikely that 65 million Johnny Cash records exist, but the reference states that Johnny Cash has sold about 90 million albums, which is more than the population of France.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">It's highly unlikely that 65 million Johnny Cash records exist across all formats (vinyl, CD, etc.) throughout the world.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Johnny Cash has sold about 90 million albums.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-126')">
            <div class="question-text">
                <div class="question-id">Question #126</div>
                Could someone mistake the smell of your brussels sprouts for a fart?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-126">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could someone mistake the smell of your brussels sprouts for a fart?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Brussels Sprouts are cruciferous vegetables. Cruciferous vegetables have a sulfur containing chemical called glucosinolate in them. When you cook brussels sprouts, their smell intensifies.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Brussels sprouts contain sulfur-containing compounds, which break down during cooking to produce hydrogen sulfide gas.  This gas is also a component of flatulence and has a characteristic "rotten egg" smell. Therefore, it's possible that the smell of cooking Brussels sprouts could be mistaken for a fart.
{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies the presence of sulfur-containing compounds in Brussels sprouts and explains how cooking them can produce a smell similar to flatulence, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-127')">
            <div class="question-text">
                <div class="question-id">Question #127</div>
                Can Stone Cold Steve Austin apply his finisher to a mule deer?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-127">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can Stone Cold Steve Austin apply his finisher to a mule deer?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Steve Austin's finisher, The Stone Cold Stunner, involves lifting the opponent and then pulling their head down. The largest male mule deer's are around 330 pounds. Steve Austin has applied his finisher to the wrestler The Big Show. The Big Show weighs 383 pounds.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Stone Cold Steve Austin's finisher is the Stone Cold Stunner.
A mule deer is a four-legged animal.
The Stone Cold Stunner requires an opponent to be in a standing position to be performed correctly.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a logical error that misinterprets the reference facts. The reference implies that the finisher can be applied to a large opponent, and the standing position is not a requirement.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Stone Cold Stunner requires an opponent to be in a standing position to be performed correctly.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that Steve Austin has applied his finisher to the wrestler The Big Show. The Big Show weighs 383 pounds. This implies that the finisher can be applied to a large opponent, and the standing position is not a requirement.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Stone Cold Stunner requires an opponent to be in a standing position to be performed correctly.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Steve Austin has applied his finisher to the wrestler The Big Show. The Big Show weighs 383 pounds.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-128')">
            <div class="question-text">
                <div class="question-id">Question #128</div>
                Is the Joker in a healthy romantic relationship?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-128">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is the Joker in a healthy romantic relationship?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Healthy relationships are characterized by mutual trust and respect. The Joker is dating Harley Quinn. The Joker frequently abuses and talks down to Harley.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Joker, as portrayed in most iterations, is a highly unstable, chaotic, and often violent character. He is defined by his criminal insanity and lack of empathy.  Healthy romantic relationships are built on trust, respect, and mutual care, none of which are compatible with the Joker's personality and actions. He frequently manipulates and abuses those around him, including Harley Quinn, who is often portrayed as being in a relationship with him. This relationship is typically depicted as toxic and co-dependent, rather than healthy.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that the Joker is not in a healthy romantic relationship due to his abusive and manipulative behavior towards Harley Quinn, which contradicts the principles of trust, respect, and mutual care in healthy relationships.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-129')">
            <div class="question-text">
                <div class="question-id">Question #129</div>
                Is the kayak a traditional boat in New Zealand?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-129">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is the kayak a traditional boat in New Zealand?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Kayaks were developed by native peoples to hunt in northern waters of the Arctic Ocean, North Atlantic, Bering Sea and North Pacific.  New Zealand is in the Southern Hemisphere. The native Maori people of New Zealand arrived there in canoes.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The traditional boat of the MƒÅori people of New Zealand is the waka.  Kayaks are not traditionally associated with New Zealand.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation, stating that kayaks are not traditionally associated with New Zealand and that the traditional boat of the MƒÅori people is the waka.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-130')">
            <div class="question-text">
                <div class="question-id">Question #130</div>
                Did Boris Yeltsin watch the 2008 Summer Olympics?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-130">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Boris Yeltsin watch the 2008 Summer Olympics?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The 2008 Summer Olympics were held Aug 08 - 24, 2008. Boris Yeltsin died on Apr 23, 2007.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Boris Yeltsin died in 2007. The 2008 Summer Olympics were held in 2008.  Therefore, he could not have watched them.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation, leading to a correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-131')">
            <div class="question-text">
                <div class="question-id">Question #131</div>
                Did the swallow play a role in a famous film about King Arthur?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-131">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the swallow play a role in a famous film about King Arthur?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Monty Python and the Holy Grail was a famous film about King Arthur. In Monty Python and the Holy Grail, swallows are mentioned several times.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The question refers to the film *Monty Python and the Holy Grail*.  In one scene, King Arthur and his knights are confronted by a French soldier who mocks them.  One of the insults is a challenge to their supposed knowledge of swallows, specifically regarding coconut migration and their airspeed velocity. The argument is silly and nonsensical, but iconic to the film. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately describes the role of swallows in Monty Python and the Holy Grail, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction,contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-132')">
            <div class="question-text">
                <div class="question-id">Question #132</div>
                Was Michael Crichton ever in danger of flunking out of Harvard as an undergraduate?
            </div>
            <span class="hallucination-count ">2 issues</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-132">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Michael Crichton ever in danger of flunking out of Harvard as an undergraduate?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Scholastic probation or academic dismissal, sometimes known as flunking out, is the termination of students at a higher educational institution as the result of poor academic achievement. Michael Crichton obtained his bachelor's degree in biological anthropology summa cum laude in 1964. Summa cum laude is the highest distinction a person can achieve in college for academic success. Someone who achieves summa cum laude cannot have even a single semester of poor grades.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Michael Crichton felt that his professors were trying to fail him due to his writing career taking off. He then decided to submit an English paper written by George Orwell as his own.
He received a B- for the plagiarized work and graduated Harvard in 1964
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains significant factual inaccuracies and contradicts the reference explanation. It invents a scenario about Crichton plagiarizing a paper and receiving a B-, which is inconsistent with his summa cum laude graduation.</div>
            </div>
            <h3>Detected Issues (2)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Michael Crichton felt that his professors were trying to fail him due to his writing career taking off. He then decided to submit an English paper written by George Orwell as his own.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">This statement contradicts the reference explanation, which states that Michael Crichton graduated summa cum laude, the highest distinction for academic success. There is no mention of professors trying to fail him or him submitting a paper written by George Orwell.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Michael Crichton felt that his professors were trying to fail him due to his writing career taking off. He then decided to submit an English paper written by George Orwell as his own.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Michael Crichton obtained his bachelor's degree in biological anthropology summa cum laude in 1964.</div>
        </div>
        
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">He received a B- for the plagiarized work and graduated Harvard in 1964</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">This statement contradicts the reference explanation, which states that Michael Crichton graduated summa cum laude. Receiving a B- on a plagiarized paper is not consistent with graduating summa cum laude.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">He received a B- for the plagiarized work and graduated Harvard in 1964</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Michael Crichton obtained his bachelor's degree in biological anthropology summa cum laude in 1964.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-133')">
            <div class="question-text">
                <div class="question-id">Question #133</div>
                Was Surfing popular when pogs came out?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-133">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Surfing popular when pogs came out?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Pogs came out in the 1990's. The 90's saw a rise in 'Big Wave Culture', a practice involving finding the largest possible waves to surf on.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Pogs were popular in the mid-1990s. Surfing has been popular since the early to mid 20th century. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that pogs were popular in the mid-1990s and that surfing has been popular since the early to mid 20th century. This aligns with the reference explanation, which states that pogs came out in the 1990s and that the 90s saw a rise in 'Big Wave Culture', a practice involving finding the largest possible waves to surf on.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-134')">
            <div class="question-text">
                <div class="question-id">Question #134</div>
                Could a student at the University of Houston see a caracal on campus?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-134">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a student at the University of Houston see a caracal on campus?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The caracal is native to Africa, the Middle East, Central Asia, and India. The University of Houston is located in the United States. The United States is located in North America.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The University of Houston is in Texas.  Caracals are native to Africa, the Middle East, Central Asia, and India.  While a caracal might be kept as an exotic pet, it is extremely unlikely to be found roaming free on the University of Houston campus. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that caracals are not native to the University of Houston's location and are unlikely to be found there, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-135')">
            <div class="question-text">
                <div class="question-id">Question #135</div>
                Did the Coen brothers ever collaborate with the Brothers Grimm?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-135">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the Coen brothers ever collaborate with the Brothers Grimm?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Coen brothers were born in 1954 and 1957. The Brothers Grimm died in 1859 and 1863.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Coen brothers are contemporary filmmakers.  The Brothers Grimm lived from 1785-1863. Therefore, they could not have collaborated.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that the Coen brothers and the Brothers Grimm lived in different time periods, making collaboration impossible. The reasoning aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction,logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-136')">
            <div class="question-text">
                <div class="question-id">Question #136</div>
                Could a hundred thousand lolcats fit on a first generation iPhone?
            </div>
            <span class="hallucination-count ">2 issues</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-136">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a hundred thousand lolcats fit on a first generation iPhone?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Lolcat memes are often in jpeg form. The average size of a jpeg is 10 to 30 kb. One gigabyte is 1000000 kb. The first iPhone had 4GB to 16GB of storage .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A first-generation iPhone had 4GB of storage.  Let's assume an average lolcat image is 1MB (a reasonable estimate, given older image compression and resolutions). 1GB is equal to 1024MB.  So, 4GB is equal to 4096MB. Therefore, a first-generation iPhone could theoretically store about 4096 lolcats. 100,000 is significantly more than 4096.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a significant factual error regarding the size of a lolcat image, which leads to an incorrect conclusion. The reasoning is flawed due to this initial incorrect assumption.</div>
            </div>
            <h3>Detected Issues (2)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Let's assume an average lolcat image is 1MB (a reasonable estimate, given older image compression and resolutions).</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that an average lolcat image is 1MB, but the reference states that the average size of a jpeg is 10 to 30 kb. 1MB is equal to 1024 kb, so this is a contradiction.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">1MB</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">10 to 30 kb</div>
        </div>
        
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Therefore, a first-generation iPhone could theoretically store about 4096 lolcats.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">Given that the average lolcat image is assumed to be 1MB, and the iPhone has 4096MB of storage, the calculation is correct. However, since the initial assumption of 1MB is wrong, the conclusion is also wrong. The reference states that the average size of a jpeg is 10 to 30 kb, which means the iPhone could store significantly more lolcats.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">4096 lolcats</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">10 to 30 kb</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-137')">
            <div class="question-text">
                <div class="question-id">Question #137</div>
                Are monks forbidden from engaging in warfare?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-137">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are monks forbidden from engaging in warfare?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Monks are members of religious orders that usually take vows of poverty, chastity, and obedience. The Knights Templar were a religious order that fought during the Crusades and captured Jerusalem in 1099. Buddhist Shaolin monks developed very powerful martial arts skills, have defended temples during conquests.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Buddhist monks are expected to adhere to the principle of non-violence.  Many monastic orders have explicit prohibitions against participating in warfare. The concept of a "warrior monk" is more common in pop culture than in actual Buddhist practice.  While there have been historical examples of monks taking up arms (e.g., the Sohei of feudal Japan), this is generally considered an exception, not the rule. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contradicts the reference explanation by claiming that warrior monks are more common in pop culture than in reality, while the reference provides historical examples of such monks.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The concept of a "warrior monk" is more common in pop culture than in actual Buddhist practice.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">This statement contradicts the reference explanation, which provides examples of warrior monks such as the Knights Templar and Buddhist Shaolin monks who developed martial arts skills and defended temples during conquests.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The concept of a "warrior monk" is more common in pop culture than in actual Buddhist practice.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Buddhist Shaolin monks developed very powerful martial arts skills, have defended temples during conquests.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-138')">
            <div class="question-text">
                <div class="question-id">Question #138</div>
                Is the BBC World Service hosted in Europe?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-138">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is the BBC World Service hosted in Europe?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The BBC World Service is part of the BBC network. The BBC operates in England. England is part of Europe.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The BBC World Service is a division of the BBC.  The BBC is the British Broadcasting Corporation, and is headquartered in London, England. London is a city in Europe.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a clear and concise justification for the answer. There are no hallucinations or logical errors present.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-139')">
            <div class="question-text">
                <div class="question-id">Question #139</div>
                Would 1996 leap year baby technically be 1 year old in 2000?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-139">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would 1996 leap year baby technically be 1 year old in 2000?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A leap year happens once every 4 years and has 29 days in February. The years 1996, 2000, 2004, 2008, 2012, 2016, and 2020 are the last 7 leap years that have happened. 1996 to 2000 is one leap year.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A leap year baby born in 1996 would have their first birthday in 1997.  They would turn 2 in 1998, 3 in 1999, and 4 in 2000.

{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly explains why a leap year baby born in 1996 would be 4 years old in 2000.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-140')">
            <div class="question-text">
                <div class="question-id">Question #140</div>
                Did Clark Gable marry more women once than Richard Burton?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-140">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Clark Gable marry more women once than Richard Burton?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Richard Burton was married to Elizabeth Taylor twice.  Richard Burton married Sally Burton, Suzy Hunt, and Sybil Williams once. Clark Gable was married to five different women, one time each.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
Clark Gable was married five times.
Richard Burton was married twice to Elizabeth Taylor, in addition to marriages with Sybil Williams and Sally Hay.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains an entity swap, misidentifying one of Richard Burton's wives as Sally Hay instead of Sally Burton.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Richard Burton was married twice to Elizabeth Taylor, in addition to marriages with Sybil Williams and Sally Hay.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">Richard Burton was married to Sally Burton, not Sally Hay.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Sally Hay</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Sally Burton</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-141')">
            <div class="question-text">
                <div class="question-id">Question #141</div>
                Is one blast from double-barreled shotgun likely to kill all squid brains?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-141">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is one blast from double-barreled shotgun likely to kill all squid brains?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A double-barreled shotgun fires two rounds in one single blast. Squids have three brains.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A double-barreled shotgun fires two shots simultaneously or in very quick succession.  Squid have a single, centralized brain.  Even if a squid were large enough to require two shots to ensure destruction of the brain (which is unlikely, as most squid are relatively small), a double-barreled shotgun blast at close range would likely obliterate the entire squid, including the brain. Therefore, it's highly probable that one blast would be sufficient.

{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error about the number of brains a squid has, which contradicts the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Squid have a single, centralized brain.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that squids have a single brain, but the reference explanation states that squids have three brains.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Squid have a single, centralized brain.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Squids have three brains.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-142')">
            <div class="question-text">
                <div class="question-id">Question #142</div>
                Do women often need new shoes during their pregnancy?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-142">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do women often need new shoes during their pregnancy?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Pregnancy can cause swelling in the feet and legs. For safety and comfort, one needs to get new shoes if the size of their feet change.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Pregnant women often experience swelling in their feet, particularly in the later stages of pregnancy. This swelling can make their regular shoes feel tight and uncomfortable, and in some cases, they may not even be able to wear their usual size.  Therefore, many women find it necessary to purchase new shoes, often in a larger size or a wider width, to accommodate their swollen feet and maintain comfort during pregnancy. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that pregnant women often need new shoes due to swelling in their feet, which can make their regular shoes uncomfortable and necessitate purchasing larger or wider shoes.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-143')">
            <div class="question-text">
                <div class="question-id">Question #143</div>
                Are some adherents to Christianity in China historic enemies of Catholic Church?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-143">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are some adherents to Christianity in China historic enemies of Catholic Church?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Christianity in China is comprised of several different groups including: Protestants, Catholics, Evangelicals, and Orthodox Christians. Catholics have been at war with Protestants throughout history. The 1572 St. Bartholomew's Day Massacre saw thousands of Protestants killed by Catholic mobs. English Protestant rulers killed many Irish Catholics during the Reformation.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Christianity encompasses various denominations, including Protestantism and Catholicism.  Historically, there have been tensions and conflicts between different Christian denominations, including between Protestants and Catholics. Given the presence of both Protestant and Catholic communities in China, it's likely that some Chinese Christians who adhere to Protestantism might harbor historical animosity towards the Catholic Church.

{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies the historical tensions between Protestantism and Catholicism and applies this understanding to the context of Christianity in China. No hallucinations are present.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-144')">
            <div class="question-text">
                <div class="question-id">Question #144</div>
                Is Chinese successor to Chevrolet Cruze name a town far from Milan?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-144">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Chinese successor to Chevrolet Cruze name a town far from Milan?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Chinese successor to Chevrolet Cruze is the Chevrolet Monza. Monza is a city near the north of Milan.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Chinese successor to the Chevrolet Cruze is the Chevrolet Monza. Monza is a city near Milan, Italy. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. There are no hallucinations or logical errors present.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-145')">
            <div class="question-text">
                <div class="question-id">Question #145</div>
                Could the Dominican Order hypothetically defeat Blessed Gerard's order?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-145">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could the Dominican Order hypothetically defeat Blessed Gerard's order?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Dominican Order is a Catholic group of friars that several priestly vows. Blessed Gerard was the founder of the Order of St John of Jerusalem (Knights Hospitaller).  The Order of St John of Jerusalem (Knights Hospitaller) were a well trained Catholic military order that fought in the Crusades.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
The question lacks key information such as *which* order Blessed Gerard founded.  Blessed Gerard of Clairvaux founded the Knights Templar, a powerful military order. The Dominican Order is a mendicant order, focused on preaching and teaching.  A military confrontation between the two would likely favor the Knights Templar. However, "defeat" can be interpreted in multiple ways. The Dominicans might "defeat" the Templars in a theological debate, for example. Without specifying the nature of the hypothetical conflict, it's difficult to give a definitive answer.

{uncertain}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly states that Blessed Gerard of Clairvaux founded the Knights Templar, when he actually founded the Order of St John of Jerusalem (Knights Hospitaller).</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Blessed Gerard of Clairvaux founded the Knights Templar, a powerful military order.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that Blessed Gerard of Clairvaux founded the Knights Templar. However, the reference states that Blessed Gerard founded the Order of St John of Jerusalem (Knights Hospitaller).</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Blessed Gerard of Clairvaux founded the Knights Templar</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Blessed Gerard was the founder of the Order of St John of Jerusalem (Knights Hospitaller).</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-146')">
            <div class="question-text">
                <div class="question-id">Question #146</div>
                Is a pottery kiln inappropriate for use with glass blowing?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-146">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is a pottery kiln inappropriate for use with glass blowing?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Pottery kilns heat from the sides. Glass kilns heat from the top. Glass can be fused in a ceramic pottery kiln without trouble.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Pottery kilns are designed to reach temperatures suitable for firing clay, typically up to around 2300¬∞F (1260¬∞C).  Glass blowing, however, requires much higher temperatures, generally between 2400¬∞F (1315¬∞C)  and 2600¬∞F (1425¬∞C) for soft glass, and even higher for borosilicate glass. While some overlap exists, pottery kilns usually don't reach the necessary temperatures for proper glass manipulation and are not designed to handle molten glass. Their structure and heating elements are optimized for ceramics, not the rapid temperature changes and high heat required for glass blowing.

{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning provides a reasonable explanation of why pottery kilns might be considered inappropriate for glass blowing, focusing on temperature differences and design considerations. However, the reference explanation states that glass can be fused in a ceramic pottery kiln without trouble, which contradicts the generated reasoning. The generated reasoning does not contain any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-147')">
            <div class="question-text">
                <div class="question-id">Question #147</div>
                Are there enough people in the Balkans to match the population of Japan?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-147">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are there enough people in the Balkans to match the population of Japan?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. There are approximately 55 million people in the Balkans. There are more than 125 million people in Japan.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
The Balkans is a geopolitical and cultural region of southeastern Europe.  The total population of the Balkan countries is estimated to be around 55 million people. Japan, on the other hand, has a population exceeding 125 million. Therefore, the population of the Balkans is significantly less than that of Japan.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. It correctly states the approximate populations of the Balkans and Japan and concludes that the population of the Balkans is significantly less than that of Japan.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-148')">
            <div class="question-text">
                <div class="question-id">Question #148</div>
                Could Steven Spielberg send emails as a child?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-148">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could Steven Spielberg send emails as a child?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Steven Spielberg was born in 1946. Email did not become available to the general public until 1995.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Steven Spielberg was born in 1946.
Email was invented in 1971.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contains a factual error about when email was invented, which leads to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Email was invented in 1971.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that email was invented in 1971, which contradicts the reference explanation that email did not become available to the general public until 1995.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Email was invented in 1971.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Email did not become available to the general public until 1995.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-149')">
            <div class="question-text">
                <div class="question-id">Question #149</div>
                Was Charles Manson's body unwanted?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-149">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Charles Manson's body unwanted?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Charles Manson's body was debated over for so long that he had to stay on ice. Charles Manson had four people fighting over his corpse.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Charles Manson died in prison in 2017.  His grandson, Jason Freeman, claimed the body and arranged for cremation.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference by stating that Charles Manson's grandson claimed the body and arranged for cremation, while the reference states that four people were fighting over his corpse.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">His grandson, Jason Freeman, claimed the body and arranged for cremation.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that four people were fighting over Charles Manson's corpse, implying it was wanted. The generated reasoning states that his grandson claimed the body and arranged for cremation, which contradicts the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">His grandson, Jason Freeman, claimed the body and arranged for cremation.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Charles Manson had four people fighting over his corpse.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-150')">
            <div class="question-text">
                <div class="question-id">Question #150</div>
                Would a Beaver's teeth rival that of a Smilodon?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-150">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a Beaver's teeth rival that of a Smilodon?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A beaver has teeth measuring 25 mm on average. The Smilodon was a prehistoric saber-toothed tiger. The Smilodon's teeth were around 11 inches long.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Beavers have constantly growing incisors that are reinforced with iron.  Smilodons were saber-toothed cats with very large canines. While a beaver's teeth are strong for gnawing wood, they wouldn't rival the size or sharpness of a Smilodon's teeth, which were designed for killing prey.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately compares the teeth of a beaver and a Smilodon, correctly concluding that a beaver's teeth would not rival those of a Smilodon.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-151')">
            <div class="question-text">
                <div class="question-id">Question #151</div>
                Is dysphoria around one's pelvis treatable without surgery?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-151">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is dysphoria around one's pelvis treatable without surgery?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. For individuals experiencing dysphoria around having a vagina, packers can relieve symptoms. For people experiencing dysphoria about having a penis, there are tucking underwear and comfort gaffs available.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Dysphoria, including dysphoria related to one's pelvis, can be addressed through various non-surgical means.  Therapy, particularly gender-affirming therapy, can help individuals explore and cope with their feelings of dysphoria.  Other non-surgical options include hormone replacement therapy (HRT), which can alter secondary sex characteristics and potentially alleviate some dysphoria.  Additionally, some individuals find relief through clothing, binders or gaffs, padding, and other means of altering their physical presentation.  While surgery may be an option for some, it is not the only treatment, and many individuals find non-surgical approaches to be helpful.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning includes a non-surgical treatment option (HRT) that is not mentioned in the reference explanation, and is a broader treatment not specific to pelvic dysphoria.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Other non-surgical options include hormone replacement therapy (HRT), which can alter secondary sex characteristics and potentially alleviate some dysphoria.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation only mentions packers, tucking underwear, and comfort gaffs as non-surgical treatments for dysphoria around one's pelvis. HRT is not mentioned and is a broader treatment not specific to pelvic dysphoria.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">hormone replacement therapy (HRT), which can alter secondary sex characteristics and potentially alleviate some dysphoria</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">packers can relieve symptoms. For people experiencing dysphoria about having a penis, there are tucking underwear and comfort gaffs available.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-152')">
            <div class="question-text">
                <div class="question-id">Question #152</div>
                Would members of Blue Lives Matter support every element of Grand Theft Auto III?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-152">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would members of Blue Lives Matter support every element of Grand Theft Auto III?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Blue Lives Matter is a countermovement in the United States that supports police officers and law enforcement personnel. Grand Theft Auto III allows for gratuitous violence against police officers in the game.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Blue Lives Matter is a countermovement that supports police. Grand Theft Auto III is a video game where players can, among other things, commit crimes and kill police officers.  Supporting every element of the game would mean supporting the killing of police officers, which is antithetical to the Blue Lives Matter movement.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and provides a logical argument for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-153')">
            <div class="question-text">
                <div class="question-id">Question #153</div>
                Can the Dalai Lama fit in a car?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-153">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can the Dalai Lama fit in a car?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Dalai Lama is a person. Cars are designed for people to sit in them.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Dalai Lama is a human being.  Human beings can generally fit inside cars. Therefore, the Dalai Lama can likely fit in a car.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a clear and logical justification for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-154')">
            <div class="question-text">
                <div class="question-id">Question #154</div>
                Can actress Dafne Keen win the Eurovision Song Contest finals in 2020?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-154">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can actress Dafne Keen win the Eurovision Song Contest finals in 2020?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Contestants must be at least 16 years of age to compete in the finals of Eurovision Song Contest. Dafne Keen is 15 years old in 2020.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Dafne Keen is a British-Spanish actress.
The Eurovision Song Contest is an international song competition.
Winners are chosen by national juries and by televoting from people all across Europe.
Dafne Keen did not participate in the Eurovision Song Contest finals in 2020.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The reasoning chain does not provide the correct reasoning for why Dafne Keen could not participate in the Eurovision Song Contest finals in 2020. It states that she did not participate, but does not explain why.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Dafne Keen did not participate in the Eurovision Song Contest finals in 2020.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reasoning chain does not explain why Dafne Keen did not participate in the Eurovision Song Contest finals in 2020. The reference states that she was 15 years old in 2020, and contestants must be at least 16 years of age to compete in the finals.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Dafne Keen did not participate in the Eurovision Song Contest finals in 2020.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Contestants must be at least 16 years of age to compete in the finals of Eurovision Song Contest. Dafne Keen is 15 years old in 2020.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-155')">
            <div class="question-text">
                <div class="question-id">Question #155</div>
                Does United Airlines have a perfect operation record?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-155">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does United Airlines have a perfect operation record?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. An airline with a perfect operation record has no crashes or other damaging incidents. United Airlines has had over 30 crash incidents over several decades.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: United Airlines, like any major airline, has had incidents and accidents throughout its history.  A perfect operational record would mean no accidents, incidents, delays, or cancellations. This is practically impossible for an airline operating at such a large scale. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly states that United Airlines has had incidents and accidents, and that a perfect operational record is practically impossible for a large airline. This aligns with the reference explanation that United Airlines has had over 30 crash incidents, indicating it does not have a perfect operational record.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-156')">
            <div class="question-text">
                <div class="question-id">Question #156</div>
                Can United States Secretary of State do crimes in U.K. without being arrested?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-156">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can United States Secretary of State do crimes in U.K. without being arrested?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Diplomatic Immunity allows for diplomats in other countries to not be tried for their transgressions. Countries that signed the Vienna Convention on Diplomatic Relations allow for Diplomatic Immunity. All UN member states besides Palau, The Solomon Islands, and South Sudan have signed the Vienna Convention on Diplomatic Relations treaty. The U.K. is one of the original UN member nations.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The United States Secretary of State does not have diplomatic immunity in the U.K.. Even while abroad representing the U.S., they are subject to the laws of the country they are visiting.  While some courtesies might be extended, committing a crime in the U.K. would certainly put them at risk of arrest and legal proceedings there.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference explanation by stating that the United States Secretary of State does not have diplomatic immunity in the U.K..</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The United States Secretary of State does not have diplomatic immunity in the U.K..</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that the United States Secretary of State does not have diplomatic immunity in the U.K., which contradicts the reference explanation that states that diplomatic immunity allows diplomats in other countries to not be tried for their transgressions.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The United States Secretary of State does not have diplomatic immunity in the U.K..</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Diplomatic Immunity allows for diplomats in other countries to not be tried for their transgressions.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-157')">
            <div class="question-text">
                <div class="question-id">Question #157</div>
                Is myocardial infarction a brain problem?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-157">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is myocardial infarction a brain problem?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Myocardial infarction is a problem in the heart. The equivalent in the brain would be similar to a stroke.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Myocardial infarction is commonly known as a heart attack. It occurs when blood flow decreases or stops to a part of the heart, causing damage to the heart muscle.  The brain is a separate organ. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that myocardial infarction is a heart problem and not a brain problem, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-158')">
            <div class="question-text">
                <div class="question-id">Question #158</div>
                Will Chick Fil A be open on Halloween 2021?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-158">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will Chick Fil A be open on Halloween 2021?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Chick Fil A restaurants close on Sundays. Halloween 2021 falls on a Sunday.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Halloween was on a Sunday in 2021. Chick Fil A is not open on Sundays. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, leading to the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-159')">
            <div class="question-text">
                <div class="question-id">Question #159</div>
                Was  Godfrey of Bouillon an Islamaphobe?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-159">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was  Godfrey of Bouillon an Islamaphobe?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes.  Godfrey of Bouillon lead troops during the Prince's Crusade. The Prince's Crusade was an attempt by Europeans to "take back" the city of Jerusalem from Islamic hands.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Godfrey of Bouillon was a leader of the First Crusade, a military expedition by European Christians to reclaim the Holy Land from Muslim rule.  The Crusades were characterized by religious zeal and often involved violence against Muslims and Jews. While the term "Islamophobe" is a modern one, Godfrey's actions and motivations align with a fear and hatred of Islam. He participated in the siege of Jerusalem in 1099, which resulted in the massacre of Muslim and Jewish inhabitants.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, providing a clear and concise justification for the answer. There are no contradictions, entity swaps, or logical errors.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-160')">
            <div class="question-text">
                <div class="question-id">Question #160</div>
                Is an espresso likely to assuage fear?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-160">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is an espresso likely to assuage fear?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Fear raises heart rate. Caffeine raises heart rate. Coffee may also increase symptoms such as jitteriness and nausea .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Espresso contains caffeine, a stimulant. Stimulants can exacerbate anxiety and fear.  Therefore, it is unlikely to assuage fear.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that espresso contains caffeine, a stimulant, which can exacerbate anxiety and fear, making it unlikely to assuage fear.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-161')">
            <div class="question-text">
                <div class="question-id">Question #161</div>
                If you add water to rice pudding is it horchata?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-161">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">If you add water to rice pudding is it horchata?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Horchata is a drink made from soaking dry rice in water for hours, then pulverizing and straining the mixture and adding spices and sweetener. Rice pudding includes ingredients like eggs, and whole grains of cooked rice.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Horchata is a rice-based beverage, but it's made by soaking rice, sometimes with spices, then grinding it and mixing it with water, milk, and often sugar and other flavorings.  Rice pudding, on the other hand, is a sweet dessert made by cooking rice in milk or water with sugar, spices, and sometimes other ingredients like raisins or eggs. Adding water to rice pudding would just make it thinner rice pudding, not horchata.  They are different dishes with different processes.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains the difference between horchata and rice pudding, and correctly concludes that adding water to rice pudding would not make it horchata.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-162')">
            <div class="question-text">
                <div class="question-id">Question #162</div>
                Did Bill Gates achieve Latin honors?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-162">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Bill Gates achieve Latin honors?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Bill Gates left Harvard after two years. Latin honors are Latin phrases used in some colleges and universities to indicate the level of distinction with which an academic degree has been earned. You cannot earn an academic degree if you drop out of the program.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Bill Gates attended Harvard University but dropped out in 1975 to found Microsoft.  Latin honors (cum laude, magna cum laude, summa cum laude) are awarded at graduation. Since he didn't graduate, he couldn't have received them.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that Bill Gates dropped out of Harvard and therefore could not have received Latin honors, which are awarded at graduation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-163')">
            <div class="question-text">
                <div class="question-id">Question #163</div>
                Was Superhero fiction invented in the digital format?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-163">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Superhero fiction invented in the digital format?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Golden Age of comics occurred between the 1930's and the 1950's. Shatter was the first digitally drawn, commercially published comic.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Superhero fiction arose long before digital formats existed.  Comic books, the initial medium for many superheroes, were printed on paper.  Superman, for example, debuted in 1938 in Action Comics #1, a physical comic book.  The digital age came much later.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly explains why superhero fiction was not invented in the digital format, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-164')">
            <div class="question-text">
                <div class="question-id">Question #164</div>
                Are any animals in Chinese calendar Chordata?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-164">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are any animals in Chinese calendar Chordata?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The chinese zodiac based on the Chinese calendar has a number of animals including dogs and pigs. Chordata is a scientific classification of an animals phylum. The phylum of pigs is Chordata.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">The Chinese zodiac consists of 12 animals: Rat, Ox, Tiger, Rabbit, Dragon, Snake, Horse, Goat, Monkey, Rooster, Dog, and Pig.  All of these are real animals (even the mythical dragon is based on reptilian/avian forms) and belong to the Chordata phylum.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that animals in the Chinese calendar belong to the Chordata phylum, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-165')">
            <div class="question-text">
                <div class="question-id">Question #165</div>
                Was Daniel thrown into the lion's den in the New Testament?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-165">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Daniel thrown into the lion's den in the New Testament?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Book of Daniel is a book in the Old Testament of the Bible. The Bible is divided into the Old Testament and the New Testament. The New Testament focuses on four Gospels regarding the life of Jesus.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The story of Daniel in the lion's den is found in the Old Testament in the Book of Daniel, chapter 6.  The New Testament does not recount this story.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately states that the story of Daniel in the lion's den is found in the Old Testament and not the New Testament, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-166')">
            <div class="question-text">
                <div class="question-id">Question #166</div>
                Will 2020 elephant pregnancy last past next year with 4 solar eclipses?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-166">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will 2020 elephant pregnancy last past next year with 4 solar eclipses?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The gestation period of elephants are around 95 weeks. The year 2029 is the next year with 4 solar eclipses.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Elephant pregnancies last around 22 months.  A pregnancy starting in 2020 would likely end in late 2021 or early 2022. The number of solar eclipses is irrelevant to the length of an elephant's gestation. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning is mostly correct, but the slight inaccuracy in the gestation period is a minor hallucination.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Elephant pregnancies last around 22 months.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that elephant gestation is around 95 weeks, which is approximately 21.8 months. While close, 22 months is not precise and could lead to incorrect calculations. It's a minor inaccuracy but technically a contradiction.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Elephant pregnancies last around 22 months.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The gestation period of elephants are around 95 weeks.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-167')">
            <div class="question-text">
                <div class="question-id">Question #167</div>
                Does the word swastika have meaning in sanskrit?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-167">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does the word swastika have meaning in sanskrit?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In Sanskrit, the word swastika is a combination of ‚Äòsu‚Äô (meaning ‚Äògood‚Äô) and ‚Äòasti‚Äô (meaning ‚Äòto exist‚Äô). This meaning of swastika  from Sanskrit this gets translated as ‚Äòall is well.‚Äô .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The word swastika is derived from the Sanskrit word svastika, meaning "well-being" or "good luck."  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that the word swastika is derived from Sanskrit and means "well-being" or "good luck," which aligns with the reference's explanation of 'su' (meaning 'good') and 'asti' (meaning 'to exist') translating to 'all is well.'</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-168')">
            <div class="question-text">
                <div class="question-id">Question #168</div>
                Did Sony definitively win the video game war against Sega?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-168">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Sony definitively win the video game war against Sega?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Sony is the maker of the Playstation which has sold over 108 million PS4 units by March 2020. Sega's last console, the Sega Dreamcast, was discontinued in 2001. Sony Playstation competed with Sega's Dreamcast and Saturn systems in the 1990s. Sega now makes games for its former competitor, Sony, including Team Sonic Racing in 2019. At the height of the console wars, Sega Saturn sold 9.5 million units while Sony Playstation sold 102 million units.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The "console wars" between Sega and Sony (specifically, the Sega Genesis/Mega Drive and the Sony PlayStation) took place primarily in the 1990s. While Sega had early success with the Genesis, the PlayStation ultimately outsold it significantly and became the dominant console of that generation. This success cemented Sony's place in the console market and led to the demise of Sega's console business.  While Sega still exists as a software company, Sony is widely considered the victor of that particular "war."

{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation, indicating that Sony won the console war against Sega. There are no contradictions, entity swaps, or logical errors present.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-169')">
            <div class="question-text">
                <div class="question-id">Question #169</div>
                Would an ethics professor teach a class on Cezanne?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-169">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would an ethics professor teach a class on Cezanne?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Cezanne was an Impressionist painter. Aesthetics is the branch of philosophy that deals with the arts.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Cezanne was a painter.  Ethics professors teach about moral philosophy.  These are different subjects.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that ethics professors teach moral philosophy, which is different from art (Cezanne was a painter). This aligns with the reference explanation that aesthetics is the branch of philosophy dealing with the arts.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-170')">
            <div class="question-text">
                <div class="question-id">Question #170</div>
                Can a dolphin keep a diary?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-170">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a dolphin keep a diary?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A diary is a written record. Dolphins cannot write.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Dolphins are highly intelligent marine mammals, but they lack the physical dexterity needed to write, and the cognitive capacity for symbolic written language.  They also lack the concept of a "diary" as a personal record of events and thoughts. Therefore, a dolphin cannot keep a diary.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a logical error because it states that dolphins lack the cognitive capacity for symbolic written language, which is not mentioned in the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Dolphins are highly intelligent marine mammals, but they lack the physical dexterity needed to write, and the cognitive capacity for symbolic written language.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that dolphins cannot write, and the generated reasoning chain states that they lack the cognitive capacity for symbolic written language. This is a logical error because the reference explanation does not mention cognitive capacity.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Dolphins are highly intelligent marine mammals, but they lack the physical dexterity needed to write, and the cognitive capacity for symbolic written language.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Dolphins cannot write.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-171')">
            <div class="question-text">
                <div class="question-id">Question #171</div>
                Would Columbus have discovered Durian trees during his 1492 expedition?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-171">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Columbus have discovered Durian trees during his 1492 expedition?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Columbus ended up in the Americas. Durian only exists in Southeast Asia.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Christopher Columbus's 1492 expedition landed in the Americas. Durian trees are native to Southeast Asia. Therefore, Columbus would not have encountered Durian trees on his 1492 voyage.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that Columbus landed in the Americas and Durian trees are native to Southeast Asia, thus he would not have encountered them.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-172')">
            <div class="question-text">
                <div class="question-id">Question #172</div>
                Can you carry a Chrysler in a laptop bag?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-172">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you carry a Chrysler in a laptop bag?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Chrysler manufactures automobiles, which weigh several thousand pounds. Laptop bags are designed to hold laptop computers, which typically weigh under ten pounds.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: A Chrysler is a car, typically weighing thousands of pounds. A laptop bag is designed to carry small, portable electronic devices and accessories.  Cars cannot fit inside laptop bags.
{false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that a Chrysler is a car weighing thousands of pounds, while a laptop bag is designed for small electronics, making it impossible to fit a car inside.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-173')">
            <div class="question-text">
                <div class="question-id">Question #173</div>
                Has every astronaut survived their space journey?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-173">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Has every astronaut survived their space journey?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. In 1986, the space shuttle Challenger exploded during launch, killing all astronauts aboard. In 2003, the space shuttle Columbia also exploded, again killing its entire crew. Various other space flights have resulted in fatal disasters.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Space travel is inherently dangerous, and there have been accidents resulting in the loss of astronauts' lives.  Examples include the Challenger and Columbia disasters.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that space travel is dangerous and citing the Challenger and Columbia disasters as examples.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-174')">
            <div class="question-text">
                <div class="question-id">Question #174</div>
                Do members of the Supreme Court of the United States have longer terms than most senators?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-174">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do members of the Supreme Court of the United States have longer terms than most senators?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Senators, on average, serve for 10 years. Supreme Court Justices serve for their entire life. The average term for a Supreme court justice is 16 years.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Supreme Court justices are appointed for life.  Senators serve 6-year terms.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contains a factual error regarding the length of senators' terms, stating they serve 6-year terms when the reference indicates an average of 10 years.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Senators serve 6-year terms.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that senators serve for 10 years on average, not 6 years.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Senators serve 6-year terms.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Senators, on average, serve for 10 years.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-175')">
            <div class="question-text">
                <div class="question-id">Question #175</div>
                Would Dante have hypothetically placed Nostradamus in 3rd Circle of Hell?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-175">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Dante have hypothetically placed Nostradamus in 3rd Circle of Hell?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Nostradamus was a famous seer and court astrologer. Dante's 3rd Circle of Hell is reserved for gluttons. The 8th Circle of Hell is reserved for frauds. Astrology was seen as a valuable skill during Dante's lifetime. Dante places the mystic and prophet Joachim of Flora in the heaven of the sun.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
Dante's Third Circle of Hell is reserved for the Gluttonous. Nostradamus was a physician and astrologer, known for his prophecies. There's no historical record suggesting he was particularly gluttonous. Therefore, it's unlikely Dante would have placed him in the Third Circle.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Nostradamus would not be placed in the 3rd Circle of Hell, as it is reserved for the gluttonous, and there is no indication that Nostradamus was gluttonous. The reasoning aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-176')">
            <div class="question-text">
                <div class="question-id">Question #176</div>
                Was Mercedes-Benz associated with the Nazis?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-176">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Mercedes-Benz associated with the Nazis?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. During the 1930s, Mercedes-Benz produced the 770 model. The 770 was popular with Nazis, and Adolf Hitler used them as his personal vehicle.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Mercedes-Benz, then known as Daimler-Benz, used forced labor during the Nazi regime.  They profited from the Nazi regime. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Mercedes-Benz was associated with the Nazis, and provides a valid reason for this association.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-177')">
            <div class="question-text">
                <div class="question-id">Question #177</div>
                Is Disneyland Paris the largest Disney resort?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-177">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Disneyland Paris the largest Disney resort?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Disneyland Paris contains two parks, several hotels, and a shopping district. By comparison, Walt Disney World in Florida contains four parks, two waterparks, a shopping district, and many hotels. Disney World is bigger than Disneyland Paris Resort and Disneyland California Resort combined.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Disney World in Florida is the largest Disney resort.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Disney World in Florida is the largest Disney resort, which implies that Disneyland Paris is not the largest.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-178')">
            <div class="question-text">
                <div class="question-id">Question #178</div>
                Would a Rockette look odd with a moustache?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-178">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a Rockette look odd with a moustache?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Rockettes are an American dance group made up of all women. In America, it is uncommon to see a woman with a moustache.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Rockettes are a precision dance company known for their glamorous and traditionally feminine appearance.  Facial hair on women, such as a mustache, is not typically part of that aesthetic. Therefore, a Rockette with a mustache would deviate from their established image.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that a Rockette with a mustache would look odd because it deviates from their established image and the uncommonness of women with mustaches in America.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-179')">
            <div class="question-text">
                <div class="question-id">Question #179</div>
                Can a sea turtle play tennis using a tennis racket?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-179">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a sea turtle play tennis using a tennis racket?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. to play tennis, a human-like hand is needed to properly hold the tennis racket. sea turtles have flippers and not human-like hands.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Sea turtles are marine animals with flippers, not hands.  They are adapted for swimming, not manipulating tools like tennis rackets.  Therefore, a sea turtle physically cannot play tennis using a tennis racket.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that sea turtles cannot play tennis due to having flippers instead of hands.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-180')">
            <div class="question-text">
                <div class="question-id">Question #180</div>
                Did Donald Trump come up with the idea for the New York Harbor?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-180">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Donald Trump come up with the idea for the New York Harbor?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The New York Harbor is at the mouth of the Hudson River. A harbor is a sheltered body of water where boats and ships can be docked. The New York Harbor has been used since colonial era of the 1500s. Donald Trump is a failed business man and 2016 president elect. Donald Trump makes outrageous deceitful claims .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Donald Trump is a real estate developer and former President of the United States.  New York Harbor has existed for centuries, long before Donald Trump was born.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly states that the New York Harbor existed long before Donald Trump was born, aligning with the reference explanation. There are no hallucinations or errors in the reasoning.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-181')">
            <div class="question-text">
                <div class="question-id">Question #181</div>
                Would it be unusual to use paypal for drug deals?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-181">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would it be unusual to use paypal for drug deals?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Paypal prohibits the use of their platform for drugs or drug paraphernalia.  Using paypal leaves a digital footprint of any drug purchase.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Paypal transactions are monitored and can be traced.  Paypal accounts can be frozen or shut down if suspicious activity is detected. Using Paypal for drug deals would leave a clear record of the transaction and could easily be used as evidence by law enforcement. So, yes, it would be unusual and risky to use PayPal for drug deals.
{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that using PayPal for drug deals is unusual and risky due to monitoring, potential account freezes, and the creation of a clear transaction record.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-182')">
            <div class="question-text">
                <div class="question-id">Question #182</div>
                Is it safe to eat kidney?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-182">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it safe to eat kidney?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Traditional British cuisine includes "Kidney Pie", or "Steak and Kidney Pie". Kidney Pie contains kidney.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Kidney is a commonly consumed organ meat in many cultures.  When sourced from healthy animals and prepared properly, kidney can be a safe and nutritious food. However, kidneys are high in purines, which can be a concern for people with gout or kidney stones.  Additionally, like all organ meats, kidneys can accumulate toxins, so it's important to source them responsibly.

Answer: {true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning provides additional information about the safety of eating kidney, but it does not contradict the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-183')">
            <div class="question-text">
                <div class="question-id">Question #183</div>
                Do shrimp taste best when cooked for a long time?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-183">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do shrimp taste best when cooked for a long time?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Shrimp becomes tough and rubbery if cooked for a long time. The ideal texture for shrimp is soft and easily chewed.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Shrimp are delicate and easily overcooked. Overcooked shrimp become rubbery and tough, losing their delicate flavor.  Therefore, shrimp taste best when cooked briefly.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that shrimp become tough and rubbery if overcooked, and therefore taste best when cooked briefly.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-184')">
            <div class="question-text">
                <div class="question-id">Question #184</div>
                Hypothetically, will an African elephant be crushed by Hulk on its back?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-184">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Hypothetically, will an African elephant be crushed by Hulk on its back?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Hulk is a Marvel comics character. The Hulk is said to be around 8 feet tall and weigh around 1400 pounds. An African elephant can carry up to 9,000 kg, or 19,841 pounds.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Hulk's strength is incalculable and varies depending on his rage. An African elephant can weigh up to 13,000 lbs.  Even in a calm state, the Hulk can lift far more than this.  So an enraged Hulk would certainly be able to crush an elephant.
{true}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contains a factual error about the weight an African elephant can carry, which leads to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">An African elephant can weigh up to 13,000 lbs.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that an African elephant can weigh up to 13,000 lbs, but the reference states that an African elephant can carry up to 19,841 pounds.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">An African elephant can weigh up to 13,000 lbs.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">An African elephant can carry up to 9,000 kg, or 19,841 pounds.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-185')">
            <div class="question-text">
                <div class="question-id">Question #185</div>
                Does Rupert Murdoch's alma mater have more history than the USA?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-185">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Rupert Murdoch's alma mater have more history than the USA?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Rupert Murdoch's alma mater is Worcester College. Worcester College was founded in 1714. The first documented use of the term the United States of America was in a January 2, 1776 letter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Rupert Murdoch's alma mater is Worcester College, Oxford.  Worcester College, Oxford was founded in 1714. The USA declared its independence in 1776.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a logical error by misinterpreting the first documented use of the term the United States of America as the USA declaring its independence.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The USA declared its independence in 1776.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states the first documented use of the term the United States of America was in a January 2, 1776 letter. The generated reasoning misinterprets this as the USA declaring its independence in 1776.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The USA declared its independence in 1776.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The first documented use of the term the United States of America was in a January 2, 1776 letter.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-186')">
            <div class="question-text">
                <div class="question-id">Question #186</div>
                Is Saturn named after king of gods in Greek mythology?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-186">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Saturn named after king of gods in Greek mythology?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Saturn, the sixth planet from the sun is named after the Roman god Saturn. The Roman god Saturn is derived from its Greek equivalent, Kronos. The king of the gods in Greek mythology was Zeus. Kronos was Zeus's father, and was the leader of the Titans.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Saturn is named after the Roman god of agriculture and wealth, who was also associated with time and its passage.  While the Greek equivalent, Cronus, was the king of the Titans and father of Zeus (Jupiter), Saturn himself was not the king of the gods in Roman mythology (that would be Jupiter).

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Saturn is not named after the king of the gods in Greek mythology, and accurately explains the relationship between Saturn, Cronus, Zeus, and Jupiter.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-187')">
            <div class="question-text">
                <div class="question-id">Question #187</div>
                Does American Independence Day occur during autumn?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-187">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does American Independence Day occur during autumn?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Autumn runs from about September 20 to about December 20. American Independence Day is July 4, over two months before autumn begins.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: American Independence Day is celebrated on July 4th. July is a summer month.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that American Independence Day occurs in July, which is a summer month, and therefore not in autumn.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-188')">
            <div class="question-text">
                <div class="question-id">Question #188</div>
                Is Albany, Georgia the most populous US Albany?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-188">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Albany, Georgia the most populous US Albany?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Albany, Georgia had a population of 75,249 in 2018. Albany, New York had a population of 97,279 in 2018.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Albany, New York is the capital of New York state. Albany, Georgia is located in Georgia. The population of Albany, Georgia is less than 100,000. Albany, Oregon has a population of about 50,000. Albany, New York has a population over 100,000.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Albany, Georgia is not the most populous US Albany, but it introduces an irrelevant entity (Albany, Oregon) to support its reasoning.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Albany, Oregon has a population of about 50,000.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning introduces Albany, Oregon, which is not mentioned in the reference explanation. This is an entity swap to justify the reasoning.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Albany, Oregon</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Albany, Georgia</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-189')">
            <div class="question-text">
                <div class="question-id">Question #189</div>
                Are the founders of Skype from Asia?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-189">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are the founders of Skype from Asia?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Skype was created by the Niklas Zennstr√∂m and the Dane Janus Friis. Niklas Zennstr√∂m and Dane Janus Friis are from Sweden. Sweden is located in Europe, not Asia.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The founders of Skype are Niklas Zennstr√∂m, from Sweden, and Janus Friis, from Denmark.  Sweden and Denmark are in Europe, not Asia.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that the founders of Skype are from Sweden and Denmark, which are in Europe, not Asia.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-190')">
            <div class="question-text">
                <div class="question-id">Question #190</div>
                Are all Wednesdays in a year enough to read Bible 15 times?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-190">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are all Wednesdays in a year enough to read Bible 15 times?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. There are 52 Wednesdays in a year. There are 1,248 hours over all the Wednesdays in a year. The Old Testament of the Bible takes an average of 52 hours to read. The New Testament of the Bible takes an average of 18 hours to read.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer:
The Bible has about 31,102 verses.
There are 52 weeks in a year, so approximately 52 Wednesdays.
Reading the Bible 15 times would require reading 31,102 verses * 15 = 466,530 verses.
If one reads an even amount each Wednesday, that would require 466,530 verses / 52 Wednesdays = 8,971.73 verses per Wednesday.
This is a very large number of verses to read in a single day.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain introduces a non-existent fact about the number of verses in the Bible, which is not present in the reference explanation. This leads to an incorrect calculation and flawed reasoning.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Bible has about 31,102 verses.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation does not mention the number of verses in the Bible. Instead, it provides the average time to read the Old and New Testaments.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Bible has about 31,102 verses.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Old Testament of the Bible takes an average of 52 hours to read. The New Testament of the Bible takes an average of 18 hours to read.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-191')">
            <div class="question-text">
                <div class="question-id">Question #191</div>
                Did the butler Eugene Allen retire the same year a centuries-old war ended?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-191">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the butler Eugene Allen retire the same year a centuries-old war ended?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Eugene Allen was a butler at the White House for 34 years until 1986. The United Kingdom and the Kingdom of the Netherlands ended the Three Hundred and Thirty Five Years' Warnin 1986.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Eugene Allen retired in 1986.
The Hundred Years' War ended in 1453.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains an entity swap, replacing the Three Hundred and Thirty Five Years' War with the Hundred Years' War. This leads to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Hundred Years' War ended in 1453.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that the Hundred Years' War ended in 1453, but the reference explanation states that the Three Hundred and Thirty Five Years' War ended in 1986.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Hundred Years' War</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Three Hundred and Thirty Five Years' War</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-192')">
            <div class="question-text">
                <div class="question-id">Question #192</div>
                Did the writer of Christmas carol fast during Ramadan?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-192">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the writer of Christmas carol fast during Ramadan?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The writer of Christmas carol is Charles Dickens, who is a Christian.  Christians do not fast during Ramadan.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Charles Dickens wrote A Christmas Carol.
Charles Dickens was a Christian.
Christians do not observe Ramadan.
Muslims observe Ramadan.
So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Charles Dickens wrote A Christmas Carol, was a Christian, and that Christians do not observe Ramadan, leading to the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-193')">
            <div class="question-text">
                <div class="question-id">Question #193</div>
                Is entire Common Era minuscule to lifespan of some trees?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-193">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is entire Common Era minuscule to lifespan of some trees?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Common Era has lasted for over 2,000 years as of 2020. A tree named Methuselah, from California's White Mountains, is almost 5,000 years old.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Common Era encompasses approximately 2024 years.  Some trees, like bristlecone pines and giant sequoias, can live for thousands of years, far exceeding the length of the Common Era.
So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning is mostly correct but contains a minor imprecision regarding the length of the Common Era.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Common Era encompasses approximately 2024 years.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the Common Era has lasted for over 2,000 years as of 2020. The generated reasoning states that it encompasses approximately 2024 years, which is not wrong but not precise as the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Common Era encompasses approximately 2024 years.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Common Era has lasted for over 2,000 years as of 2020.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-194')">
            <div class="question-text">
                <div class="question-id">Question #194</div>
                Is Tange Sazen hypothetically an ideal choice for a secretary job?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-194">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Tange Sazen hypothetically an ideal choice for a secretary job?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Secretaries are required to type and also read copious amounts of notes. Tange Sazen is a one-eyed, one-armed swordsman in Japanese literature.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Tange Sazen is a fictional character, a one-armed swordsman.  Secretarial work generally requires typing and other administrative tasks, which would be difficult for a one-armed person, especially a swordsman likely more skilled in combat than office work.

So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Tange Sazen, being a one-armed swordsman, would not be suitable for secretarial work, which requires typing and administrative tasks. This aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-195')">
            <div class="question-text">
                <div class="question-id">Question #195</div>
                Are Brussels sprout particularly good for adrenal fatigue?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-195">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are Brussels sprout particularly good for adrenal fatigue?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Adenal fatigue is a disorder in which the body does not produce enough hormones and people get tired. Brussels sprout are foods rich in vitamin C. When stress levels rise, the adrenal glands require more Vitamin C and it is used very quickly.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Adrenal fatigue is a term for a collection of symptoms such as body aches, fatigue, nervousness, sleep disturbances and digestive problems.  It is not a medically recognized condition. Brussels sprouts are a good source of vitamin C, which some alternative medicine practitioners believe can help with adrenal fatigue. However, there is no scientific evidence that Brussels sprouts are particularly good for adrenal fatigue.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference by stating there is no scientific evidence that Brussels sprouts are good for adrenal fatigue, while the reference states they are beneficial due to their vitamin C content.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">However, there is no scientific evidence that Brussels sprouts are particularly good for adrenal fatigue.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Brussels sprouts are good for adrenal fatigue because they are rich in vitamin C, which the adrenal glands need when stressed. The generated reasoning contradicts this by saying there is no scientific evidence that Brussels sprouts are particularly good for adrenal fatigue.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">However, there is no scientific evidence that Brussels sprouts are particularly good for adrenal fatigue.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Brussels sprout are foods rich in vitamin C. When stress levels rise, the adrenal glands require more Vitamin C and it is used very quickly.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-196')">
            <div class="question-text">
                <div class="question-id">Question #196</div>
                Does Adam Sandler skip celebrating Easter?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-196">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Adam Sandler skip celebrating Easter?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Adam Sandler is Jewish. Jewish religious people do not celebrate Easter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Adam Sandler is Jewish.  Jewish people do not celebrate Easter. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that Adam Sandler is Jewish and Jewish people do not celebrate Easter.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-197')">
            <div class="question-text">
                <div class="question-id">Question #197</div>
                Does March begin on the same day of the week as February during leap years?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-197">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does March begin on the same day of the week as February during leap years?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. During normal years, February has exactly 28 days, so March begins on the same day of the week as February. However, on leap years, February has an extra day, so March begins the next day of the week from whichever day started February.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">March begins on the same day of the week as February in any year, leap or not.  A leap year just adds an extra day to February, shifting the days of the week for March and every subsequent month by one.

Answer: {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a contradiction, stating that March begins on the same day of the week as February in any year, leap or not, which is incorrect according to the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">March begins on the same day of the week as February in any year, leap or not.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that March begins on the same day of the week as February in any year, leap or not. This contradicts the reference explanation, which states that during normal years, March begins on the same day of the week as February, but on leap years, March begins the next day of the week from whichever day started February.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">March begins on the same day of the week as February in any year, leap or not.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">March begins on the same day of the week as February. However, on leap years, February has an extra day, so March begins the next day of the week from whichever day started February.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-198')">
            <div class="question-text">
                <div class="question-id">Question #198</div>
                Is Shiva's divine dance an ancient physical fitness pose?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-198">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Shiva's divine dance an ancient physical fitness pose?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. In yoga as exercise, the pose called Natarajasara represents Shiva's divine dance. This pose is new, originating in the early 20th century. Exercise is an activity that maintains physical fitness.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: Shiva's divine dance, often depicted as Nataraja, is a significant concept in Hinduism, representing the cosmic cycles of creation and destruction. While it involves a dynamic pose, it's primarily a symbolic and spiritual representation rather than a physical fitness pose in the modern sense. Although some yoga poses may draw inspiration from the Nataraja imagery, the dance itself is more of a religious and artistic expression than a workout routine. {false}
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why Shiva's divine dance is not an ancient physical fitness pose, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-cot-199')">
            <div class="question-text">
                <div class="question-id">Question #199</div>
                Was Land of Israel in possession of an Islamic empire in 16th century?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-cot-199">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Land of Israel in possession of an Islamic empire in 16th century?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Land of Israel was controlled by the Ottoman Empire in 16th century.  The religion of Ottoman Empire was Sunni Islam.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Answer: The Ottoman Empire, an Islamic empire, ruled the Land of Israel from 1516 or 1517 until 1917. The 16th century falls within this period. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation, confirming that the Land of Israel was under the control of the Ottoman Empire, an Islamic empire, during the 16th century.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
        </div>
    </div>
    
    <div class="mode-content" id="mode-dataset-0-hot" style="display: none;">
        <div class="summary-grid">
            <div class="summary-card">
                <h4>Questions Analyzed</h4>
                <div class="value">200</div>
            </div>
            <div class="summary-card">
                <h4>With Issues</h4>
                <div class="value" style="color: var(--accent-red)">68</div>
                <div class="subtitle">34.0% of questions</div>
            </div>
            <div class="summary-card">
                <h4>Total Issues Found</h4>
                <div class="value" style="color: var(--accent-yellow)">69</div>
                <div class="subtitle">0.34 per question</div>
            </div>
        </div>
        
        <h3>Issue Type Distribution</h3>
        <div class="type-distribution">
            <span class="type-badge" style="background: #e74c3c">contradiction: 35</span><span class="type-badge" style="background: #3498db">logical_error: 26</span><span class="type-badge" style="background: #9b59b6">entity_swap: 8</span>
        </div>
        
        <h3>Question Analysis</h3>
        <div class="filter-bar">
            <input type="text" class="filter-input" id="search-dataset-0-hot" 
                   placeholder="Search questions..." oninput="filterQuestions('dataset-0', 'hot')">
            <select class="filter-select" id="type-dataset-0-hot" onchange="filterQuestions('dataset-0', 'hot')">
                <option value="">All Types</option>
                <option value="contradiction">contradiction</option><option value="logical_error">logical_error</option><option value="entity_swap">entity_swap</option>
            </select>
        </div>
        
        <div class="question-list">
            
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-0')">
            <div class="question-text">
                <div class="question-id">Question #0</div>
                Is it common to see frost during some college commencements?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-0">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it common to see frost during some college commencements?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. College commencement ceremonies often happen during the months of December, May, and sometimes June.  Frost isn't uncommon to see during the month of December, as it is the winter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is it common to see <fact1>frost</fact1> during some <fact2>college commencements</fact2>?
Answer: <fact2>College commencements</fact2> typically occur in the spring, between April and June. <fact1>Frost</fact1> is less common in these months.  Therefore, it is not common to see <fact1>frost</fact1> during <fact2>college commencements</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference by omitting December as a common month for college commencements, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">College commencements typically occur in the spring, between April and June.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that college commencements often happen during December, May, and sometimes June. The generated reasoning only mentions spring months, omitting December.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">College commencements typically occur in the spring, between April and June.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">College commencement ceremonies often happen during the months of December, May, and sometimes June.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-1')">
            <div class="question-text">
                <div class="question-id">Question #1</div>
                Hydrogen's atomic number squared exceeds number of Spice Girls?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-1">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Hydrogen's atomic number squared exceeds number of Spice Girls?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Hydrogen is the first element and has an atomic number of one. To square a number, you multiply it by itself. The Spice Girls has five members.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Hydrogen's atomic number</fact1> squared exceed the <fact2>number of Spice Girls</fact2>?
Answer: <fact1>Hydrogen's atomic number</fact1> is 1.  1 squared is 1. There are <fact2>five Spice Girls</fact2>. Since 1 is less than 5, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-2')">
            <div class="question-text">
                <div class="question-id">Question #2</div>
                Would a pear sink in water?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-2">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a pear sink in water?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The density of a raw pear is about 0.59 g/cm^3. The density of water is about 1 g/cm^3. Objects only sink if they are denser than the surrounding fluid.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>pear</fact1> <fact2>sink</fact2> in <fact3>water</fact3>?
Answer: A <fact1>pear's</fact1> density is greater than the density of <fact3>water</fact3>.  Therefore, a <fact1>pear</fact1> will <fact2>sink</fact2> in <fact3>water</fact3>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly states that a pear's density is greater than water's density, leading to a false conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A pear's density is greater than the density of water.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The density of a pear is less than the density of water, not greater.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">greater than</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">0.59 g/cm^3</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-3')">
            <div class="question-text">
                <div class="question-id">Question #3</div>
                Do hamsters provide food for any animals?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-3">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do hamsters provide food for any animals?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Hamsters are prey animals. Prey animals provide food for predators.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>hamsters</fact1> provide <fact2>food</fact2> for any <fact3>animals</fact3>?
Answer: <fact1>Hamsters</fact1> are small rodents that are preyed upon by various <fact3>animals</fact3>, including snakes, birds of prey, and foxes.  These predators consume <fact1>hamsters</fact1> as a source of <fact2>food</fact2>. Therefore, the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that hamsters are prey animals and thus provide food for predators.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-4')">
            <div class="question-text">
                <div class="question-id">Question #4</div>
                Are all limbs required for jujutsu?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-4">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are all limbs required for jujutsu?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Jujutsu is a Japanese martial art that uses unarmed combat to subdue opponents. Nick Newell, a congenital amputee, got his black belt after two straight submission wins. Fighter Aaron LaPointe has succeeded in martial arts with a fully paralyzed arm.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are all <fact1>limbs</fact1> required for <fact2>jujutsu</fact2>?
Answer: <fact2>Jujutsu</fact2> involves grappling and joint manipulation.  <fact2>Jujutsu</fact2> practitioners use their <fact1>arms and legs</fact1> (i.e., <fact1>limbs</fact1>) to perform throws, holds, and locks. While adaptive <fact2>jujutsu</fact2> exists, traditional forms of <fact2>jujutsu</fact2> heavily utilize all four <fact1>limbs</fact1>. Therefore, the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contradicts the reference explanation by stating that traditional jujutsu heavily utilizes all four limbs, while the reference provides examples of successful practitioners with limb differences.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">While adaptive jujutsu exists, traditional forms of jujutsu heavily utilize all four limbs.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation provides examples of jujutsu practitioners who have succeeded without the full use of all four limbs, directly contradicting the statement that traditional forms of jujutsu heavily utilize all four limbs.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">traditional forms of jujutsu heavily utilize all four limbs</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Nick Newell, a congenital amputee, got his black belt after two straight submission wins. Fighter Aaron LaPointe has succeeded in martial arts with a fully paralyzed arm.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-5')">
            <div class="question-text">
                <div class="question-id">Question #5</div>
                Could a llama birth twice during War in Vietnam (1945-46)?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-5">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a llama birth twice during War in Vietnam (1945-46)?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The War in Vietnam (1945-46) lasted around 6 months. The gestation period for a llama is 11 months.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could a <fact1>llama</fact1> birth <fact2>twice</fact2> during <fact3>War in Vietnam (1945-46)</fact3>?
Answer: The gestation period for a <fact1>llama</fact1> is 11 months. The <fact3>War in Vietnam</fact3>, also known as the First Indochina War, lasted from <fact3>1946 to 1954</fact3>.  Since the war lasted 8 years, a <fact1>llama</fact1> could give birth multiple times during this period, certainly more than <fact2>twice</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain hallucinates the duration of the War in Vietnam, which leads to a wrong conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The War in Vietnam, also known as the First Indochina War, lasted from 1946 to 1954.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that the War in Vietnam lasted from 1946 to 1954, but the reference states that it lasted from 1945-46.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The War in Vietnam, also known as the First Indochina War, lasted from 1946 to 1954.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The War in Vietnam (1945-46)</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-6')">
            <div class="question-text">
                <div class="question-id">Question #6</div>
                Does Linus Torvalds make money off of DirectX?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-6">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Linus Torvalds make money off of DirectX?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. DirectX is a proprietary technology owned by Microsoft. Linus Torvalds is the creator and lead developer for the open-source Linux kernel. The Linux kernel is used in operating systems that are competitors of Microsoft Windows.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Linus Torvalds</fact1> make money off of <fact2>DirectX</fact2>?
Answer: <fact1>Linus Torvalds</fact1> is the creator of the Linux kernel. <fact2>DirectX</fact2> is a collection of application programming interfaces (APIs) developed by Microsoft.  Since <fact1>Linus Torvalds</fact1> is associated with Linux, an open-source operating system, and <fact2>DirectX</fact2> is a Microsoft product designed primarily for Windows, it's highly unlikely <fact1>he</fact1> makes money from <fact2>it</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-7')">
            <div class="question-text">
                <div class="question-id">Question #7</div>
                Could Brooke Shields succeed at University of Pennsylvania?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-7">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could Brooke Shields succeed at University of Pennsylvania?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Brooke Shields graduated from Princeton University. Princeton is ranked as the number 1 national college by US news. University of Pennsylvania is ranked as number 6 national college by US news. Princeton only admits around 6 percent of applicants as of 2018. University of Pennsylvania accepts around 9% of applicants as of 2018.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could <fact1>Brooke Shields</fact1> succeed at <fact2>University of Pennsylvania</fact2>?
Answer: <fact1>Brooke Shields</fact1> graduated from <fact2>Princeton University</fact2> with a Bachelor of Arts in French Literature.  <fact2>Princeton University</fact2> is a highly selective Ivy League university.  Success at one Ivy League institution suggests a high probability of success at another, such as <fact2>the University of Pennsylvania</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly uses the information provided in the reference explanation to arrive at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-8')">
            <div class="question-text">
                <div class="question-id">Question #8</div>
                Could a silverfish reach the top of the Empire State Building?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-8">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a silverfish reach the top of the Empire State Building?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Silverfish cannot fly. Animals that cannot fly can only access objects at or near ground level without mechanical assistance. The top of the Empire State Building is 	1,454 ft high.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could a <fact1>silverfish</fact1> reach the top of the <fact2>Empire State Building</fact2>?
Answer: <fact1>Silverfish</fact1> are small insects that can climb walls. The <fact2>Empire State Building</fact2> is a very tall building. While <fact1>silverfish</fact1> are capable climbers, they are unlikely to traverse the entire height of the <fact2>Empire State Building</fact2> due to the sheer distance, potential obstacles, and environmental factors. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning contains a logical error by implying that the silverfish's ability to climb walls is relevant to whether it can reach the top of the Empire State Building, while the reference explanation focuses on the silverfish's inability to fly and the height of the building.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Silverfish are small insects that can climb walls.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that silverfish cannot fly and therefore cannot reach the top of the Empire State Building without mechanical assistance. The generated reasoning states that silverfish can climb walls, but this does not mean they can climb the entire height of the Empire State Building. The reference explanation implies that the height of the building is the limiting factor, not the silverfish's ability to climb.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Silverfish are small insects that can climb walls.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Silverfish cannot fly.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-9')">
            <div class="question-text">
                <div class="question-id">Question #9</div>
                Are the majority of Reddit users familiar with the Pledge of Allegiance?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-9">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are the majority of Reddit users familiar with the Pledge of Allegiance?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. 55% of the Reddit user base comes from the United States. Congressional sessions open with the recital of the Pledge, as do many government meetings at local levels, and meetings held by many private organizations. All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are the <fact1>majority</fact1> of <fact2>Reddit users</fact2> familiar with the <fact3>Pledge of Allegiance</fact3>?
Answer: <fact3>The Pledge of Allegiance</fact3> is a patriotic oath recited by Americans, primarily in schools and at official events. While many Americans are familiar with <fact3>it</fact3>, <fact2>Reddit</fact2>'s user base is international.  A substantial portion of <fact2>Reddit users</fact2> live outside the United States and may not have been exposed to <fact3>the Pledge</fact3>.  Therefore, it is unlikely that <fact1>a majority</fact1> of <fact2>Reddit users</fact2> are familiar with <fact3>the Pledge of Allegiance</fact3>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly concludes that a majority of Reddit users are unlikely to be familiar with the Pledge of Allegiance, misinterpreting the fact that 55% of Reddit users are from the United States and the prevalence of the Pledge in US institutions.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Therefore, it is unlikely that a majority of Reddit users are familiar with the Pledge of Allegiance.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that 55% of Reddit users are from the United States. It also states that the Pledge of Allegiance is recited in schools and government meetings, implying that a significant portion of the US population is familiar with it. Therefore, it is likely that a majority of Reddit users are familiar with the Pledge of Allegiance, contradicting the generated reasoning.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Therefore, it is unlikely that a majority of Reddit users are familiar with the Pledge of Allegiance.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">55% of the Reddit user base comes from the United States. Congressional sessions open with the recital of the Pledge, as do many government meetings at local levels, and meetings held by many private organizations. All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-10')">
            <div class="question-text">
                <div class="question-id">Question #10</div>
                Do the anchors on Rede Globo speak Chinese?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-10">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do the anchors on Rede Globo speak Chinese?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Rede Globo is a Brazilian television network. The official language of Brazil is Portuguese.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do the anchors on <fact1>Rede Globo</fact1> speak <fact2>Chinese</fact2>?
Answer: <fact1>Rede Globo</fact1> is a Brazilian television network.  The primary language of Brazil is Portuguese.  Therefore, it is highly unlikely that the anchors on <fact1>Rede Globo</fact1> speak <fact2>Chinese</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Rede Globo is a Brazilian television network and that the primary language of Brazil is Portuguese, leading to the correct conclusion that it is unlikely the anchors speak Chinese.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-11')">
            <div class="question-text">
                <div class="question-id">Question #11</div>
                Can Reiki be stored in a bottle?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-11">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can Reiki be stored in a bottle?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Reiki practitioners use a technique called palm healing or hands-on healing through which a "universal energy" is said to be transferred through the palms of the practitioner to the patient in order to encourage emotional or physical healing. Medications are typically stored in pill bottles.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can <fact1>Reiki</fact1> be stored in a <fact2>bottle</fact2>?
Answer: <fact1>Reiki</fact1> is a form of energy healing.  Energy, by its nature, cannot be contained in a physical object like a <fact2>bottle</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly states that Reiki is a form of energy healing and that energy cannot be contained in a physical object like a bottle, which aligns with the reference explanation that Reiki is a technique of transferring "universal energy".</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-12')">
            <div class="question-text">
                <div class="question-id">Question #12</div>
                While viewing "Scary Movie" is the viewer likely to experience an increase in adrenaline?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-12">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">While viewing "Scary Movie" is the viewer likely to experience an increase in adrenaline?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Scary Movie is a film that is a comedy take on horror, intended to make viewers laugh but not afraid. Adrenaline is produced when a human is frightened or excited.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: While viewing "<fact1>Scary Movie</fact1>" is the viewer likely to experience <fact2>an increase in adrenaline</fact2>?
Answer: <fact1>"Scary Movie"</fact1> is a parody film designed to elicit laughter.  While some viewers may experience a slight <fact2>increase in adrenaline</fact2> due to the comedic suspense or jump scares, the primary physiological response would likely be related to amusement rather than fear. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning introduces the possibility of adrenaline increase due to comedic suspense or jump scares, which contradicts the reference's statement that the movie is intended to make viewers laugh but not afraid.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">While some viewers may experience a slight increase in adrenaline due to the comedic suspense or jump scares, the primary physiological response would likely be related to amusement rather than fear.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that adrenaline is produced when a human is frightened or excited, and that Scary Movie is intended to make viewers laugh but not afraid. The generated reasoning suggests that viewers may experience a slight increase in adrenaline due to comedic suspense or jump scares, which contradicts the reference's intention that the movie is not intended to frighten viewers.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">While some viewers may experience a slight increase in adrenaline due to the comedic suspense or jump scares, the primary physiological response would likely be related to amusement rather than fear.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">intended to make viewers laugh but not afraid. Adrenaline is produced when a human is frightened or excited.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-13')">
            <div class="question-text">
                <div class="question-id">Question #13</div>
                Would Marvel's Gateway be envious of the Doctor (Doctor Who)'s TARDIS machine?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-13">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Marvel's Gateway be envious of the Doctor (Doctor Who)'s TARDIS machine?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Doctor (Doctor Who) used the TARDIS, a largely unreliable time traveling machine, to travel through time and space. Gateway is a Marvel comic character linked to the X-Men comics. Gateway has the power to create wormholes that allow him to travel through time and space.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>Marvel's Gateway</fact1> be envious of the <fact2>Doctor (Doctor Who)'s TARDIS</fact2> machine?
Answer: <fact1>Gateway</fact1> is a Marvel character who can create portals to teleport himself and others across vast distances. The <fact2>TARDIS</fact2> is a time machine and spacecraft that is much larger on the inside than it appears on the outside, and can travel through time and space.  Since <fact1>Gateway's</fact1> powers are limited to teleportation, it is plausible that he would be envious of the <fact2>TARDIS's</fact2> time travel and significantly more advanced technology. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly limits Gateway's powers, leading to a flawed conclusion. It misinterprets the reference information about Gateway's ability to travel through time and space.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Since Gateway's powers are limited to teleportation, it is plausible that he would be envious of the TARDIS's time travel and significantly more advanced technology.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Gateway can travel through time and space using wormholes, not just teleportation. The generated reasoning incorrectly limits Gateway's powers to teleportation only, leading to the flawed conclusion that he would be envious of the TARDIS's time travel capabilities.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Since Gateway's powers are limited to teleportation</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Gateway has the power to create wormholes that allow him to travel through time and space.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-14')">
            <div class="question-text">
                <div class="question-id">Question #14</div>
                Is material from an aloe plant sometimes enclosed in petroleum-derived products?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-14">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is material from an aloe plant sometimes enclosed in petroleum-derived products?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Aloe vera gel is sometimes kept in plastic packaging. Plastic packaging is derived from petroleum.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>material</fact1> from an <fact2>aloe plant</fact2> sometimes enclosed in <fact3>petroleum-derived products</fact3>?
Answer: <fact2>Aloe</fact2> vera gel is often sold in <fact3>plastic bottles</fact3>. <fact3>Plastic</fact3> is a <fact3>petroleum-derived product</fact3>. Therefore, <fact1>aloe vera gel</fact1>, a <fact1>material from an aloe plant</fact1>, is sometimes enclosed in <fact3>petroleum-derived products</fact3>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, providing a clear and logical justification for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-15')">
            <div class="question-text">
                <div class="question-id">Question #15</div>
                Could a bee hummingbird balance a scale with a single pea on it?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-15">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a bee hummingbird balance a scale with a single pea on it?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The average pea weighs between 0.1 and 0.36 grams. Female bee hummingbirds on average weigh 2.6 grams, while on average male bee hummingbirds weigh 1.95 grams.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could a <fact1>bee hummingbird</fact1> balance a scale with a <fact2>single pea</fact2> on it?
Answer: A <fact1>bee hummingbird</fact1> weighs less than a <fact2>single pea</fact2>.  Therefore, it could not balance a scale with a pea on the other side. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error that contradicts the reference explanation. The reasoning is based on the incorrect premise that a bee hummingbird weighs less than a pea.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A bee hummingbird weighs less than a single pea.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that bee hummingbirds weigh between 1.95 and 2.6 grams, while a pea weighs between 0.1 and 0.36 grams. Therefore, a bee hummingbird weighs more than a pea, not less.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">A bee hummingbird weighs less than a single pea.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Female bee hummingbirds on average weigh 2.6 grams, while on average male bee hummingbirds weigh 1.95 grams. The average pea weighs between 0.1 and 0.36 grams.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-16')">
            <div class="question-text">
                <div class="question-id">Question #16</div>
                Would a broadcast from Spirit make the news in 2020?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-16">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a broadcast from Spirit make the news in 2020?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In 2010, the Spirit rover sent what is recorded as its final transmission. In 2019, another rover made the news with its viral "final words".</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>broadcast from Spirit</fact1> make the <fact2>news</fact2> in <fact3>2020</fact3>?
Answer: <fact1>Spirit</fact1> is the Mars Exploration Rover that landed on Mars in 2004.  Communication with <fact1>Spirit</fact1> ceased in 2009. If there was a <fact1>broadcast from Spirit</fact1> in <fact3>2020</fact3>, it would definitely make the <fact2>news</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain contains a factual error regarding the year of Spirit's final transmission. The reference states 2010, while the generated reasoning states 2009.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Communication with Spirit ceased in 2009.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the final transmission from Spirit was in 2010, not 2009.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Communication with Spirit ceased in 2009.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">In 2010, the Spirit rover sent what is recorded as its final transmission.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-17')">
            <div class="question-text">
                <div class="question-id">Question #17</div>
                Would characters in Harry Potter and the Philosopher's Stone be persecuted as pagans?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-17">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would characters in Harry Potter and the Philosopher's Stone be persecuted as pagans?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Pagans are defined as people that hold beliefs other than those of the major world religions (Christianity, Islam, and Judaism). The characters in Harry Potter and the Philosopher's Stone practice magic. Islam explicitly forbid the practice of magic and has harsh consequences for it. Jezebel in Hebrew scripture was a worshiper of pagan Baal and was thrown from a window for her beliefs. Women accused of being witches were burned alive by Christians during the Salem Witch Trials.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would characters in <fact1>Harry Potter and the Philosopher's Stone</fact1> be persecuted as <fact2>pagans</fact2>?
Answer: <fact2>Paganism</fact2> often involves magic and nature worship.  The magic practiced in <fact1>Harry Potter and the Philosopher's Stone</fact1> is a core element of the world. Characters interact with magical creatures and perform spells. Some might consider this similar to <fact2>pagan</fact2> practices. However, the characters are not explicitly identified as <fact2>pagans</fact2>, and the wizarding world exists alongside the "Muggle" world, which is largely Christian. While the magical elements might be seen as "pagan" by some, there isn't a clear persecution of wizards *because* they're <fact2>pagan</fact2> within the context of the book.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning fails to recognize that the practice of magic is considered pagan and that throughout history, pagans have been persecuted for their beliefs. It incorrectly concludes that there is no clear persecution of wizards in the context of the book.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">However, the characters are not explicitly identified as pagans, and the wizarding world exists alongside the "Muggle" world, which is largely Christian. While the magical elements might be seen as "pagan" by some, there isn't a clear persecution of wizards *because* they're pagan within the context of the book.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explains that practicing magic is explicitly forbidden in Islam and that throughout history, people who practiced magic or were accused of witchcraft were persecuted. The generated reasoning states that there isn't a clear persecution of wizards because they're pagan within the context of the book, which is a misinterpretation of the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">there isn't a clear persecution of wizards *because* they're pagan within the context of the book</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Islam explicitly forbid the practice of magic and has harsh consequences for it. Jezebel in Hebrew scripture was a worshiper of pagan Baal and was thrown from a window for her beliefs. Women accused of being witches were burned alive by Christians during the Salem Witch Trials.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-18')">
            <div class="question-text">
                <div class="question-id">Question #18</div>
                Can music be used as a weapon?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-18">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can music be used as a weapon?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Music is an art form whose medium is sound. Music can help elevate or subdue emotions. People connect to music through the sound. The military uses loud music to cause psychological disorientation and confusion . The military calls the use of loud disorienting music part of psychological operations.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can <fact1>music</fact1> be used as a <fact2>weapon</fact2>?
Answer: <fact1>Music</fact1> can be used as a form of psychological torture.  Loud, jarring, or repetitive <fact1>music</fact1> has been used in interrogations and as a means of crowd dispersal.  Therefore, since <fact1>music</fact1> can be used to inflict harm or achieve a strategic advantage, it can be considered a <fact2>weapon</fact2> in certain contexts.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that music can be used as a weapon, aligning with the reference explanation. The reasoning provided is consistent with the reference.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-19')">
            <div class="question-text">
                <div class="question-id">Question #19</div>
                Can Harry Potter book a flight on Asiana Airlines?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-19">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can Harry Potter book a flight on Asiana Airlines?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Asiana Airlines is the second largest airline in South Korea. Harry Potter is a fictional character.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can <fact1>Harry Potter</fact1> book a flight on <fact2>Asiana Airlines</fact2>?
Answer: <fact1>Harry Potter</fact1> is a fictional character. <fact2>Asiana Airlines</fact2> is a real airline. Fictional characters cannot book real flights. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Harry Potter is fictional and Asiana Airlines is real, leading to the correct conclusion that Harry Potter cannot book a flight on Asiana Airlines. The reasoning aligns perfectly with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-20')">
            <div class="question-text">
                <div class="question-id">Question #20</div>
                Karachi was a part of Alexander the Great's success?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-20">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Karachi was a part of Alexander the Great's success?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Karachi is a city in modern day Pakistan. Krokola was an ancient port located in what is now Karachi. Alexander the Great stationed his fleet in Krokola on his way to Babylon. Alexander the Great defeated Darius and conquered Babylon before expanding his empire.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Karachi</fact1> a part of <fact2>Alexander the Great's</fact2> success?
Answer: <fact1>Karachi</fact1> was founded in 1729. <fact2>Alexander the Great</fact2> died in 323 BCE. Since 1729 CE is after 323 BCE, <fact1>Karachi</fact1> could not have been a part of <fact2>Alexander the Great's</fact2> success.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error about the founding date of Karachi, which contradicts the reference explanation. This error leads to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Karachi was founded in 1729.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that Karachi was founded in 1729. However, the reference states that Krokola, an ancient port located in what is now Karachi, existed during the time of Alexander the Great.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Karachi was founded in 1729</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Krokola was an ancient port located in what is now Karachi</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-21')">
            <div class="question-text">
                <div class="question-id">Question #21</div>
                Was Jackson Pollock trained by Leonardo da Vinci?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-21">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Jackson Pollock trained by Leonardo da Vinci?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Leonardo lived during the Italian Renaissance in the 17th century. Jackson Pollock lived during the 20th century.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Jackson Pollock</fact1> trained by <fact2>Leonardo da Vinci</fact2>?
Answer: <fact1>Jackson Pollock</fact1> (1912‚Äì1956) was an American painter. <fact2>Leonardo da Vinci</fact2> (1452‚Äì1519) was an Italian Renaissance artist. Given the gap in their lifespans, <fact1>Jackson Pollock</fact1> could not have been trained by <fact2>Leonardo da Vinci</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contains a factual error regarding the time period in which Leonardo da Vinci lived, misattributing him to the 17th century instead of the 15th/16th century.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Leonardo lived during the Italian Renaissance in the 17th century.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Leonardo lived in the 15th/16th century, not the 17th century.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">17th century</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">17th century</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-22')">
            <div class="question-text">
                <div class="question-id">Question #22</div>
                Will The Exorcist stimulate limbic system?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-22">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will The Exorcist stimulate limbic system?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The limbic system of the brain contains regions that detect fear, control bodily functions and perceive sensory information. The Exorcist has been called one of the scariest movies of all time. The Exorcist ranked number 3 on the American Film Institute's 100 Years/100 Thrills list.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Will <fact1>The Exorcist</fact1> stimulate the <fact2>limbic system</fact2>?
Answer: <fact1>The Exorcist</fact1> is a horror film. Horror films are designed to evoke strong emotional responses, including fear and disgust. The <fact2>limbic system</fact2> is involved in processing emotions. Therefore, watching <fact1>The Exorcist</fact1> is likely to stimulate the <fact2>limbic system</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly infers that The Exorcist will stimulate the limbic system based on its nature as a horror film designed to evoke strong emotional responses, which aligns with the reference explanation that the limbic system is involved in processing emotions and detecting fear.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-23')">
            <div class="question-text">
                <div class="question-id">Question #23</div>
                Would World War II have been the same without Alan Turing?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-23">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would World War II have been the same without Alan Turing?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. During WW2, the German Military used something called the Engima device to send messages secretly.  Alan Turing broke the Enigma code, allowing German messages to be understood and intercepted.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>World War II</fact1> have been the same without <fact2>Alan Turing</fact2>?
Answer: <fact2>Alan Turing</fact2> was a British mathematician and computer scientist who played a crucial role in breaking the German Enigma code during <fact1>World War II</fact1>. This breakthrough significantly impacted the Allied war effort, allowing them to anticipate German movements and strategies.  Therefore, it's highly unlikely that <fact1>World War II</fact1> would have been the same without <fact2>Alan Turing's</fact2> contributions.  His code-breaking work is widely credited with shortening the war and saving countless lives. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, highlighting Alan Turing's crucial role in breaking the Enigma code during World War II and its impact on the Allied war effort. There are no contradictions, entity swaps, or logical errors.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-24')">
            <div class="question-text">
                <div class="question-id">Question #24</div>
                Would a sophist use an √©p√©e?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-24">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a sophist use an √©p√©e?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A sophist is a specific kind of teacher in ancient Greece, in the fifth and fourth centuries BC. Sophists specialized in using the tools of philosophy and rhetoric, though other sophists taught subjects such as music, athletics and mathematics. An √©p√©e is a sword used in fencing. The √©p√©e was not developed until the 19th century.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>sophist</fact1> use an <fact2>√©p√©e</fact2>?
Answer: <fact1>Sophists</fact1> were ancient Greek teachers of rhetoric and philosophy.  An <fact2>√©p√©e</fact2> is a fencing sword.  <fact1>Sophists</fact1> existed centuries before the invention of the <fact2>√©p√©e</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-25')">
            <div class="question-text">
                <div class="question-id">Question #25</div>
                Did Dale Jr hug his dad after their last Daytona 500 together?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-25">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Dale Jr hug his dad after their last Daytona 500 together?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Dale Jr. and his father Dale Sr. last raced together at the Daytona 500 in 2001. During the 2001 Daytona 500 Dale Sr. suffered a basilar skull fracture and died.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Dale Jr.</fact1> hug his dad after their <fact2>last Daytona 500</fact2> together?
Answer: <fact1>Dale Earnhardt Jr.'s</fact1> father, Dale Earnhardt Sr., died in a crash on the last lap of the 2001 Daytona 500. This was their <fact2>last Daytona 500</fact2> together.  Since <fact1>Dale Jr.'s</fact1> dad died during the race, they could not have hugged after. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that Dale Earnhardt Sr. died in a crash during the 2001 Daytona 500, which was their last race together, thus they could not have hugged after the race.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-26')">
            <div class="question-text">
                <div class="question-id">Question #26</div>
                Can citrus grow in Ulaanbaatar?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-26">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can citrus grow in Ulaanbaatar?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Citrus can withstand short periods down to as cold as ‚àí10 ¬∞C (14 ¬∞F), but realistically temperatures not falling below ‚àí2 ¬∞C (28 ¬∞F) are required for successful cultivation. Ulaanbaatar has an average annual temperature of ‚àí0.4 ¬∞C or 31.3 ¬∞F.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can <fact1>citrus</fact1> grow in <fact2>Ulaanbaatar</fact2>?
Answer: <fact1>Citrus trees</fact1> require a warm climate. <fact2>Ulaanbaatar</fact2> has a subarctic climate with very cold winters, making it unsuitable for <fact1>citrus cultivation</fact1>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that citrus trees require a warm climate and that Ulaanbaatar's subarctic climate is unsuitable for citrus cultivation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-27')">
            <div class="question-text">
                <div class="question-id">Question #27</div>
                Does New York Harbor sit on a craton without volcanic activity?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-27">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does New York Harbor sit on a craton without volcanic activity?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. New York Harbor is located on Laurentia craton.  The southwestern portion of Laurentia contains numerous large volcanic eruptions.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>New York Harbor</fact1> sit on a <fact2>craton</fact2> <fact3>without volcanic activity</fact3>?
Answer: <fact1>New York Harbor</fact1> is located on the North American <fact2>craton</fact2>. <fact2>Cratons</fact2> are generally stable and <fact3>lack volcanic activity</fact3>.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly claims that cratons generally lack volcanic activity, contradicting the reference explanation which states that the southwestern portion of Laurentia contains numerous large volcanic eruptions.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Cratons are generally stable and lack volcanic activity.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the southwestern portion of Laurentia contains numerous large volcanic eruptions, contradicting the statement that cratons lack volcanic activity.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Cratons are generally stable and lack volcanic activity.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The southwestern portion of Laurentia contains numerous large volcanic eruptions.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-28')">
            <div class="question-text">
                <div class="question-id">Question #28</div>
                Can the Palace of Westminster tell time in the dark?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-28">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can the Palace of Westminster tell time in the dark?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Palace of Westminster has Big Ben, a striking clock tower. Big Ben communicates the time via bells.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can the <fact1>Palace of Westminster</fact1> tell time in the <fact2>dark</fact2>?
Answer: The <fact1>Palace of Westminster</fact1> houses the iconic clock tower, Big Ben.  Big Ben, and the clock within it, are illuminated at <fact2>night</fact2>. Therefore, the <fact1>Palace of Westminster</fact1> *can* tell time in the <fact2>dark</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces the concept of illumination, which is not mentioned in the reference. The reference states that Big Ben communicates the time via bells.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Big Ben, and the clock within it, are illuminated at night.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Big Ben communicates the time via bells, not by illumination. The generated reasoning introduces the concept of illumination, which is not mentioned in the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Big Ben, and the clock within it, are illuminated at night.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Big Ben communicates the time via bells.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-29')">
            <div class="question-text">
                <div class="question-id">Question #29</div>
                In teenagers and young adults with depression, are SSRI medications less safe than they are for adults?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-29">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">In teenagers and young adults with depression, are SSRI medications less safe than they are for adults?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In teens, SSRI medications may increase the risk of suicidal thinking. In adults over 25, SSRI medications are regarded as generally safe.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: In <fact1>teenagers and young adults</fact1> with <fact2>depression</fact2>, are <fact3>SSRI medications</fact3> less <fact4>safe</fact4> than they are for <fact5>adults</fact5>?

Answer:  SSRIs carry a black box warning for <fact1>children, adolescents, and young adults</fact1> due to an increased risk of suicidal thoughts and behaviors. While <fact3>SSRIs</fact3> can be effective in treating <fact2>depression</fact2> in these age groups, they require careful monitoring. The increased risk does not necessarily make them categorically "less <fact4>safe</fact4>" for <fact1>younger individuals</fact1> compared to <fact5>older adults</fact5>, but it does highlight the need for increased vigilance and a different risk/benefit assessment than when prescribing to <fact5>adults</fact5>.  So, while they are not strictly less safe in terms of other side effects, the increased risk of suicidality in <fact1>younger patients</fact1> requires considering them differently in terms of <fact4>safety</fact4>.  The answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, highlighting the increased risk of suicidal thoughts and behaviors in younger individuals taking SSRIs compared to adults. It correctly emphasizes the need for careful monitoring and a different risk/benefit assessment.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-30')">
            <div class="question-text">
                <div class="question-id">Question #30</div>
                Does Marco Rubio have a close relationship with Allah?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-30">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Marco Rubio have a close relationship with Allah?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Marco Rubio adheres to the religious sect of Christianity known as Catholicism. Catholics and other Christians worship God. Allah is worshiped by believers of Islam.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Marco Rubio</fact1> have a close relationship with <fact2>Allah</fact2>?
Answer: <fact2>Allah</fact2> is the Arabic word for God. <fact1>Marco Rubio</fact1> is a practicing Catholic.  Catholicism is a Christian religion. While both Christianity and Islam are Abrahamic religions that believe in one God, they have different theological interpretations. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly explains why Marco Rubio does not have a close relationship with Allah, based on his Catholic faith and the distinct theological differences between Christianity and Islam.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-31')">
            <div class="question-text">
                <div class="question-id">Question #31</div>
                Would Persephone be a good consultant to a landscape architect?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-31">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Persephone be a good consultant to a landscape architect?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Persephone is a vegetation goddess.  A vegetation deity is a nature deity whose disappearance and reappearance, or life, death and rebirth, embodies the growth cycle of plants. Landscape architects deal with planning and laying out gardens and other plant life.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>Persephone</fact1> be a good consultant to a <fact2>landscape architect</fact2>?
Answer: In Greek mythology, <fact1>Persephone</fact1> is the goddess of spring growth.  A <fact2>landscape architect</fact2> designs outdoor spaces, often incorporating plants.  Given <fact1>Persephone's</fact1> association with vegetation and the cycle of seasons, she would likely have significant knowledge about plants and their growth, making her a potentially valuable consultant to a <fact2>landscape architect</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, providing a logical justification for why Persephone would be a good consultant to a landscape architect.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-32')">
            <div class="question-text">
                <div class="question-id">Question #32</div>
                Is Argon near Neon on the periodic table of elements?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-32">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Argon near Neon on the periodic table of elements?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Argon is a noble gas. Neon is a noble gas.  The noble gases are all clumped together on the periodic table of elements.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>Argon</fact1> near <fact2>Neon</fact2> on the <fact3>periodic table of elements</fact3>?
Answer:  <fact1>Argon (Ar)</fact1> and <fact2>Neon (Ne)</fact2> are both in Group 18 (noble gases) of the <fact3>periodic table</fact3>.  <fact2>Neon</fact2> is in period 2, while <fact1>Argon</fact1> is in period 3, placing them adjacent to one another in the same column. Therefore, the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why Argon and Neon are near each other on the periodic table, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-33')">
            <div class="question-text">
                <div class="question-id">Question #33</div>
                Did Thomas Greenhill's parents violate the concept of monogamy?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-33">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Thomas Greenhill's parents violate the concept of monogamy?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Thomas Greenhill was a surgeon born to William and Elizabeth Greenhill. William and Elizabeth Greenhill had 39 children. Monogamy is a committed relationship between two people where usually they remain together for life. Thomas Greenhill was the last of his parents 39 children and was born shortly after his father died.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Thomas Greenhill's parents</fact1> violate the concept of <fact2>monogamy</fact2>?
Answer: <fact2>Monogamy</fact2> is defined as the state of being married to one person at a time. <fact1>Thomas Greenhill</fact1> was an illegitimate child, therefore <fact1>his parents</fact1> were not married. Since <fact1>his parents</fact1> were not married, the concept of <fact2>monogamy</fact2> does not apply. Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain incorrectly states that Thomas Greenhill was an illegitimate child, contradicting the reference explanation. This leads to a flawed conclusion about monogamy not applying to his parents.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Thomas Greenhill was an illegitimate child, therefore his parents were not married.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Thomas Greenhill was born to William and Elizabeth Greenhill, implying they were married and that he was not illegitimate.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Thomas Greenhill was an illegitimate child, therefore his parents were not married.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Thomas Greenhill was a surgeon born to William and Elizabeth Greenhill.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-34')">
            <div class="question-text">
                <div class="question-id">Question #34</div>
                Would it be uncommon for a high schooler to use the yellow pages?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-34">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would it be uncommon for a high schooler to use the yellow pages?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. High school students are between 14-19 years old.  Teenagers now are considered 'digital natives'.  'Digital natives' are individuals who have grown up during the computer age, being exposed to technology from early childhood.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would it be <fact1>uncommon</fact1> for a <fact2>high schooler</fact2> to use the <fact3>yellow pages</fact3>?
Answer: <fact3>Yellow pages</fact3> are primarily used to find business contact information.  <fact2>High schoolers</fact2> today primarily use the internet for information searches. Therefore, it would be <fact1>uncommon</fact1> for a <fact2>high schooler</fact2> to use the <fact3>yellow pages</fact3>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that high schoolers primarily use the internet for information searches, making it uncommon for them to use the yellow pages. This aligns with the reference explanation that teenagers are 'digital natives' and exposed to technology from early childhood.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-35')">
            <div class="question-text">
                <div class="question-id">Question #35</div>
                Could an escapee swim nonstop from Alcatraz island to Siberia?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-35">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could an escapee swim nonstop from Alcatraz island to Siberia?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Alcatraz Island was a San Francisco Bay prison. Siberia is over 5,217 miles away from San Francisco. The longest continuous swim record was 139 miles.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could an <fact1>escapee</fact1> swim <fact2>nonstop</fact2> from <fact3>Alcatraz island</fact3> to <fact4>Siberia</fact4>?
Answer: <fact3>Alcatraz Island</fact3> is located in the San Francisco Bay, off the coast of California.  <fact4>Siberia</fact4> is located in Northeast Asia, separated from Alaska by the Bering Strait.  The Pacific Ocean lies between <fact3>Alcatraz</fact3> and <fact4>Siberia</fact4>.  It is physically impossible for a human to swim <fact2>nonstop</fact2> across the Pacific Ocean, even for a hypothetical <fact1>escapee</fact1>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why it is impossible to swim from Alcatraz to Siberia, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-36')">
            <div class="question-text">
                <div class="question-id">Question #36</div>
                Would the Titanic be well preserved at the bottom of the Gulf of Finland?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-36">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would the Titanic be well preserved at the bottom of the Gulf of Finland?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The bottom of the gulf is one of the world's largest ship cemeteries. Because of the low salinity and cold waters, and no shipworms, the ships are relatively well preserved. RMS Titanic was a British passenger ship.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would the <fact1>Titanic</fact1> be well preserved at the bottom of the <fact2>Gulf of Finland</fact2>?
Answer: The <fact1>Titanic</fact1> sank in the Atlantic Ocean. The <fact2>Gulf of Finland</fact2> is part of the Baltic Sea.  Since the <fact1>Titanic</fact1> is not in the <fact2>Gulf of Finland</fact2>, it cannot be well preserved there.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that the Titanic is not in the Gulf of Finland, and therefore cannot be well-preserved there. This aligns with the reference explanation, which provides context about ship preservation in the Gulf of Finland but does not imply the Titanic is located there.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-37')">
            <div class="question-text">
                <div class="question-id">Question #37</div>
                Could a snowy owl survive in the Sonoran?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-37">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a snowy owl survive in the Sonoran?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Snowy owl is a bird native to the Arctic regions of North America. Temperatures in the North American Arctic range from -36.4F to 50F. The Sonoran is one of the hottest deserts in the world. The Sonoran Desert can get as hot as 118F.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could a <fact1>snowy owl</fact1> survive in the <fact2>Sonoran Desert</fact2>?
Answer: <fact1>Snowy owls</fact1> are adapted to cold, arctic climates. The <fact2>Sonoran Desert</fact2> is a hot, arid environment.  The extreme heat of the <fact2>Sonoran Desert</fact2> would likely be fatal to a <fact1>snowy owl</fact1>, which lacks the adaptations to cope with such temperatures. Therefore, a <fact1>snowy owl</fact1> could not survive in the <fact2>Sonoran Desert</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that a snowy owl could not survive in the Sonoran Desert due to the owl's adaptation to cold climates and the desert's extreme heat.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-38')">
            <div class="question-text">
                <div class="question-id">Question #38</div>
                Would a rabbi worship martyrs Ranavalona I killed?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-38">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a rabbi worship martyrs Ranavalona I killed?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Rabbis are teachers of Judaism. Ranavalona I, ruler of Madagascar, killed many Christians that were later determined by the church to be martyrs. Judaism does not have a group of saints and martyrs that are prayed to like Christianity..</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>rabbi</fact1> worship <fact2>martyrs Ranavalona I killed</fact2>?
Answer: <fact1>Rabbis</fact1> are Jewish religious leaders. <fact2>Ranavalona I</fact2> persecuted Christians in Madagascar.  A <fact1>rabbi</fact1> would not worship <fact2>Christian martyrs</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-39')">
            <div class="question-text">
                <div class="question-id">Question #39</div>
                Would an oil painter avoid reds from scale insects that live on a cactus?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-39">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would an oil painter avoid reds from scale insects that live on a cactus?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Carmine is the product of an insect that lives on some cacti. Carmine is not stable in oil paints and its usage has been discontinued. Carmine is red.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would an <fact1>oil painter</fact1> avoid <fact2>reds</fact2> from <fact3>scale insects</fact3> that live on a <fact4>cactus</fact4>?
Answer: <fact2>Reds</fact2> made from <fact3>scale insects</fact3>, like carmine, are known to be fugitive, meaning they fade over time. <fact1>Oil painters</fact1>, particularly those creating works meant to last, would likely avoid such pigments due to their instability.  While the <fact4>cactus</fact4> habitat of the insects is interesting, it doesn't directly affect the pigment's lightfastness, which is the primary concern for an <fact1>oil painter</fact1>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that oil painters would avoid reds from scale insects due to their instability (fugitive nature) in oil paints.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-40')">
            <div class="question-text">
                <div class="question-id">Question #40</div>
                Was the Second Amendment to the United States Constitution written without consideration for black Americans?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-40">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was the Second Amendment to the United States Constitution written without consideration for black Americans?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The writers of the Constitutional Amendments did not view black people as legitimate human beings. The writers of the Constitutional Amendments believed that slavery benefited black slaves. The Constitutional Amendments were written for people that the writers considered human.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was the <fact1>Second Amendment</fact1> to the <fact2>United States Constitution</fact2> written without consideration for <fact3>black Americans</fact3>?
Answer: The <fact2>United States Constitution</fact2>, including the <fact1>Second Amendment</fact1>, was written at a time when slavery was legal and <fact3>Black Americans</fact3> were not considered full citizens.  The framers of the Constitution largely viewed <fact3>Black Americans</fact3> as property, not as individuals with the same rights as white Americans. Therefore, it is accurate to say that the <fact1>Second Amendment</fact1> was written without consideration for the rights of <fact3>Black Americans</fact3>.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that the Second Amendment was written without consideration for Black Americans due to the prevailing views of the time.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-41')">
            <div class="question-text">
                <div class="question-id">Question #41</div>
                Are all the elements plants need for photosynthesis present in atmosphere of Mars?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-41">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are all the elements plants need for photosynthesis present in atmosphere of Mars?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Plants need three elements for photosynthesis: Hydrogen, Oxygen, and Carbon. The atmosphere of Mars is composed of carbon dioxide, nitrogen, argon, and trace levels of water vapor, oxygen, carbon monoxide, hydrogen and other noble gases.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are all the elements plants need for <fact1>photosynthesis</fact1> present in <fact2>atmosphere of Mars</fact2>?
Answer: Plants need light, water, and carbon dioxide for <fact1>photosynthesis</fact1>. While <fact2>Mars's atmosphere</fact2> contains carbon dioxide, it lacks sufficient liquid water and receives less sunlight than Earth. Therefore, not all elements necessary for <fact1>photosynthesis</fact1> are present in the <fact2>atmosphere of Mars</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces irrelevant factors (liquid water and sunlight) and incorrectly concludes that not all necessary elements are present in the atmosphere of Mars, contradicting the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">While Mars's atmosphere contains carbon dioxide, it lacks sufficient liquid water and receives less sunlight than Earth. Therefore, not all elements necessary for photosynthesis are present in the atmosphere of Mars.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that plants need Hydrogen, Oxygen, and Carbon for photosynthesis, all of which are present in the atmosphere of Mars. The generated reasoning introduces the need for liquid water and sunlight, which are not elements and are not relevant to the question of whether the necessary elements are present in the atmosphere.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">While Mars's atmosphere contains carbon dioxide, it lacks sufficient liquid water and receives less sunlight than Earth. Therefore, not all elements necessary for photosynthesis are present in the atmosphere of Mars.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Plants need three elements for photosynthesis: Hydrogen, Oxygen, and Carbon. The atmosphere of Mars is composed of carbon dioxide, nitrogen, argon, and trace levels of water vapor, oxygen, carbon monoxide, hydrogen and other noble gases.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-42')">
            <div class="question-text">
                <div class="question-id">Question #42</div>
                Can you find Bob Marley's face in most smoke shops?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-42">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you find Bob Marley's face in most smoke shops?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Bob Marley's face is on the packaging of a popular brand of rolling papers. Bob Marley is a popular graphic to print on t-shirts for sale to smokers.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can you find <fact1>Bob Marley's face</fact1> in <fact2>most smoke shops</fact2>?
Answer: <fact1>Bob Marley</fact1> is a cultural icon associated with cannabis use. <fact2>Smoke shops</fact2> often sell paraphernalia related to cannabis consumption.  Therefore, it is likely that <fact1>images of Bob Marley's face</fact1> would be found in <fact2>many smoke shops</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly infers that Bob Marley's image is likely found in smoke shops due to his association with cannabis culture, which aligns with the reference explanation that his face is on rolling papers and t-shirts sold in such shops.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-43')">
            <div class="question-text">
                <div class="question-id">Question #43</div>
                Did Pablo Escobar's nickname collection outshine Robert Moses Grove's?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-43">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Pablo Escobar's nickname collection outshine Robert Moses Grove's?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Robert Moses Grove was a baseball player nicknamed Lefty Grove. Pablo Escobar had several nicknames including: Don Pablo, El Padrino, and El Patr√≥n.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Pablo Escobar's nickname collection</fact1> outshine <fact2>Robert Moses Grove's</fact2>?
Answer: <fact1>Pablo Escobar</fact1> had nicknames such as "The King of Cocaine" and "Don Pablo."  <fact2>Robert Moses Grove</fact2>, a baseball player, was nicknamed "Lefty" and "Old Mose."  <fact1>Escobar's</fact1> nicknames reflect his notorious criminal enterprise, while <fact2>Grove's</fact2> are related to his athletic career.  So, while subjective, it's likely <fact1>Escobar's nicknames</fact1> are more widely recognized and associated with a more impactful (though negative) figure, thus "outshining" <fact2>Grove's</fact2> in terms of notoriety.  The answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error by including a nickname for Robert Moses Grove that is not mentioned in the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Robert Moses Grove, a baseball player, was nicknamed "Lefty" and "Old Mose."</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation only mentions that Robert Moses Grove was nicknamed "Lefty Grove". The nickname "Old Mose" is not mentioned in the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">"Lefty" and "Old Mose"</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Lefty Grove</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-44')">
            <div class="question-text">
                <div class="question-id">Question #44</div>
                Has the Subway restaurant franchise had any connections with child abusers?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-44">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Has the Subway restaurant franchise had any connections with child abusers?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Subway hired Jared Fogle as a spokesman for their sandwich shops. Jared Fogle was convicted for having sex with minors and for possessing child pornography.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Has the <fact1>Subway restaurant franchise</fact1> had any connections with <fact2>child abusers</fact2>?
Answer:  <fact1>Subway</fact1> was formerly represented by <fact2>Jared Fogle</fact2>.  <fact2>Fogle</fact2> was convicted of <fact2>child sex offenses</fact2> and possession of <fact2>child pornography</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. It correctly identifies Jared Fogle's association with Subway and his conviction for child sex offenses and possession of child pornography.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-45')">
            <div class="question-text">
                <div class="question-id">Question #45</div>
                Does autopilot rely on fossil fuels?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-45">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does autopilot rely on fossil fuels?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Autopilot is used in vehicles. Vehicles are powered by engines. Engines rely on fossil fuels to operate.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>autopilot</fact1> rely on <fact2>fossil fuels</fact2>?
Answer: <fact1>Autopilot</fact1> systems are primarily used in aircraft and increasingly in cars.  Most aircraft and the vast majority of cars currently run on <fact2>fossil fuels</fact2>. Thus, in its most common applications, <fact1>autopilot</fact1> relies on vehicles powered by <fact2>fossil fuels</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that autopilot systems rely on fossil fuels because they are used in vehicles, which are powered by engines that rely on fossil fuels.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-46')">
            <div class="question-text">
                <div class="question-id">Question #46</div>
                Are psychiatric patients welcome to join the United States Air Force?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-46">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are psychiatric patients welcome to join the United States Air Force?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Having a history of mental illness disqualifies most people from joining the Armed Forces. Psychiatric patients are being seen for management of mental illness.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are <fact1>psychiatric patients</fact1> welcome to join the <fact2>United States Air Force</fact2>?
Answer: <fact1>Individuals with a history of psychiatric conditions</fact1>, particularly those requiring ongoing treatment or medication, generally face significant challenges in joining the <fact2>United States Air Force</fact2>.  The <fact2>Air Force</fact2> has stringent medical standards to ensure personnel can handle the demanding physical and psychological rigors of military service.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that individuals with a history of psychiatric conditions generally face significant challenges in joining the United States Air Force due to stringent medical standards.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-47')">
            <div class="question-text">
                <div class="question-id">Question #47</div>
                Does Nicole Kidman know any Scientologists?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-47">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Nicole Kidman know any Scientologists?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Nicole Kidman was married to Tom Cruise. Tom Cruise is a Scientologist.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Nicole Kidman</fact1> know any <fact2>Scientologists</fact2>?
Answer: <fact1>Nicole Kidman's</fact1> ex-husband, Tom Cruise, is a prominent <fact2>Scientologist</fact2>. Therefore, it is highly likely that <fact1>Nicole Kidman</fact1> knows <fact2>Scientologists</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and provides a logical deduction.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-48')">
            <div class="question-text">
                <div class="question-id">Question #48</div>
                Was John Lennon known to be a good friend to Sasha Obama?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-48">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was John Lennon known to be a good friend to Sasha Obama?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. John Lennon died in 1980. Sasha Obama was born in 2001.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>John Lennon</fact1> known to be a good friend to <fact2>Sasha Obama</fact2>?
Answer: <fact1>John Lennon</fact1> died in 1980. <fact2>Sasha Obama</fact2> was born in 2001.  Since <fact1>John Lennon</fact1> died before <fact2>Sasha Obama</fact2> was born, they could not have been friends. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly uses the dates of John Lennon's death and Sasha Obama's birth to conclude that they could not have been friends.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-49')">
            <div class="question-text">
                <div class="question-id">Question #49</div>
                Would the tunnels at CERN fit onto the High Speed 1 rails?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-49">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would the tunnels at CERN fit onto the High Speed 1 rails?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. High Speed 1 (HS1), legally the Channel Tunnel Rail Link (CTRL), is a 67-mile (108 km) high-speed railway. The CERN collider is contained in a circular tunnel, with a circumference of 26.7 kilometres (16.6 mi). The circumference of a circle is the length of the enclosing boundary.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would the <fact1>tunnels at CERN</fact1> fit onto the <fact2>High Speed 1 rails</fact2>?
Answer: The <fact1>Large Hadron Collider at CERN</fact1> has a circumference of 27 kilometers.  <fact2>High Speed 1</fact2> is 108 kilometers long.  The <fact1>tunnel</fact1> is much shorter than the length of the <fact2>rails</fact2>, so it could theoretically fit lengthwise. However, the question doesn't specify *how* the tunnel would be placed on the rails.  The <fact1>LHC tunnel</fact1>'s cross-section is much larger than the space between the <fact2>rails</fact2>, so it physically wouldn't fit. Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly uses the lengths of the CERN collider and High Speed 1 to determine if the collider could fit on the rails. It also considers the cross-section of the tunnel, which is a valid point.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-50')">
            <div class="question-text">
                <div class="question-id">Question #50</div>
                Could an elephant easily defeat a male macaque?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-50">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could an elephant easily defeat a male macaque?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Male macaques range from 16 to 28 inches tall with a weight between 12.13 to 39.7 pounds. Elephants are between 7 to 11 feet tall and weigh several thousand pounds. Elephants contain large, sharp tusks that can injure or kill other animals.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could an <fact1>elephant</fact1> easily defeat a <fact2>male macaque</fact2>?
Answer: <fact1>Elephants</fact1> are significantly larger and stronger than <fact2>macaques</fact2>.  An <fact1>elephant</fact1> could easily crush a <fact2>macaque</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that elephants are significantly larger and stronger than macaques and could easily crush them.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-51')">
            <div class="question-text">
                <div class="question-id">Question #51</div>
                Do the Ubuntu people speak Ubuntu?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-51">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do the Ubuntu people speak Ubuntu?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Ubuntu is a of free and open-source software used on computers. The Ubuntu people are a tribe that lives in Africa. The Ubuntu people derive their language from Nguni Bantu. As of 2019 only 10% of households in Africa have a computer.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do the <fact1>Ubuntu people</fact1> speak <fact2>Ubuntu</fact2>?
Answer: <fact2>Ubuntu</fact2> is not a spoken language, it's the name of an operating system and a Nguni Bantu term. The <fact1>Ubuntu people</fact1> are a Nguni ethnolinguistic group, primarily in South Africa, and speak Nguni Bantu languages, not <fact2>Ubuntu</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why the Ubuntu people do not speak Ubuntu, aligning with the reference explanation. It correctly identifies Ubuntu as an operating system and the language of the Ubuntu people as Nguni Bantu.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-52')">
            <div class="question-text">
                <div class="question-id">Question #52</div>
                Is cycling a high-risk activity for pelvis fractures?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-52">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is cycling a high-risk activity for pelvis fractures?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Cycling is a low-impact activity . Stress fractures in a pelvic bone often develop as a result of repetitive, high-impact activity that puts stress on the pelvis, such as long-distance running or ballet.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>cycling</fact1> a <fact2>high-risk</fact2> activity for <fact3>pelvis fractures</fact3>?
Answer: While <fact1>cycling</fact1> can result in falls, and falls can cause <fact3>pelvis fractures</fact3>, <fact1>cycling</fact1> is not generally considered a <fact2>high-risk</fact2> activity for this type of injury.  Activities like  contact sports, high-impact falls from heights, or motor vehicle accidents are more commonly associated with <fact3>pelvic fractures</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that cycling is not generally considered a high-risk activity for pelvis fractures and providing examples of activities that are more commonly associated with such injuries.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-53')">
            <div class="question-text">
                <div class="question-id">Question #53</div>
                Is a platypus immune from cholera?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-53">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is a platypus immune from cholera?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Cholera is a bacteria that damages the small intestines in humans. The intestines are part of the stomach of humans. A platypus does not have a stomach.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is a <fact1>platypus</fact1> immune from <fact2>cholera</fact2>?
Answer: <fact2>Cholera</fact2> is caused by bacteria. <fact1>Platypuses</fact1> are mammals and are susceptible to bacterial infections. Thus, a <fact1>platypus</fact1> is not immune from <fact2>cholera</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning fails to connect the fact that platypuses lack a stomach to the fact that cholera affects the stomach, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Thus, a platypus is not immune from cholera.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that cholera affects the small intestines, which are part of the stomach in humans. Platypuses do not have stomachs, therefore they are immune. The generated reasoning fails to make this connection and incorrectly concludes that platypuses are not immune.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Thus, a platypus is not immune from cholera.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">A platypus does not have a stomach.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-54')">
            <div class="question-text">
                <div class="question-id">Question #54</div>
                Would a moose hypothetically be too much for a minotaur to devour whole?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-54">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a moose hypothetically be too much for a minotaur to devour whole?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A minotaur was a mythological beast with the head of a bull and body of a human. Human stomachs process about three to four pounds of food a day. A moose can weigh up to 1500 pounds. Bulls can consume around 33 pounds of food a day.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>moose</fact1> hypothetically be <fact2>too much</fact2> for a <fact3>minotaur</fact3> to devour whole?
Answer: A <fact1>moose</fact1> can weigh up to 1,800 lbs.  A <fact3>minotaur</fact3> is a mythical creature, half man and half bull. While bulls are large and powerful, they are herbivores.  Even assuming a carnivorous <fact3>minotaur</fact3> with enhanced eating capacity compared to a bull, 1,800 lbs of <fact1>moose</fact1> is <fact2>a tremendous amount</fact2> for any creature to consume in one sitting. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning contains a factual error regarding the weight of a moose, but the overall logic is sound.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A moose can weigh up to 1,800 lbs.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that a moose can weigh up to 1,800 lbs, but the reference states that a moose can weigh up to 1500 pounds.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">1,800 lbs</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">1500 pounds</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-55')">
            <div class="question-text">
                <div class="question-id">Question #55</div>
                Are there bones in an anchovy pizza?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-55">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are there bones in an anchovy pizza?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Anchovies used on pizza are typically packed whole in oil or water.  Anchovies on pizza are not usually cut or filleted in any way.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are there <fact1>bones</fact1> in an <fact2>anchovy pizza</fact2>?
Answer: <fact2>Anchovies</fact2> are small fish.  Fish have <fact1>bones</fact1>. While some <fact2>pizza</fact2> makers may use <fact2>anchovy fillets</fact2> where larger <fact1>bones</fact1> have been removed, <fact2>anchovies</fact2> still contain smaller, more delicate <fact1>bones</fact1>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that anchovies are small fish with bones and that they are typically used whole on pizzas, thus containing bones.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-56')">
            <div class="question-text">
                <div class="question-id">Question #56</div>
                Can a Bengal cat survive eating only pancakes?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-56">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a Bengal cat survive eating only pancakes?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Bengal cats are carnivores. Pancakes contain no meat. Carnivores eat only meat to survive.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can a <fact1>Bengal cat</fact1> survive eating only <fact2>pancakes</fact2>?
Answer: <fact2>Pancakes</fact2> do not contain the necessary nutrients for a <fact1>cat</fact1> to survive. <fact1>Cats</fact1> are obligate carnivores. This means their survival depends on nutrients found in meat. Because <fact2>pancakes</fact2> are not meat, a <fact1>Bengal cat</fact1> cannot survive eating only <fact2>pancakes</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that Bengal cats are carnivores and cannot survive on a diet of pancakes, which lack the necessary nutrients found in meat.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-57')">
            <div class="question-text">
                <div class="question-id">Question #57</div>
                Can the original name of the zucchini be typed on the top row of a QWERTY keyboard?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-57">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can the original name of the zucchini be typed on the top row of a QWERTY keyboard?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The original name for the zucchini in Mexican language or Nahuatl is ayokonetl. The top row of a QWERTY keyboard contains the keys q, w, e, r, t, y, u, i , o, and p.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can the <fact1>original name</fact1> of the <fact2>zucchini</fact2> be typed on the <fact3>top row</fact3> of a <fact4>QWERTY keyboard</fact4>?
Answer: The <fact1>original name</fact1> of the <fact2>zucchini</fact2> is "zucchino."  The letters in "zucchino" are z, u, c, c, h, i, n, o.  The letters on the <fact3>top row</fact3> of a <fact4>QWERTY keyboard</fact4> are q, w, e, r, t, y, u, i, o, p.  While u, i, and o appear in both "zucchino" and the <fact3>top row</fact3>, the letters z, c, h, and n do not. Therefore, "zucchino" cannot be typed using only the <fact3>top row</fact3> of a <fact4>QWERTY keyboard</fact4>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain hallucinates the original name of the zucchini, which leads to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The original name of the zucchini is "zucchino."</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The original name of the zucchini is ayokonetl, not zucchino.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">"zucchino."</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">ayokonetl</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-58')">
            <div class="question-text">
                <div class="question-id">Question #58</div>
                Does The Hague border multiple bodies of water?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-58">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does The Hague border multiple bodies of water?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Hague is in the Netherlands.  The Hague is in the Western part of the Netherlands.  The Netherlands borders the North Sea to its west.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>The Hague</fact1> border <fact2>multiple bodies of water</fact2>?
Answer: <fact1>The Hague</fact1> is on the coast of the North Sea.  <fact1>The Hague</fact1> also borders multiple lakes and canals. Thus, <fact1>The Hague</fact1> borders <fact2>multiple bodies of water</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain hallucinates that The Hague borders multiple lakes and canals, which is not mentioned in the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Hague also borders multiple lakes and canals.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation only mentions that the Netherlands borders the North Sea to its west. It does not mention that The Hague borders multiple lakes and canals.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Hague also borders multiple lakes and canals.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Netherlands borders the North Sea to its west.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-59')">
            <div class="question-text">
                <div class="question-id">Question #59</div>
                Do people in middle school usually get breast exams?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-59">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do people in middle school usually get breast exams?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Women should begin giving themselves breast exams at the age of 20. Middle school students are usually preteens or young teens.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>people in middle school</fact1> usually get <fact2>breast exams</fact2>?
Answer: <fact2>Breast exams</fact2> are typically recommended for adult women as a screening tool for breast cancer.  <fact1>People in middle school</fact1> are children and adolescents, not yet adults.  Therefore, <fact2>routine breast exams</fact2> are not typically part of healthcare for <fact1>middle school students</fact1>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and provides a logical justification for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-60')">
            <div class="question-text">
                <div class="question-id">Question #60</div>
                Did people in Korea under Japanese Rule watch a lot of Iron Chef?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-60">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did people in Korea under Japanese Rule watch a lot of Iron Chef?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The first televisions were sold in 1946. Iron Chef started airing in 1993.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did people in <fact1>Korea under Japanese Rule</fact1> watch a lot of <fact2>Iron Chef</fact2>?
Answer: <fact2>Iron Chef</fact2> premiered in 1993. <fact1>Japanese rule in Korea</fact1> ended in 1945.  Therefore, people in <fact1>Korea under Japanese rule</fact1> could not have watched <fact2>Iron Chef</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly uses the dates of Iron Chef's premiere and the end of Japanese rule in Korea to conclude that people in Korea under Japanese rule could not have watched Iron Chef.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-61')">
            <div class="question-text">
                <div class="question-id">Question #61</div>
                Would  bald eagle deliver an urgent message before B-52?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-61">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would  bald eagle deliver an urgent message before B-52?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A bald eagle can travel up to 99 MPH. The B-52 is a US air bomber that can travel up to 650 MPH.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>bald eagle</fact1> deliver an urgent message before a <fact2>B-52</fact2>?
Answer: A <fact1>bald eagle</fact1> is a bird. A <fact2>B-52</fact2> is a strategic bomber.  A bird is much faster than a strategic bomber. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error, stating that a bird is faster than a strategic bomber, which contradicts the reference explanation. This leads to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A bird is much faster than a strategic bomber.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">This statement contradicts the reference explanation, which states that a B-52 can travel up to 650 MPH, while a bald eagle can travel up to 99 MPH. Therefore, the bomber is much faster than the bird.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">A bird is much faster than a strategic bomber.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">A bald eagle can travel up to 99 MPH. The B-52 is a US air bomber that can travel up to 650 MPH.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-62')">
            <div class="question-text">
                <div class="question-id">Question #62</div>
                Does Snoopy look like Chance from Homeward Bound?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-62">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Snoopy look like Chance from Homeward Bound?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Chance from Homeward Bound is a golden retriever.  Snoopy is black and white. Golden Retrievers are yellow in color.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Snoopy</fact1> look like <fact2>Chance</fact2> from <fact3>Homeward Bound</fact3>?
Answer: <fact1>Snoopy</fact1> is a beagle from the comic strip Peanuts. <fact2>Chance</fact2> from <fact3>Homeward Bound</fact3> is an American Bulldog.  Since beagles and American Bulldogs are different breeds with distinct appearances, <fact1>Snoopy</fact1> does not look like <fact2>Chance</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly identifies Chance from Homeward Bound as an American Bulldog instead of a golden retriever, leading to a flawed comparison and conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Chance from Homeward Bound is an American Bulldog.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">Chance from Homeward Bound is a golden retriever, not an American Bulldog.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Chance from Homeward Bound is an American Bulldog</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Chance from Homeward Bound is a golden retriever</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-63')">
            <div class="question-text">
                <div class="question-id">Question #63</div>
                Was Dioskourides a lapidary?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-63">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Dioskourides a lapidary?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A lapidary is a person or machine who cuts gemstones; classically, it refers to a person who engraves gemstones. Dioskourides put his signature on a Roman amethyst ringstone with a portrait of Demosthenes circa late 1st century BC. Artists sign their work.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Dioskourides</fact1> a <fact2>lapidary</fact2>?
Answer: <fact1>Dioskourides</fact1> was a physician, pharmacologist and botanist. A <fact2>lapidary</fact2> is someone who cuts, polishes, or engraves gems. Therefore, <fact1>Dioskourides</fact1> was not a <fact2>lapidary</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly concludes that Dioskourides was not a lapidary based on his other professions, contradicting the reference which states he signed a ringstone, indicating he was also a lapidary.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Dioskourides was a physician, pharmacologist and botanist.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning uses Dioskourides's profession as a physician, pharmacologist, and botanist to incorrectly conclude that he was not a lapidary. The reference states that Dioskourides signed a Roman amethyst ringstone, indicating he was also a lapidary.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Dioskourides was a physician, pharmacologist and botanist.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Dioskourides put his signature on a Roman amethyst ringstone with a portrait of Demosthenes circa late 1st century BC.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-64')">
            <div class="question-text">
                <div class="question-id">Question #64</div>
                Do most middle class families have butlers?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-64">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do most middle class families have butlers?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Butlers make about $60,000 per year on average for their work. Middle class income is between $48,000 and $145,000.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>most</fact1> <fact2>middle class families</fact2> have <fact3>butlers</fact3>?
Answer: <fact3>Butlers</fact3> are typically employed by the wealthy.  <fact2>Middle class families</fact2> generally do not have the financial resources to employ a <fact3>butler</fact3>. Therefore, <fact1>most</fact1> <fact2>middle class families</fact2> do not have <fact3>butlers</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-65')">
            <div class="question-text">
                <div class="question-id">Question #65</div>
                Was Hillary Clinton's deputy chief of staff in 2009 baptised?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-65">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Hillary Clinton's deputy chief of staff in 2009 baptised?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Huma Abedin was Hillary Clinton's deputy chief of staff in 2009. Huma Abedin is an American Muslim. Baptism is a Christian tradition.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Hillary Clinton's deputy chief of staff</fact1> in <fact2>2009</fact2> <fact3>baptised</fact3>?
Answer: <fact1>Hillary Clinton's deputy chief of staff in 2009</fact1> was <fact1>Huma Abedin</fact1>. <fact1>Huma Abedin</fact1> is Muslim.  Muslims are not typically <fact3>baptised</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-66')">
            <div class="question-text">
                <div class="question-id">Question #66</div>
                Does the New York Public Library sell Alpo products?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-66">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does the New York Public Library sell Alpo products?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The New York Public Library is a public lending library system in New York City. Alpo produces pet food and related products.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does the <fact1>New York Public Library</fact1> sell <fact2>Alpo products</fact2>?
Answer: <fact2>Alpo</fact2> is a brand of dog food.  <fact1>The New York Public Library</fact1> is a library system. Libraries lend books and other media. They do not typically sell pet food. Therefore, the <fact1>New York Public Library</fact1> does not sell <fact2>Alpo products</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that the New York Public Library does not sell Alpo products, based on the fact that the library is a lending system and Alpo is a brand of dog food.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-67')">
            <div class="question-text">
                <div class="question-id">Question #67</div>
                Did Solomon make up bigger percentage of Islamic prophets than Kings of Judah?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-67">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Solomon make up bigger percentage of Islamic prophets than Kings of Judah?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. According to The Quran, Solomon was one of 25 prophets. According to some Islamic hadiths, there have been as many as 124,000 prophets. Solomon was one of 20 Kings of Judah.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Solomon</fact1> make up bigger percentage of <fact2>Islamic prophets</fact2> than <fact3>Kings of Judah</fact3>?

Answer: <fact1>Solomon</fact1> is considered a prophet in Islam.  There are many <fact2>Islamic prophets</fact2>, including figures like Moses, Jesus, and Muhammad.  <fact1>Solomon</fact1> is only one of them, so he represents a small percentage of the total number of <fact2>Islamic prophets</fact2>. <fact1>Solomon</fact1> was also a <fact3>King of Judah</fact3>. The number of <fact3>Kings of Judah</fact3> is far fewer than the number of <fact2>Islamic prophets</fact2>. Therefore, <fact1>Solomon</fact1> makes up a larger percentage of the <fact3>Kings of Judah</fact3> than the <fact2>Islamic prophets</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The reasoning contains a logical error, leading to an incorrect conclusion. The generated reasoning incorrectly concludes that Solomon represents a larger percentage of Islamic prophets than Kings of Judah, contradicting the reference.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Therefore, Solomon makes up a larger percentage of the Kings of Judah than the Islamic prophets.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reasoning is flawed. The reference states that Solomon was one of 25 prophets (or even one of 124,000 according to some hadiths) and one of 20 Kings of Judah. Therefore, Solomon represents a larger percentage of the Kings of Judah than the Islamic prophets.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Therefore, Solomon makes up a larger percentage of the Kings of Judah than the Islamic prophets.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Solomon was one of 25 prophets. Solomon was one of 20 Kings of Judah.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-68')">
            <div class="question-text">
                <div class="question-id">Question #68</div>
                Would Taylor Swift refer to Snoopy as oppa?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-68">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Taylor Swift refer to Snoopy as oppa?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Oppa is a Korean word used by women to address a man who is 10 or more years older than her. Snoopy is 47 years old. Taylor Swift is 30 years old.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>Taylor Swift</fact1> refer to <fact2>Snoopy</fact2> as <fact3>oppa</fact3>?
Answer: <fact3>Oppa</fact3> is a Korean honorific used by females to refer to older males. <fact1>Taylor Swift</fact1> is American.  <fact2>Snoopy</fact2> is a cartoon dog.  It's highly unlikely <fact1>Taylor Swift</fact1> would use a Korean honorific to refer to <fact2>Snoopy</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning makes an incorrect assumption that Taylor Swift would not use a Korean honorific to refer to Snoopy, contradicting the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">It's highly unlikely Taylor Swift would use a Korean honorific to refer to Snoopy.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that Taylor Swift is 30 and Snoopy is 47, so she could refer to him as oppa. The generated reasoning incorrectly assumes that she would not use a Korean honorific to refer to Snoopy.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">It's highly unlikely Taylor Swift would use a Korean honorific to refer to Snoopy.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Oppa is a Korean word used by women to address a man who is 10 or more years older than her. Snoopy is 47 years old. Taylor Swift is 30 years old.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-69')">
            <div class="question-text">
                <div class="question-id">Question #69</div>
                Did Confederate States Army influence West Point fashion?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-69">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Confederate States Army influence West Point fashion?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Confederate States Army was clad in cadet gray uniforms. West Point uniforms are cadet gray and white. Confederate States Army uniforms contained Generally, the uniform jacket of the Confederate soldier was single breasted, made of gray or brown fabric, with a six to nine button front and hat.  West Point uniforms contain a standing collar, white trousers, and black shakos (known as a "tarbucket hat" in U.S. Army nomenclature).</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Confederate States Army</fact1> influence <fact2>West Point fashion</fact2>?
Answer: Many <fact1>Confederate officers</fact1> were graduates of <fact2>West Point</fact2>.  After the Civil War, some aspects of <fact1>Confederate uniforms</fact1> and styles, such as the kepi and certain gray shades, were adopted into <fact2>military fashion more broadly</fact2>, sometimes influencing <fact2>later West Point styles</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning contains a logical error by suggesting that West Point styles were influenced *after* the Civil War, while the reference implies that the influence was already present due to the Confederate army being clad in cadet gray uniforms, which is the same color as West Point uniforms.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">After the Civil War, some aspects of Confederate uniforms and styles, such as the kepi and certain gray shades, were adopted into military fashion more broadly, sometimes influencing later West Point styles.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that West Point uniforms are cadet gray and white, and that Confederate uniforms were clad in cadet gray uniforms. The generated reasoning suggests that West Point styles were influenced *after* the Civil War, implying a later adoption. However, the reference implies that the influence was already present due to the Confederate army being clad in cadet gray uniforms, which is the same color as West Point uniforms.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">After the Civil War, some aspects of Confederate uniforms and styles, such as the kepi and certain gray shades, were adopted into military fashion more broadly, sometimes influencing later West Point styles.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Confederate States Army was clad in cadet gray uniforms. West Point uniforms are cadet gray and white.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-70')">
            <div class="question-text">
                <div class="question-id">Question #70</div>
                Does conservatism repulse Blaire White?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-70">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does conservatism repulse Blaire White?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Blaire White is a Youtuber. Blaire White posts content that leans towards conservative politics.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>conservatism</fact1> repulse <fact2>Blaire White</fact2>?
Answer: <fact2>Blaire White</fact2> is a transgender YouTube commentator who is politically <fact1>conservative</fact1>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Blaire White is politically conservative, aligning with the reference explanation. There are no hallucinations or errors in the reasoning.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-71')">
            <div class="question-text">
                <div class="question-id">Question #71</div>
                Do all parts of the aloe vera plant taste good?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-71">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do all parts of the aloe vera plant taste good?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. There is a layer of yellow latex liquid between the outside of an aloe leaf and the gel inside. The latex inside aloe tastes very bitter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>all parts</fact1> of the <fact2>aloe vera plant</fact2> <fact3>taste good</fact3>?
Answer: While the <fact2>aloe vera plant's</fact2> inner gel is known for its medicinal properties and is sometimes added to drinks, the <fact1>outer parts</fact1>, including the rind and latex, contain compounds that can be toxic and taste bitter or unpleasant. Therefore, not <fact1>all parts</fact1> of the <fact2>aloe vera plant</fact2> <fact3>taste good</fact3>. The answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that not all parts of the aloe vera plant taste good, but it incorrectly states that the outer parts are toxic, which is not mentioned in the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">the outer parts, including the rind and latex, contain compounds that can be toxic</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation only mentions that the latex tastes bitter, not that the outer parts are toxic.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">contain compounds that can be toxic</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The latex inside aloe tastes very bitter.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-72')">
            <div class="question-text">
                <div class="question-id">Question #72</div>
                Does an individual oceanographer study many sciences?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-72">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does an individual oceanographer study many sciences?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Study of the oceans involve many fields or science. To properly study their specific topic of research, an oceanographer must understand how their science interacts with the other involved sciences.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does an <fact1>individual oceanographer</fact1> study <fact2>many sciences</fact2>?
Answer: An <fact1>oceanographer</fact1> studies the ocean.  The ocean encompasses many disciplines, including physics, chemistry, geology, and biology.  Because an <fact1>oceanographer</fact1>'s work can involve these different aspects of the ocean, they often draw upon <fact2>multiple scientific fields</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that oceanographers study the ocean, which encompasses many disciplines, and therefore they often draw upon multiple scientific fields.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-73')">
            <div class="question-text">
                <div class="question-id">Question #73</div>
                Did Kurt Cobain's music genre survive after his death?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-73">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Kurt Cobain's music genre survive after his death?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Kurt Cobain was the lead singer of Nirvana. Nirvana's music is classified as Grunge rock. Kurt Cobain died on April 5, 1994. Some of the major Grunge rock bands included Alice in Chains, Pearl Jam, and Soundgarden. Alice in Chains and Pearl Jam released their latest albums in 2018 and 2020 respectively.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Kurt Cobain's</fact1> <fact2>music genre</fact2> survive after <fact1>his death</fact1>?
Answer: <fact1>Kurt Cobain</fact1> was the lead singer and guitarist of the band Nirvana. Nirvana's <fact2>music genre</fact2> was grunge, a subgenre of alternative rock.  Grunge music continued to be made and enjoyed by fans after <fact1>Kurt Cobain's death</fact1> in 1994.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. There are no contradictions or logical errors.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-74')">
            <div class="question-text">
                <div class="question-id">Question #74</div>
                Did Immanuel Kant ever meet the 14th president of the United States?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-74">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Immanuel Kant ever meet the 14th president of the United States?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Immanuel Kant died on Feb 12, 1804. Franklin Pierce was the 14th president of the United States. Franklin PIerce was born Nov 23, 1804.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Immanuel Kant</fact1> ever meet the <fact2>14th president of the United States</fact2>?
Answer: <fact1>Immanuel Kant</fact1> died in 1804. <fact2>Franklin Pierce</fact2>, the <fact2>14th president of the United States</fact2>, was born in 1804.  Therefore, <fact1>Kant</fact1> could not have met <fact2>Pierce</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly states that Immanuel Kant died in 1804 and Franklin Pierce was born in 1804, leading to the correct conclusion that they could not have met.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-75')">
            <div class="question-text">
                <div class="question-id">Question #75</div>
                Would eliminating competition in the Japanese bulk carrier market be profitable for a steel company?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-75">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would eliminating competition in the Japanese bulk carrier market be profitable for a steel company?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. 62% of bulk carriers are built in Japan. Bulk carrier hulls are made of steel.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would eliminating competition in the <fact1>Japanese bulk carrier market</fact1> be profitable for a <fact2>steel company</fact2>?
Answer:  <fact1>Bulk carriers</fact1> are ships used to transport large quantities of unpackaged goods, like steel.  <fact2>Steel companies</fact2> would likely supply steel to companies building <fact1>bulk carriers</fact1>. Eliminating competition in <fact1>the Japanese bulk carrier market</fact1> would likely decrease the demand for new <fact1>bulk carriers</fact1>, which would reduce the need for steel. This would likely decrease profits for <fact2>a steel company</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly assumes that eliminating competition would decrease demand for bulk carriers and steel, contradicting the likely outcome of increased profits and steel demand.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Eliminating competition in the Japanese bulk carrier market would likely decrease the demand for new bulk carriers, which would reduce the need for steel.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that 62% of bulk carriers are built in Japan and that bulk carrier hulls are made of steel. Eliminating competition would allow Japanese companies to charge more, increasing profits, and thus increasing steel demand.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Eliminating competition in the Japanese bulk carrier market would likely decrease the demand for new bulk carriers, which would reduce the need for steel.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">62% of bulk carriers are built in Japan. Bulk carrier hulls are made of steel.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-76')">
            <div class="question-text">
                <div class="question-id">Question #76</div>
                Would a geographer use biochemistry in their work?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-76">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a geographer use biochemistry in their work?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A geographer is a scientist whose area of study is geography, the study of Earth's natural environment and human society. Biochemistry is the study of chemical processes within and relating to living organisms.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>geographer</fact1> use <fact2>biochemistry</fact2> in their work?
Answer: <fact1>Geographers</fact1> study the earth and its features, inhabitants, and phenomena. <fact2>Biochemistry</fact2> is the study of chemical processes within and relating to living organisms.  A <fact1>geographer</fact1> would be unlikely to employ <fact2>biochemistry</fact2> directly in their studies. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that geographers study the earth and its features, while biochemistry focuses on chemical processes in living organisms, making it unlikely for a geographer to directly use biochemistry in their studies.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-77')">
            <div class="question-text">
                <div class="question-id">Question #77</div>
                Is most coffee produced South of the Equator?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-77">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is most coffee produced South of the Equator?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The countries with the highest coffee production are in South America. Almost all of South America is in the Southern Hemisphere.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is most <fact1>coffee</fact1> produced <fact2>South of the Equator</fact2>?
Answer: Most <fact1>coffee</fact1> production occurs in a region known as the Bean Belt.  The Bean Belt spans the globe along the equator, with the vast majority of producing countries lying <fact2>south of the equator</fact2>. Thus, most <fact1>coffee</fact1> *is* produced <fact2>south of the Equator</fact2>.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces the concept of the 'Bean Belt' which is not mentioned in the reference explanation, and incorrectly states that the vast majority of producing countries lie south of the equator. The reference explanation states that the countries with the highest coffee production are in South America, which is almost entirely in the Southern Hemisphere.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Bean Belt spans the globe along the equator, with the vast majority of producing countries lying south of the equator.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the countries with the highest coffee production are in South America, which is almost entirely in the Southern Hemisphere. The generated reasoning states that the Bean Belt spans the globe along the equator, with the vast majority of producing countries lying south of the equator. This is a contradiction because the reference does not mention the Bean Belt.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Bean Belt spans the globe along the equator, with the vast majority of producing countries lying south of the equator.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The countries with the highest coffee production are in South America. Almost all of South America is in the Southern Hemisphere.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-78')">
            <div class="question-text">
                <div class="question-id">Question #78</div>
                Is it hard to get a BLT in Casablanca?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-78">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it hard to get a BLT in Casablanca?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A BLT is a sandwich consisting of bacon, lettuce and tomato. Casablanca is predominantly Muslim. Islam forbids the consumption of pork and pork products.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is it hard to get a <fact1>BLT</fact1> in <fact2>Casablanca</fact2>?
Answer: A <fact1>BLT</fact1> is a sandwich containing bacon, lettuce, and tomato.  <fact2>Casablanca</fact2> is a predominantly Muslim city in Morocco.  Pork products, like bacon, are not commonly consumed in Muslim cultures. Therefore, it is likely difficult to find the ingredients for a <fact1>BLT</fact1> in <fact2>Casablanca</fact2>, making it hard to get one. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and provides a logical justification for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction,contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-79')">
            <div class="question-text">
                <div class="question-id">Question #79</div>
                Could largest ship from Voyages of Christopher Columbus haul Statue of Liberty?
            </div>
            <span class="hallucination-count ">2 issues</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-79">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could largest ship from Voyages of Christopher Columbus haul Statue of Liberty?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The largest ship Christopher Columbus used was the Santa Maria. The Santa Maria has a cargo capacity of 108 tons. The Statue of Liberty weighs 225 tons.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could the <fact1>largest ship</fact1> from the <fact2>Voyages of Christopher Columbus</fact2> haul the <fact3>Statue of Liberty</fact3>?
Answer: The <fact3>Statue of Liberty</fact3> weighs 450,000 lbs.  The <fact1>largest ship</fact1> on <fact2>Columbus's first voyage</fact2> was the Santa Mar√≠a, which had a cargo capacity estimated between 200 and 250 toneladas. A tonelada is roughly equivalent to 2,000 lbs.  This means the Santa Mar√≠a could carry between 400,000 and 500,000 lbs. Since this is greater than the weight of the <fact3>Statue of Liberty</fact3>, the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains factual errors regarding the cargo capacity of the Santa Maria and misrepresents the units of measurement for the Statue of Liberty's weight, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (2)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Statue of Liberty weighs 450,000 lbs.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The Statue of Liberty weighs 225 tons, which is equivalent to 450,000 lbs. However, the reference states the weight in tons (225 tons), not pounds.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Statue of Liberty weighs 450,000 lbs.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Statue of Liberty weighs 225 tons.</div>
        </div>
        
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">which had a cargo capacity estimated between 200 and 250 toneladas</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The Santa Maria had a cargo capacity of 108 tons, not 200-250 toneladas.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">which had a cargo capacity estimated between 200 and 250 toneladas</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Santa Maria has a cargo capacity of 108 tons.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-80')">
            <div class="question-text">
                <div class="question-id">Question #80</div>
                Would Jolly Green Giant's largest monument look impressive next to Pyrenees?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-80">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Jolly Green Giant's largest monument look impressive next to Pyrenees?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Jolly Green Giant monument in Blue Earth, Minnesota is 55.5 feet tall. The Pyrenees mountains are 11,168 feet high. The Pyrenees mountains are 305 miles wide.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>Jolly Green Giant's largest monument</fact1> look impressive next to <fact2>Pyrenees</fact2>?
Answer: The <fact1>Jolly Green Giant statue in Blue Earth, Minnesota</fact1> is 55 feet tall. The <fact2>Pyrenees mountain range</fact2> has peaks that reach over 11,000 feet.  Therefore, the <fact1>Jolly Green Giant statue</fact1> would be dwarfed by the <fact2>Pyrenees</fact2> and would not look impressive next to them. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-81')">
            <div class="question-text">
                <div class="question-id">Question #81</div>
                Did Karl Marx influence the communist party of China?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-81">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Karl Marx influence the communist party of China?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Communist ideology is the foundation of communist party of China. Marx produced a political pamphlet that has since come to be commonly known as the communist manifesto.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Karl Marx</fact1> influence the <fact2>communist party of China</fact2>?
Answer: <fact2>The Communist Party of China</fact2>‚Äôs ideology is officially Marxism-Leninism, a synthesis of <fact1>Karl Marx</fact1>‚Äôs ideas and those of Vladimir Lenin. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a logical error by stating that the ideology is Marxism-Leninism, which is a synthesis of Karl Marx's ideas and those of Vladimir Lenin. This implies that Marx's ideas were not directly used, but rather a synthesis of his and Lenin's ideas were used, which is not stated in the reference.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Communist Party of China‚Äôs ideology is officially Marxism-Leninism, a synthesis of Karl Marx‚Äôs ideas and those of Vladimir Lenin.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that communist ideology is the foundation of the communist party of China and that Marx produced the communist manifesto. The generated reasoning states that the ideology is Marxism-Leninism, which is a synthesis of Karl Marx's ideas and those of Vladimir Lenin. While this may be true, it is not stated in the reference and implies that Marx's ideas were not directly used, but rather a synthesis of his and Lenin's ideas were used.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Communist Party of China‚Äôs ideology is officially Marxism-Leninism, a synthesis of Karl Marx‚Äôs ideas and those of Vladimir Lenin.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Communist ideology is the foundation of communist party of China. Marx produced a political pamphlet that has since come to be commonly known as the communist manifesto.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-82')">
            <div class="question-text">
                <div class="question-id">Question #82</div>
                Does Soylent use Pea for their source of protein?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-82">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Soylent use Pea for their source of protein?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Soylent is a meal replacement drink that offers 20mg protein. The protein in Soylent is derived from Soy.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Soylent</fact1> use <fact2>Pea</fact2> for their source of <fact3>protein</fact3>?
Answer: <fact1>Soylent</fact1> uses <fact2>soy protein</fact2>, not <fact2>pea protein</fact2>, as its primary source of <fact3>protein</fact3>.  Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Soylent uses soy protein, not pea protein, as its primary source of protein, which aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-83')">
            <div class="question-text">
                <div class="question-id">Question #83</div>
                Do most religious people in Quebec refer to the Quran?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-83">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do most religious people in Quebec refer to the Quran?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Christianity is the major religion in Quebec. Christians refer to the Bible as their book of reference.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>most religious people</fact1> in <fact2>Quebec</fact2> refer to the <fact3>Quran</fact3>?
Answer: The <fact3>Quran</fact3> is the central religious text of Islam.  <fact2>Quebec's</fact2> population is largely Christian, with Catholicism being the most prevalent religion. <fact1>Most religious people</fact1> in <fact2>Quebec</fact2> would therefore refer to the Bible, not the <fact3>Quran</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Christianity as the major religion in Quebec and the Bible as the primary religious text for Christians, leading to the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-84')">
            <div class="question-text">
                <div class="question-id">Question #84</div>
                Does Family Guy take place on the American West Coast?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-84">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Family Guy take place on the American West Coast?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Family Guy takes place in the fictional town of Quahog, Rhode Island. Rhode Island is a state on the American East Coast.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Family Guy</fact1> take place on the <fact2>American West Coast</fact2>?
Answer: <fact1>Family Guy</fact1> takes place in Quahog, Rhode Island. Rhode Island is on the <fact2>East Coast</fact2> of the United States, not the <fact2>West Coast</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that Family Guy takes place in Quahog, Rhode Island, which is on the East Coast, not the West Coast.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-85')">
            <div class="question-text">
                <div class="question-id">Question #85</div>
                Are lengths measured in metres in the UK?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-85">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are lengths measured in metres in the UK?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Metres are part of the metric system. The UK uses the metric system for measurements.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are lengths measured in <fact1>metres</fact1> in the <fact2>UK</fact2>?
Answer: The <fact2>UK</fact2> uses the metric system, so lengths are measured in <fact1>metres</fact1>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that the UK uses the metric system, which includes metres for measuring lengths.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-86')">
            <div class="question-text">
                <div class="question-id">Question #86</div>
                Did the first Duke of Valentinois play a key role in the Hundred Years' War?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-86">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the first Duke of Valentinois play a key role in the Hundred Years' War?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Hundred Years' War was a conflict between England and France from 1337-1453. Cesare Borgia, the son of Pope Alexander VI, was the first Duke of Valentinois. Cesare Borgia was born in 1475.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did the <fact1>first Duke of Valentinois</fact1> play a key role in the <fact2>Hundred Years' War</fact2>?
Answer: The <fact2>Hundred Years' War</fact2> took place between 1337 and 1453.  The <fact1>first Duke of Valentinois</fact1> was Cesare Borgia, who lived from 1475 to 1507. Since Cesare Borgia was born after the <fact2>Hundred Years' War</fact2> ended, he could not have played a key role in it. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Cesare Borgia could not have played a role in the Hundred Years' War because he was born after it ended. The reasoning is sound and consistent with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-87')">
            <div class="question-text">
                <div class="question-id">Question #87</div>
                Do gorillas fight with panda bears?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-87">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do gorillas fight with panda bears?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Gorilla distribution is limited to areas of the continent of Africa. Panda bears are found in the wild only in China.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>gorillas</fact1> fight with <fact2>panda bears</fact2>?
Answer: <fact1>Gorillas</fact1> live in the forests of central Africa. <fact2>Panda bears</fact2> live in the mountains of central China.  Since <fact1>gorillas</fact1> and <fact2>panda bears</fact2> live on different continents, they do not interact and therefore do not fight. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating the geographical locations of gorillas and panda bears and concluding that they do not interact or fight due to their different habitats.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-88')">
            <div class="question-text">
                <div class="question-id">Question #88</div>
                Was Christina Aguilera born in the forgotten borough?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-88">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Christina Aguilera born in the forgotten borough?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Christina Maria Aguilera was born on December 18, 1980, in Staten Island, New York. Staten Island has sometimes been called "the forgotten borough" by inhabitants who feel neglected by the city government.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Christina Aguilera</fact1> born in the <fact2>forgotten borough</fact2>?
Answer: <fact1>Christina Aguilera</fact1> was born in Staten Island, New York. Staten Island is known as <fact2>the forgotten borough</fact2>.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies that Christina Aguilera was born in Staten Island, which is known as the forgotten borough.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-89')">
            <div class="question-text">
                <div class="question-id">Question #89</div>
                Is H's most common two letter pair partner a freebie in Wheel of Fortune bonus round?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-89">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is H's most common two letter pair partner a freebie in Wheel of Fortune bonus round?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. H forms the most common two letter pair in the English language along with the letter T. The Wheel of Fortune bonus round gives the player six free letters: R, S, T, L, N, E.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>H</fact1>'s most common two letter pair partner a <fact2>freebie</fact2> in <fact3>Wheel of Fortune bonus round</fact3>?
Answer: The most common two letter pair partner for <fact1>H</fact1> is <fact1>T</fact1>. <fact1>T</fact1> is given as a <fact2>free letter</fact2> in the <fact3>bonus round</fact3> of <fact3>Wheel of Fortune</fact3>.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that the most common two-letter pair with H is T, and that T is a free letter in the Wheel of Fortune bonus round, thus accurately answering the question.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-90')">
            <div class="question-text">
                <div class="question-id">Question #90</div>
                Can a quarter fit inside of a human kidney?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-90">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a quarter fit inside of a human kidney?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Kidney stones are hard mineral deposits that can form in the kidneys. The largest kidney stone ever recorded was 13 cm wide. The diameter of a quarter is 2.4 cm.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can a <fact1>quarter</fact1> fit inside of a <fact2>human kidney</fact2>?
Answer: A <fact1>quarter</fact1> has a diameter of 0.955 inches. A <fact2>human kidney</fact2> is about 4 inches long, 2 inches wide, and 1 inch thick. Since the smallest dimension of a <fact2>kidney</fact2> is larger than the diameter of a <fact1>quarter</fact1>, a <fact1>quarter</fact1> can fit inside a <fact2>human kidney</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error regarding the diameter of a quarter. However, the overall logic is sound.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A quarter has a diameter of 0.955 inches.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that the diameter of a quarter is 2.4 cm, which is approximately 0.94 inches. While close, the generated reasoning states the diameter is 0.955 inches, which is incorrect.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">0.955 inches</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">2.4 cm</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-91')">
            <div class="question-text">
                <div class="question-id">Question #91</div>
                Does James Webb Space Telescope fail astronomer in locating planet Krypton?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-91">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does James Webb Space Telescope fail astronomer in locating planet Krypton?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The James Webb Space Telescope is the most powerful telescope created. Krypton is a planet in the fictional Superman comic book series.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>James Webb Space Telescope</fact1> fail astronomer in locating <fact2>planet Krypton</fact2>?
Answer: <fact2>Krypton</fact2> is a fictional planet from DC Comics, the home world of Superman.  The <fact1>James Webb Space Telescope</fact1> observes real celestial objects. Therefore, the <fact1>James Webb Space Telescope</fact1> would not be used to search for a fictional planet like <fact2>Krypton</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Krypton is a fictional planet and the James Webb Space Telescope observes real celestial objects, leading to the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-92')">
            <div class="question-text">
                <div class="question-id">Question #92</div>
                Was P. G. Wodehouse's favorite book The Hunger Games?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-92">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was P. G. Wodehouse's favorite book The Hunger Games?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. P. G. Wodehouse died in 1975. The Hunger Games was published in 2008.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>P. G. Wodehouse's</fact1> favorite book <fact2>The Hunger Games</fact2>?
Answer: <fact2>The Hunger Games</fact2> was written by Suzanne Collins and published in 2008. <fact1>P.G. Wodehouse</fact1> died in 1975. Therefore, <fact2>The Hunger Games</fact2> could not have been <fact1>P. G. Wodehouse's</fact1> favorite book. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that P.G. Wodehouse could not have liked The Hunger Games because he died before it was published. The reasoning is sound and consistent with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-93')">
            <div class="question-text">
                <div class="question-id">Question #93</div>
                Should a finished website have lorem ipsum paragraphs?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-93">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Should a finished website have lorem ipsum paragraphs?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Lorem Ipsum paragraphs are meant to be temporary. Web designers always remove lorem ipsum paragraphs before launch.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Should a <fact1>finished website</fact1> have <fact2>lorem ipsum paragraphs</fact2>?
Answer: A <fact1>finished website</fact1> is ready to be viewed by the public.  <fact2>Lorem ipsum</fact2> is placeholder text. Placeholder text is used as a stand-in for actual content.  A <fact1>website that is finished</fact1> should not contain placeholder text. Therefore, a <fact1>finished website</fact1> should not have <fact2>lorem ipsum paragraphs</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly explains why a finished website should not have lorem ipsum paragraphs, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-94')">
            <div class="question-text">
                <div class="question-id">Question #94</div>
                Did William Shaespeare read the Daily Mirror?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-94">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did William Shaespeare read the Daily Mirror?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Daily Mirror is a British tabloid founded in 1903. William Shakespeare died in 1616.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>William Shakespeare</fact1> read the <fact2>Daily Mirror</fact2>?
Answer: <fact1>William Shakespeare</fact1> died in 1616. The <fact2>Daily Mirror</fact2> was founded in 1903.  Therefore, <fact1>Shakespeare</fact1> could not have read the <fact2>Daily Mirror</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation, and it correctly concludes that William Shakespeare could not have read the Daily Mirror.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-95')">
            <div class="question-text">
                <div class="question-id">Question #95</div>
                Will more people go in and out of Taco Bell than a Roy Rogers each year?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-95">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will more people go in and out of Taco Bell than a Roy Rogers each year?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Taco Bell has over 7,072 restaurants as of 2018. Roy Rogers had over 600 restaurants at its peak. Roy Rogers has 48 locations as of 2019.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Will more people go in and out of <fact1>Taco Bell</fact1> than a <fact2>Roy Rogers</fact2> each year?
Answer: <fact1>Taco Bell</fact1> is a large, international fast-food chain.  <fact2>Roy Rogers</fact2> is a much smaller regional chain.  Therefore, it is highly likely that more people visit <fact1>Taco Bell</fact1> annually than <fact2>Roy Rogers</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly infers that Taco Bell likely has more annual visitors than Roy Rogers based on the relative sizes of the chains, which aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-96')">
            <div class="question-text">
                <div class="question-id">Question #96</div>
                Is it safe to wear sandals in snow?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-96">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it safe to wear sandals in snow?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Sandals have open toes and don't completely cover the feet. Snow is very cold and direct exposure to skin can cause hypothermia. The feet need to be completely covered to walk through snow safely.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is it <fact1>safe</fact1> to wear <fact2>sandals</fact2> in <fact3>snow</fact3>?
Answer: <fact2>Sandals</fact2> offer minimal protection from the elements.  <fact3>Snow</fact3> is cold and often wet.  Wearing <fact2>sandals</fact2> in <fact3>snow</fact3> would expose one's feet to the cold and wet, potentially leading to frostbite or hypothermia. Therefore, it is not <fact1>safe</fact1>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that wearing sandals in the snow is unsafe due to the exposure to cold and wet conditions, which can lead to frostbite or hypothermia.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-97')">
            <div class="question-text">
                <div class="question-id">Question #97</div>
                Was Nikola Tesla's home country involved in the American Civil War?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-97">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Nikola Tesla's home country involved in the American Civil War?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Nikola Tesla was born in the Austrian Empire. The American Civil War was a domestic American conflict.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Nikola Tesla's home country</fact1> involved in the <fact2>American Civil War</fact2>?
Answer: <fact1>Nikola Tesla</fact1> was born in Smiljan, Croatia.  Croatia was part of the Austro-Hungarian Empire at the time.  The <fact2>American Civil War</fact2> was an internal conflict within the United States. The Austro-Hungarian Empire was not involved in the <fact2>American Civil War</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain contains an entity swap, stating Tesla was born in Croatia instead of the Austrian Empire. The rest of the reasoning is correct.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Nikola Tesla was born in Smiljan, Croatia.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Nikola Tesla was born in the Austrian Empire, not Croatia.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Smiljan, Croatia</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Austrian Empire</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-98')">
            <div class="question-text">
                <div class="question-id">Question #98</div>
                Did Ada Lovelace die tragically young for her era?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-98">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Ada Lovelace die tragically young for her era?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Ada Lovelace died at the age of 36 in 1852. The life expectancy in the 1800s was between 35 and 39 years old. Tuberculosis was one of the leading causes of death in the 1800s and a vaccine was not made until the 1900s.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Ada Lovelace</fact1> die tragically young for <fact2>her era</fact2>?
Answer: <fact1>Ada Lovelace</fact1> died at age 36. The average life expectancy for women in <fact2>the Victorian era</fact2> (<fact2>Lovelace's time</fact2>) was about 40 years.  While dying at 36 is certainly young, it wasn't drastically shorter than the average life expectancy for <fact2>her time</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. It correctly states Ada Lovelace's age at death and compares it to the average life expectancy of the time, concluding that her death, while young, was not drastically shorter than average.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-99')">
            <div class="question-text">
                <div class="question-id">Question #99</div>
                Can an Asian black bear use chopsticks?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-99">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can an Asian black bear use chopsticks?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Asian black bear are a species of bear found in asia.  Asian black bear don't have opposable thumbs. Chopsticks are eating utensils use requires opposable thumbs.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can an <fact1>Asian black bear</fact1> use <fact2>chopsticks</fact2>?
Answer: <fact2>Chopsticks</fact2> require a certain level of dexterity and fine motor control to use effectively.  <fact1>Bears</fact1>, while intelligent, have paws designed for powerful actions like digging, climbing, and swatting, not delicate manipulation.  Therefore, it is highly unlikely that an <fact1>Asian black bear</fact1> could use <fact2>chopsticks</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning provides a plausible but ultimately incorrect explanation for why an Asian black bear cannot use chopsticks. It focuses on dexterity rather than the lack of opposable thumbs, which is the key factor mentioned in the reference.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Bears, while intelligent, have paws designed for powerful actions like digging, climbing, and swatting, not delicate manipulation.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Asian black bears don't have opposable thumbs, which is the reason they cannot use chopsticks. The generated reasoning focuses on dexterity and fine motor control, which is a misinterpretation of the core reason.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Bears, while intelligent, have paws designed for powerful actions like digging, climbing, and swatting, not delicate manipulation.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Asian black bear don't have opposable thumbs.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-100')">
            <div class="question-text">
                <div class="question-id">Question #100</div>
                Can someone sell their time through the Toronto Star?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-100">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can someone sell their time through the Toronto Star?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Toronto Star has a classifieds section. Readers can advertise their own labor or services and thus their time .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can someone sell their <fact1>time</fact1> through the <fact2>Toronto Star</fact2>?
Answer: The <fact2>Toronto Star</fact2> is a newspaper.  Newspapers sell advertising space.  People selling <fact1>time</fact1> are offering services.  Therefore, someone could buy advertising space in the <fact2>Toronto Star</fact2> to sell their <fact1>time</fact1>/services.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a logical and correct justification for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-101')">
            <div class="question-text">
                <div class="question-id">Question #101</div>
                Were deaths from Apollo 13 mission eclipsed by other space missions?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-101">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Were deaths from Apollo 13 mission eclipsed by other space missions?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Apollo 13 was a failed Moon landing in which the crew had faulty oxygen resources. All of the Apollo 13 crew returned safely to earth. The Challenger was a space shuttle that malfunctioned, killing all seven passengers. The Space Shuttle Columbia disaster had seven casualties.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Were deaths from <fact1>Apollo 13 mission</fact1> eclipsed by <fact2>other space missions</fact2>?
Answer: The <fact1>Apollo 13 mission</fact1>, while experiencing a significant malfunction, resulted in no deaths.  <fact2>Other space missions</fact2>, such as the Challenger and Columbia shuttle disasters, resulted in the deaths of all crew members. Therefore, the <fact1>Apollo 13 mission</fact1> had zero deaths, a number not eclipsed by the death tolls of <fact2>these other missions</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The reasoning chain contains a logical error in interpreting the question, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Therefore, the Apollo 13 mission had zero deaths, a number not eclipsed by the death tolls of these other missions.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The question asks if the deaths from Apollo 13 were eclipsed by other missions. Since there were zero deaths in Apollo 13, any mission with deaths would eclipse it. The reasoning here misinterprets the question.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Therefore, the Apollo 13 mission had zero deaths, a number not eclipsed by the death tolls of these other missions.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">All of the Apollo 13 crew returned safely to earth. The Challenger was a space shuttle that malfunctioned, killing all seven passengers. The Space Shuttle Columbia disaster had seven casualties.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-102')">
            <div class="question-text">
                <div class="question-id">Question #102</div>
                Can you purchase a dish with injera at Taco Bell?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-102">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you purchase a dish with injera at Taco Bell?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Taco Bell serves a variety of Mexican and Tex-Mex foods that include tacos, burritos, quesadillas, and nachos. Injera is a sour fermented flatbread with a slightly spongy texture, traditionally made out of teff flour. Injera is part of Ethiopian cuisine.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can you purchase a dish with <fact1>injera</fact1> at <fact2>Taco Bell</fact2>?
Answer: <fact1>Injera</fact1> is a spongy flatbread made from teff flour and is a staple in Eritrean and Ethiopian cuisine. <fact2>Taco Bell</fact2> is a fast-food restaurant chain that specializes in Tex-Mex cuisine.  Since <fact2>Taco Bell's</fact2> menu does not include dishes featuring ingredients from East African cuisine, such as <fact1>injera</fact1>, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies injera as part of Eritrean and Ethiopian cuisine and Taco Bell as a Tex-Mex restaurant, concluding that Taco Bell would not serve injera.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-103')">
            <div class="question-text">
                <div class="question-id">Question #103</div>
                Is xenophobia hypothetically unimportant between Saladin and Ali Askari?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-103">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is xenophobia hypothetically unimportant between Saladin and Ali Askari?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Xenophobia is the dislike of someone that is foreign or from a different background. Saladin was a Kurdish leader that became sultan of Egypt. Ali Askari was a Kurdish politician.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>xenophobia</fact1> hypothetically unimportant between <fact2>Saladin</fact2> and <fact3>Ali Askari</fact3>?
Answer: <fact1>Xenophobia</fact1> is the fear and hatred of strangers or foreigners or of anything that is strange or foreign. <fact2>Saladin</fact2> was a Kurdish Muslim and <fact3>Ali Askari</fact3> was an Iraqi Shia Muslim.  Since they shared similar cultural and religious backgrounds, <fact1>xenophobia</fact1> would likely be unimportant between them. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a significant factual error by misidentifying Ali Askari as an Iraqi Shia Muslim instead of a Kurdish politician, which is a critical detail for assessing the potential for xenophobia between him and Saladin.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Ali Askari was an Iraqi Shia Muslim.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Ali Askari was a Kurdish politician, not an Iraqi Shia Muslim.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Ali Askari was an Iraqi Shia Muslim</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Ali Askari was a Kurdish politician</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-104')">
            <div class="question-text">
                <div class="question-id">Question #104</div>
                Does Sockington enjoy onions?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-104">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Sockington enjoy onions?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Sockington is a domestic cat. Onions can cause toxicity in cats by breaking down their red blood cells.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Sockington</fact1> enjoy <fact2>onions</fact2>?
Answer: <fact1>Sockington</fact1> is a cat. Cats generally do not enjoy <fact2>onions</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Sockington is a cat and that cats generally do not enjoy onions, which aligns with the reference explanation that onions can be toxic to cats.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-105')">
            <div class="question-text">
                <div class="question-id">Question #105</div>
                Was Raphael's paintings influenced by the country of Guam?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-105">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Raphael's paintings influenced by the country of Guam?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Raphael was a European painter that died in 1520. Magellan's 1521 voyage was Europe's first trip to Guam.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Raphael's paintings</fact1> influenced by the <fact2>country of Guam</fact2>?
Answer: <fact1>Raphael</fact1> lived from 1483 to 1520. <fact2>Guam</fact2> was discovered by Europeans in 1521. Since <fact1>Raphael</fact1> died the year before <fact2>Guam's</fact2> European discovery, his paintings could not have been influenced by it. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a clear and logical argument to support the answer. There are no hallucinations or errors in the reasoning.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-106')">
            <div class="question-text">
                <div class="question-id">Question #106</div>
                Could Oscar Wilde have operated a motor vehicle?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-106">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could Oscar Wilde have operated a motor vehicle?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Motor vehicles were in use by the 1890s. Oscar Wilde lived until 1900.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could <fact1>Oscar Wilde</fact1> have operated a <fact2>motor vehicle</fact2>?
Answer: <fact1>Oscar Wilde</fact1> died in 1900.  The first commercially available <fact2>motor vehicle</fact2> was the 1886 Benz Patent-Motorwagen.  Since 1886 is before 1900, it is possible that <fact1>Oscar Wilde</fact1> could have operated a <fact2>motor vehicle</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Oscar Wilde could have operated a motor vehicle because he lived until 1900, which is after the invention of the first commercially available motor vehicle in 1886. The reasoning is sound and aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-107')">
            <div class="question-text">
                <div class="question-id">Question #107</div>
                Does ontology require a scalpel?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-107">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does ontology require a scalpel?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A scalpel is used during surgery. Ontology is a philosophical domain, not a medical one.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>ontology</fact1> require a <fact2>scalpel</fact2>?
Answer: <fact1>Ontology</fact1> is the branch of metaphysics dealing with the nature of being. A <fact2>scalpel</fact2> is a small and extremely sharp bladed instrument used for surgery, anatomical dissection, and various arts and crafts.  Since <fact1>ontology</fact1> is a philosophical pursuit and <fact2>a scalpel</fact2> is a physical tool used in medical and other practical applications, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why ontology does not require a scalpel, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-108')">
            <div class="question-text">
                <div class="question-id">Question #108</div>
                Was King Arthur at the beheading of Anne Boleyn?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-108">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was King Arthur at the beheading of Anne Boleyn?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. King Arthur was a legendary British leader who, according to medieval histories and romances, led the defence of Britain against Saxon invaders in the late 5th and early 6th centuries. Anne Boleyn was beheaded May 19, 1536.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>King Arthur</fact1> at the <fact2>beheading</fact2> of <fact3>Anne Boleyn</fact3>?
Answer: <fact3>Anne Boleyn</fact3> was beheaded in 1536.  <fact1>King Arthur</fact1> is a legendary figure who, if he existed, would have lived centuries earlier. Therefore, <fact1>King Arthur</fact1> could not have been present at <fact3>Anne Boleyn's beheading</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that King Arthur could not have been at Anne Boleyn's beheading because they lived in different time periods, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-109')">
            <div class="question-text">
                <div class="question-id">Question #109</div>
                Would Alexander Graham Bell hypothetically support Nazi eugenics?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-109">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Alexander Graham Bell hypothetically support Nazi eugenics?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Eugenics was the idea of selective breeding or sterilization to rid the human populace of certain traits. Nazis used eugenics to justify mass sterilization and mass murder. Alexander Graham Bell Alexander Graham Bell advocated against the use of sign language and hoped to eradicate deafness through selective breeding.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>Alexander Graham Bell</fact1> hypothetically support <fact2>Nazi eugenics</fact2>?
Answer: <fact1>Alexander Graham Bell</fact1> was a proponent of eugenics. <fact2>Nazi eugenics</fact2> was based upon the same principles as Bell's beliefs. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Alexander Graham Bell as a proponent of eugenics and draws a parallel between his beliefs and the principles underlying Nazi eugenics.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-110')">
            <div class="question-text">
                <div class="question-id">Question #110</div>
                Was Harry Truman's presidency unaffected by the twenty-third Amendment to the US Constitution?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-110">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Harry Truman's presidency unaffected by the twenty-third Amendment to the US Constitution?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The 23rd Amendment to the US Constitution was passed in 1961. Harry Truman was the President from 1945-1953.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Harry Truman's presidency</fact1> unaffected by the <fact2>twenty-third Amendment</fact2> to the <fact3>US Constitution</fact3>?
Answer: The <fact2>Twenty-third Amendment</fact2> grants the District of Columbia electors in the Electoral College.  The <fact2>Twenty-third Amendment</fact2> was ratified in 1961. <fact1>Harry Truman's presidency</fact1> ended in 1953. Therefore, <fact1>his presidency</fact1> was unaffected by the <fact2>Twenty-third Amendment</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Harry Truman's presidency was unaffected by the Twenty-third Amendment because the amendment was ratified after his presidency ended. The reasoning is clear, concise, and accurate.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-111')">
            <div class="question-text">
                <div class="question-id">Question #111</div>
                Would the trees in Auburn, New York be changing colors in September?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-111">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would the trees in Auburn, New York be changing colors in September?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In New York, fall begins during the month of September.  When the weather gets cooler in the fall, leaves begin to change colors.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would the trees in <fact1>Auburn, New York</fact1> be changing colors in <fact2>September</fact2>?
Answer: <fact1>Auburn, New York</fact1> is located in the northeastern United States.  <fact2>September</fact2> marks the beginning of fall in the northeast. Trees in the northeast are known for their vibrant fall foliage. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a logical and factually correct justification for the answer. There are no hallucinations or errors present.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-112')">
            <div class="question-text">
                <div class="question-id">Question #112</div>
                Is Black Lives Matter connected with capsaicin?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-112">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Black Lives Matter connected with capsaicin?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Black Lives Matter has held numerous protests. Protesters at Black Lives Matter events have had pepper spray used against them by police. Capsaicin is the main ingredient of pepper spray.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>Black Lives Matter</fact1> connected with <fact2>capsaicin</fact2>?
Answer: <fact1>Black Lives Matter</fact1> is a social movement advocating for racial equality. <fact2>Capsaicin</fact2> is a chemical compound found in chili peppers. There is no known connection between <fact1>Black Lives Matter</fact1> and <fact2>capsaicin</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain incorrectly states that there is no connection between Black Lives Matter and capsaicin, contradicting the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">There is no known connection between Black Lives Matter and capsaicin.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Black Lives Matter protesters have had pepper spray (whose main ingredient is capsaicin) used against them by police, which establishes a connection.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">There is no known connection between Black Lives Matter and capsaicin.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Protesters at Black Lives Matter events have had pepper spray used against them by police. Capsaicin is the main ingredient of pepper spray.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-113')">
            <div class="question-text">
                <div class="question-id">Question #113</div>
                Was Achilles a direct descendent of Gaia?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-113">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Achilles a direct descendent of Gaia?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Achilles was the son of a Nereid.  The Nereids were the 50 daughters of Nereus. Nereus was the eldest son of the union between Gaia and Pontus.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Achilles</fact1> a direct descendant of <fact2>Gaia</fact2>?
Answer: <fact1>Achilles</fact1>'s mother was Thetis, a sea nymph.  Thetis's parents were Nereus and Doris, who were children of Oceanus and Tethys. Oceanus and Tethys were Titans, children of <fact2>Gaia</fact2> and Uranus. Since <fact1>Achilles</fact1>'s maternal great-grandparents were children of <fact2>Gaia</fact2>, <fact1>Achilles</fact1> was a descendant, though not a *direct* descendant, of <fact2>Gaia</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain incorrectly identifies Achilles's mother as Thetis instead of a Nereid, leading to a flawed lineage tracing and ultimately a wrong conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Achilles's mother was Thetis, a sea nymph.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Achilles was the son of a Nereid, not Thetis.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Achilles's mother was Thetis</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Achilles was the son of a Nereid</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-114')">
            <div class="question-text">
                <div class="question-id">Question #114</div>
                Does Jerry Seinfeld hang out at the Budweiser Party Deck?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-114">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Jerry Seinfeld hang out at the Budweiser Party Deck?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Budweiser Party Deck is a social gathering spot in Yankee Stadium. Yankee Stadium is home to the New York Yankees baseball team. Jerry Seinfeld is a fan of the New York Mets.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Jerry Seinfeld</fact1> hang out at the <fact2>Budweiser Party Deck</fact2>?
Answer: <fact1>Jerry Seinfeld</fact1> is a comedian and actor.  The <fact2>Budweiser Party Deck</fact2> is located at Busch Stadium in St. Louis. There's no publicly available information connecting <fact1>Jerry Seinfeld</fact1> to the <fact2>Budweiser Party Deck</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning incorrectly states the location of the Budweiser Party Deck, claiming it's in Busch Stadium instead of Yankee Stadium.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Budweiser Party Deck is located at Busch Stadium in St. Louis.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The Budweiser Party Deck is located in Yankee Stadium, not Busch Stadium.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Busch Stadium in St. Louis</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Yankee Stadium</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-115')">
            <div class="question-text">
                <div class="question-id">Question #115</div>
                Can you hide a basketball in a sand cat's ear?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-115">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you hide a basketball in a sand cat's ear?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The diameter of a standard NBA basketball is around 9.5 inches. A sand cat's ear grows to 2.8 inches tall.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can you hide a <fact1>basketball</fact1> in a <fact2>sand cat's ear</fact2>?
Answer: A <fact1>basketball</fact1> is significantly larger than a <fact2>sand cat's ear</fact2>.  Therefore, you cannot hide a <fact1>basketball</fact1> in a <fact2>sand cat's ear</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that a basketball is significantly larger than a sand cat's ear, thus it cannot be hidden inside.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-116')">
            <div class="question-text">
                <div class="question-id">Question #116</div>
                Could the Spice Girls compete against ≈ΩRK Kumanovo?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-116">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could the Spice Girls compete against ≈ΩRK Kumanovo?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Spice Girls had 5 members. ≈ΩRK Kumanovo is a women's handball club from Kumanovo in the Republic of Macedonia. Handball is a sport played by two teams of seven players each.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could the <fact1>Spice Girls</fact1> compete against <fact2>≈ΩRK Kumanovo</fact2>?
Answer: The <fact1>Spice Girls</fact1> are a British pop group. <fact2>≈ΩRK Kumanovo</fact2> is a professional handball team.  Since the <fact1>Spice Girls</fact1> are singers and <fact2>≈ΩRK Kumanovo</fact2> are athletes in a completely different field, they could not compete against each other. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that the Spice Girls and ≈ΩRK Kumanovo are in completely different fields (music vs. professional handball) and therefore could not compete against each other. This aligns with the reference explanation, which states that ≈ΩRK Kumanovo is a women's handball club and the Spice Girls had 5 members, implying they are not a handball team.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-117')">
            <div class="question-text">
                <div class="question-id">Question #117</div>
                Does the swastika have positive uses?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-117">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does the swastika have positive uses?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The swastika is used in the Hindu religion to represent the sun. People practicing Hindu believe the swastika represents prosperity and good luck.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does the <fact1>swastika</fact1> have <fact2>positive uses</fact2>?
Answer: The <fact1>swastika</fact1> symbol has been used for over 3,000 years and in many cultures represents <fact2>good fortune and well-being</fact2>.  In Hinduism, Buddhism, Jainism, and other Eastern religions, <fact1>the swastika</fact1> continues to be a sacred symbol associated with <fact2>positive meanings</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain includes information not present in the reference explanation, specifically mentioning Buddhism, Jainism, and other Eastern religions, which constitutes a logical error.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">In Hinduism, Buddhism, Jainism, and other Eastern religions, the swastika continues to be a sacred symbol associated with positive meanings.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference only mentions Hinduism. The inclusion of Buddhism, Jainism, and other Eastern religions is not supported by the reference and implies a broader scope than what is provided.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">In Hinduism, Buddhism, Jainism, and other Eastern religions, the swastika continues to be a sacred symbol associated with positive meanings.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">the swastika is used in the Hindu religion to represent the sun.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-118')">
            <div class="question-text">
                <div class="question-id">Question #118</div>
                Was Black fly upstaged by another insect in Jeff Goldblum's 1986 film?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-118">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Black fly upstaged by another insect in Jeff Goldblum's 1986 film?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Jeff Goldnlum starred in the 1986 movie The Fly. The fly used in the movie The Fly was a common Housefly. The Black fly is most closely related to Chironomidae since they both feed on mammals.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Black fly</fact1> upstaged by another insect in <fact2>Jeff Goldblum's</fact2> <fact3>1986 film</fact3>?
Answer: <fact2>Jeff Goldblum</fact2> starred in "The Fly" in <fact3>1986</fact3>. In the film, <fact2>he</fact2> transforms into a fly-like creature.  While referred to as "Brundlefly," the creature is not specifically a <fact1>black fly</fact1>, and the transformation focuses on a hybrid human-fly creature. Therefore, there isn't another insect upstaging a <fact1>black fly</fact1>, making the answer {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning contains a logical error by misinterpreting the type of fly used in the movie, as specified in the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">In the film, he transforms into a fly-like creature. While referred to as "Brundlefly," the creature is not specifically a black fly, and the transformation focuses on a hybrid human-fly creature.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the fly used in the movie was a common Housefly. The generated reasoning misinterprets this fact by stating that the creature is not specifically a black fly, implying that it could be some other type of fly, when the reference specifies it was a common Housefly.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">the creature is not specifically a black fly</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The fly used in the movie The Fly was a common Housefly.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-119')">
            <div class="question-text">
                <div class="question-id">Question #119</div>
                Did Linnaeus edit Darwin's draft of Origin of Species?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-119">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Linnaeus edit Darwin's draft of Origin of Species?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Linnaeus died in 1778. Origin of Species was published in 1859.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Linnaeus</fact1> edit Darwin's draft of <fact2>Origin of Species</fact2>?
Answer: <fact1>Carl Linnaeus</fact1> died in 1778.  Darwin's <fact2>On the Origin of Species</fact2> was published in 1859.  Therefore, <fact1>Linnaeus</fact1> could not have edited Darwin's work. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Linnaeus could not have edited Darwin's work because Linnaeus died before Darwin's work was published. The reasoning is sound and consistent with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-120')">
            <div class="question-text">
                <div class="question-id">Question #120</div>
                Do all cancer patients get disability?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-120">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do all cancer patients get disability?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. All forms of cancer qualify as diagnoses that can result in disability. Disability is not determined by diagnosis, but by degree of impairment. Some cancer patients do not experience major impairment.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>all</fact1> <fact2>cancer patients</fact2> get <fact3>disability</fact3>?
Answer:  Not <fact1>all</fact1> <fact2>cancer patients</fact2> qualify for <fact3>disability</fact3>. Disability benefits are typically awarded based on the severity of the illness and its impact on the individual's ability to work.  Some <fact2>cancer patients</fact2> may have less aggressive forms of cancer or respond well to treatment, allowing them to continue working.  Therefore, while some <fact2>cancer patients</fact2> may qualify for <fact3>disability</fact3>, it is not a guarantee for <fact1>all</fact1> patients.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that not all cancer patients qualify for disability because disability is determined by the degree of impairment, not just the diagnosis.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-121')">
            <div class="question-text">
                <div class="question-id">Question #121</div>
                Did the death of Helen Palmer have a significant effect on Dr. Seuss?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-121">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the death of Helen Palmer have a significant effect on Dr. Seuss?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Dr. Seuss's real name was Theodor Geisel. Theodor Geisel was married to Helen Palmer at the time of her suicide. Theodor Geisel is quoted having said he considered suicide after the death of his wife.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did the <fact1>death of Helen Palmer</fact1> have a significant effect on <fact2>Dr. Seuss</fact2>?
Answer: <fact1>Helen Palmer Geisel</fact1> was <fact2>Dr. Seuss</fact2>' first wife.  She suffered from illnesses for many years, and after being diagnosed with a brain tumor, she took her own life in 1967.  <fact2>Dr. Seuss</fact2> blamed himself for her suffering and her death, and it had a profound impact on him. He remarried the following year, but many believe his later works reflect the sadness and guilt he carried after <fact1>Helen's death</fact1>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies Helen Palmer as Dr. Seuss' first wife, mentions her suicide, and highlights the profound impact it had on Dr. Seuss. There are no contradictions, entity swaps, or logical errors present.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-122')">
            <div class="question-text">
                <div class="question-id">Question #122</div>
                Can fish get Tonsillitis?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-122">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can fish get Tonsillitis?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Tonsils are a pair of soft tissue masses located at the rear of the throat. Tonsillitis is the inflammation of tonsils. Fish do not have tonsils. Tonsils are only found in mammals.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can <fact1>fish</fact1> get <fact2>Tonsillitis</fact2>?
Answer: <fact2>Tonsillitis</fact2> is the inflammation of the tonsils. <fact1>Fish</fact1> do not have tonsils. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation, stating that fish do not have tonsils and therefore cannot get tonsillitis.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-123')">
            <div class="question-text">
                <div class="question-id">Question #123</div>
                Would it be impossible to get to Burning Man on the Mayflower?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-123">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would it be impossible to get to Burning Man on the Mayflower?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Mayflower was a seafaring vessel. Burning Man is held in Black Rock Desert. There are no bodies of water flowing into the Black Rock Desert.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would it be impossible to get to <fact1>Burning Man</fact1> on the <fact2>Mayflower</fact2>?
Answer: <fact1>Burning Man</fact1> is an annual event held in the Black Rock Desert of Nevada. The <fact2>Mayflower</fact2> was a 17th-century ship that transported the Pilgrims to North America.  Given the vastly different time periods and locations of <fact1>Burning Man</fact1> and the voyage of the <fact2>Mayflower</fact2>, it would be impossible to travel to the event on that ship. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies the impossibility of traveling to Burning Man on the Mayflower, citing the different time periods and locations. The reasoning aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-124')">
            <div class="question-text">
                <div class="question-id">Question #124</div>
                Does Lupita Nyongo have citizenship in paternal Family of Barack Obama's origin country?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-124">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Lupita Nyongo have citizenship in paternal Family of Barack Obama's origin country?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Actress Lupita Nyongo has dual citizenship in Kenya and Mexico. Barack Obama's father was born in Nyang‚Äôoma Kogelo, Rachuonyo District, Kenya Colony. Barack Obama's father was a Kenyan of the Luo tribe.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Lupita Nyong'o</fact1> have citizenship in <fact2>Barack Obama's</fact2> paternal <fact3>Family's origin country</fact3>?
Answer: <fact1>Lupita Nyong'o</fact1> was born in Mexico City, but both of her parents are Kenyan. <fact1>Lupita Nyong'o</fact1> holds dual citizenship in Kenya and Mexico.  <fact2>Barack Obama's</fact2> paternal <fact3>family</fact3> originates from Kenya.  Therefore, <fact1>Lupita Nyong'o</fact1> holds citizenship in <fact3>Kenya</fact3>, <fact2>Barack Obama's</fact2> paternal <fact3>family's origin country</fact3>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Lupita Nyong'o holds citizenship in Kenya, which is the origin country of Barack Obama's paternal family, as stated in the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-125')">
            <div class="question-text">
                <div class="question-id">Question #125</div>
                Are there enough Jonny Cash records in the world to give one to each French citizen?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-125">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are there enough Jonny Cash records in the world to give one to each French citizen?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Johnny Cash has sold about 90 million albums. The population of France is around 66 million .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are there enough <fact1>Jonny Cash records</fact1> in the world to give one to each <fact2>French citizen</fact2>?
Answer: There are an estimated <fact1>150 million Johnny Cash records</fact1> sold worldwide. The population of <fact2>France</fact2> is about 67 million.  Since 150 million is greater than 67 million, there are enough <fact1>Johnny Cash records</fact1> to give one to each <fact2>French citizen</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error regarding the number of Johnny Cash records sold. The rest of the reasoning is sound.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">There are an estimated 150 million Johnny Cash records sold worldwide.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that there are 150 million Johnny Cash records sold worldwide, but the reference explanation states that Johnny Cash has sold about 90 million albums.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">150 million Johnny Cash records sold worldwide</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">90 million albums</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-126')">
            <div class="question-text">
                <div class="question-id">Question #126</div>
                Could someone mistake the smell of your brussels sprouts for a fart?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-126">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could someone mistake the smell of your brussels sprouts for a fart?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Brussels Sprouts are cruciferous vegetables. Cruciferous vegetables have a sulfur containing chemical called glucosinolate in them. When you cook brussels sprouts, their smell intensifies.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could someone mistake the smell of <fact1>your brussels sprouts</fact1> for a <fact2>fart</fact2>?
Answer: <fact1>Brussels sprouts</fact1> contain sulfur-containing compounds.  <fact2>Flatulence</fact2> also often contains sulfur-containing compounds.  The sulfur compounds are what create the unpleasant odor associated with both <fact1>brussels sprouts</fact1> and <fact2>farts</fact2>. Therefore, it is possible that someone could mistake the smell of <fact1>cooking brussels sprouts</fact1> for <fact2>flatulence</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly identifies the presence of sulfur-containing compounds in both brussels sprouts and flatulence, leading to the conclusion that the smells could be mistaken for each other.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-127')">
            <div class="question-text">
                <div class="question-id">Question #127</div>
                Can Stone Cold Steve Austin apply his finisher to a mule deer?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-127">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can Stone Cold Steve Austin apply his finisher to a mule deer?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Steve Austin's finisher, The Stone Cold Stunner, involves lifting the opponent and then pulling their head down. The largest male mule deer's are around 330 pounds. Steve Austin has applied his finisher to the wrestler The Big Show. The Big Show weighs 383 pounds.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could <fact1>Stone Cold Steve Austin</fact1> apply his finisher (the Stone Cold Stunner) to a <fact2>mule deer</fact2>?
Answer: <fact1>Stone Cold Steve Austin's</fact1> finisher, the Stone Cold Stunner, requires a willing participant to jump into the air and allow the wrestler to bring them down onto their back. A <fact2>mule deer</fact2> would neither jump into the air nor take part in wrestling, thus <fact1>Stone Cold</fact1> could not apply his finisher. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain hallucinates that the Stone Cold Stunner requires a willing participant to jump, which is false. The reference states that it involves lifting the opponent and pulling their head down.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Stone Cold Steve Austin's finisher, the Stone Cold Stunner, requires a willing participant to jump into the air and allow the wrestler to bring them down onto their back.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The Stone Cold Stunner does not require a willing participant to jump into the air. It involves lifting the opponent and then pulling their head down.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Stone Cold Steve Austin's finisher, the Stone Cold Stunner, requires a willing participant to jump into the air and allow the wrestler to bring them down onto their back.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Steve Austin's finisher, The Stone Cold Stunner, involves lifting the opponent and then pulling their head down.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-128')">
            <div class="question-text">
                <div class="question-id">Question #128</div>
                Is the Joker in a healthy romantic relationship?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-128">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is the Joker in a healthy romantic relationship?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Healthy relationships are characterized by mutual trust and respect. The Joker is dating Harley Quinn. The Joker frequently abuses and talks down to Harley.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is the <fact1>Joker</fact1> in a <fact2>healthy romantic relationship</fact2>?
Answer: The <fact1>Joker</fact1> is a fictional character known for his chaotic and abusive behavior. A <fact2>healthy romantic relationship</fact2> involves mutual respect, trust, and support, which are qualities absent in the <fact1>Joker's</fact1> interactions, particularly with Harley Quinn, who is often portrayed as a victim of his manipulation and abuse.  Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that the Joker is not in a healthy romantic relationship due to his abusive behavior towards Harley Quinn.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-129')">
            <div class="question-text">
                <div class="question-id">Question #129</div>
                Is the kayak a traditional boat in New Zealand?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-129">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is the kayak a traditional boat in New Zealand?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Kayaks were developed by native peoples to hunt in northern waters of the Arctic Ocean, North Atlantic, Bering Sea and North Pacific.  New Zealand is in the Southern Hemisphere. The native Maori people of New Zealand arrived there in canoes.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is the <fact1>kayak</fact1> a <fact2>traditional boat</fact2> in <fact3>New Zealand</fact3>?
Answer: The <fact1>kayak</fact1> originated with the Inuit, Yup'ik, and Aleut peoples in the Arctic regions.  <fact3>New Zealand's</fact3> traditional boat is the waka, a large outrigger canoe.  Therefore, the <fact1>kayak</fact1> is not a <fact2>traditional boat</fact2> of <fact3>New Zealand</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that kayaks are not traditional boats in New Zealand, and accurately states that New Zealand's traditional boat is the waka.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-130')">
            <div class="question-text">
                <div class="question-id">Question #130</div>
                Did Boris Yeltsin watch the 2008 Summer Olympics?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-130">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Boris Yeltsin watch the 2008 Summer Olympics?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The 2008 Summer Olympics were held Aug 08 - 24, 2008. Boris Yeltsin died on Apr 23, 2007.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Boris Yeltsin</fact1> watch the <fact2>2008 Summer Olympics</fact2>?
Answer: <fact1>Boris Yeltsin</fact1> died in 2007. The <fact2>2008 Summer Olympics</fact2> occurred in 2008.  Therefore, <fact1>he</fact1> could not have watched the <fact2>2008 Summer Olympics</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly states that Boris Yeltsin died in 2007 and the 2008 Summer Olympics occurred in 2008. It then correctly concludes that he could not have watched the Olympics.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-131')">
            <div class="question-text">
                <div class="question-id">Question #131</div>
                Did the swallow play a role in a famous film about King Arthur?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-131">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the swallow play a role in a famous film about King Arthur?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Monty Python and the Holy Grail was a famous film about King Arthur. In Monty Python and the Holy Grail, swallows are mentioned several times.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did the <fact1>swallow</fact1> play a role in a famous film about <fact2>King Arthur</fact2>?
Answer: In *Monty Python and the Holy Grail,* a famous comedic film about <fact2>King Arthur</fact2>, there is a scene where <fact1>a swallow</fact1> is discussed as a potential means of carrying a coconut.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, confirming the role of swallows in the film about King Arthur.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-132')">
            <div class="question-text">
                <div class="question-id">Question #132</div>
                Was Michael Crichton ever in danger of flunking out of Harvard as an undergraduate?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-132">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Michael Crichton ever in danger of flunking out of Harvard as an undergraduate?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Scholastic probation or academic dismissal, sometimes known as flunking out, is the termination of students at a higher educational institution as the result of poor academic achievement. Michael Crichton obtained his bachelor's degree in biological anthropology summa cum laude in 1964. Summa cum laude is the highest distinction a person can achieve in college for academic success. Someone who achieves summa cum laude cannot have even a single semester of poor grades.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Michael Crichton</fact1> ever in danger of <fact2>flunking out</fact2> of <fact3>Harvard</fact3> as an <fact4>undergraduate</fact4>?
Answer: <fact1>Michael Crichton</fact1> <fact4>graduated summa cum laude</fact4> from <fact3>Harvard</fact3>. Therefore, <fact1>he</fact1> was not in danger of <fact2>flunking out</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation. It correctly infers that someone who graduated summa cum laude could not have been in danger of flunking out.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-133')">
            <div class="question-text">
                <div class="question-id">Question #133</div>
                Was Surfing popular when pogs came out?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-133">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Surfing popular when pogs came out?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Pogs came out in the 1990's. The 90's saw a rise in 'Big Wave Culture', a practice involving finding the largest possible waves to surf on.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Surfing</fact1> popular when <fact2>pogs</fact2> came out?
Answer: <fact2>Pogs</fact2> were popular in the mid-1990s. <fact1>Surfing</fact1> was already a popular sport by the mid-1990s. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly infers that surfing was popular when pogs came out, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-134')">
            <div class="question-text">
                <div class="question-id">Question #134</div>
                Could a student at the University of Houston see a caracal on campus?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-134">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a student at the University of Houston see a caracal on campus?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The caracal is native to Africa, the Middle East, Central Asia, and India. The University of Houston is located in the United States. The United States is located in North America.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could a student at the <fact1>University of Houston</fact1> see a <fact2>caracal</fact2> on campus?
Answer:  <fact2>Caracals</fact2> are wild cats native to Africa, the Middle East, Central Asia, and India.  They are not native to Texas, where the <fact1>University of Houston</fact1> is located. While it's *possible* a <fact2>caracal</fact2> could escape from a zoo or private owner and end up near the <fact1>University of Houston</fact1> campus, it is extremely unlikely. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that caracals are not native to Texas, where the University of Houston is located. It also acknowledges the remote possibility of a caracal escaping from captivity but deems it extremely unlikely.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-135')">
            <div class="question-text">
                <div class="question-id">Question #135</div>
                Did the Coen brothers ever collaborate with the Brothers Grimm?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-135">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the Coen brothers ever collaborate with the Brothers Grimm?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Coen brothers were born in 1954 and 1957. The Brothers Grimm died in 1859 and 1863.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did the <fact1>Coen brothers</fact1> ever collaborate with the <fact2>Brothers Grimm</fact2>?
Answer: The <fact1>Coen brothers</fact1> are contemporary filmmakers. The <fact2>Brothers Grimm</fact2> are famous for their fairy tales, and died in the 19th century.  Therefore, collaboration between the <fact1>Coen brothers</fact1> and the <fact2>Brothers Grimm</fact2> would be impossible. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why the Coen brothers could not have collaborated with the Brothers Grimm, based on their respective lifespans.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-136')">
            <div class="question-text">
                <div class="question-id">Question #136</div>
                Could a hundred thousand lolcats fit on a first generation iPhone?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-136">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could a hundred thousand lolcats fit on a first generation iPhone?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Lolcat memes are often in jpeg form. The average size of a jpeg is 10 to 30 kb. One gigabyte is 1000000 kb. The first iPhone had 4GB to 16GB of storage .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could <fact1>a hundred thousand lolcats</fact1> fit on a <fact2>first generation iPhone</fact2>?
Answer: A <fact2>first-generation iPhone</fact2> had storage options of 4GB or 8GB.  <fact1>One hundred thousand lolcats</fact1>, assuming an average image size (which could vary wildly), would likely take up far more space than even 8GB.  Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning makes a logical error in calculating the storage space required for 100,000 lolcats, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">One hundred thousand lolcats, assuming an average image size (which could vary wildly), would likely take up far more space than even 8GB.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning makes a logical error. The reference states that the average size of a jpeg is 10 to 30 kb. 100,000 lolcats at 30kb each would take up 3,000,000 kb, which is 3GB. This would fit on a first generation iPhone.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">would likely take up far more space than even 8GB</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The average size of a jpeg is 10 to 30 kb. One gigabyte is 1000000 kb. The first iPhone had 4GB to 16GB of storage</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-137')">
            <div class="question-text">
                <div class="question-id">Question #137</div>
                Are monks forbidden from engaging in warfare?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-137">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are monks forbidden from engaging in warfare?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Monks are members of religious orders that usually take vows of poverty, chastity, and obedience. The Knights Templar were a religious order that fought during the Crusades and captured Jerusalem in 1099. Buddhist Shaolin monks developed very powerful martial arts skills, have defended temples during conquests.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are <fact1>monks</fact1> forbidden from engaging in <fact2>warfare</fact2>?
Answer: The <fact1>monastic code</fact1> generally emphasizes non-violence and pacifism.  Therefore, most <fact1>monks</fact1> are forbidden from participating in <fact2>warfare</fact2>. There are some historical exceptions such as warrior monks, but these are not representative of the vast majority of monastic traditions.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain makes a generalization about monks being forbidden from warfare, which is contradicted by the reference explanation that provides examples of monks participating in warfare.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Therefore, most monks are forbidden from participating in warfare.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation provides examples of monks engaging in warfare, such as the Knights Templar and Buddhist Shaolin monks. This directly contradicts the statement that most monks are forbidden from participating in warfare.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Therefore, most monks are forbidden from participating in warfare.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Knights Templar were a religious order that fought during the Crusades and captured Jerusalem in 1099. Buddhist Shaolin monks developed very powerful martial arts skills, have defended temples during conquests.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-138')">
            <div class="question-text">
                <div class="question-id">Question #138</div>
                Is the BBC World Service hosted in Europe?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-138">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is the BBC World Service hosted in Europe?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The BBC World Service is part of the BBC network. The BBC operates in England. England is part of Europe.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is the <fact1>BBC World Service</fact1> hosted in <fact2>Europe</fact2>?
Answer: The <fact1>BBC World Service</fact1> is headquartered in London, which is located in the <fact2>United Kingdom, a European country</fact2>. Thus, the <fact1>BBC World Service</fact1> is hosted in <fact2>Europe</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a clear and concise justification for the answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-139')">
            <div class="question-text">
                <div class="question-id">Question #139</div>
                Would 1996 leap year baby technically be 1 year old in 2000?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-139">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would 1996 leap year baby technically be 1 year old in 2000?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. A leap year happens once every 4 years and has 29 days in February. The years 1996, 2000, 2004, 2008, 2012, 2016, and 2020 are the last 7 leap years that have happened. 1996 to 2000 is one leap year.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>1996 leap year baby</fact1> technically be <fact2>1 year old</fact2> in <fact3>2000</fact3>?
Answer: A <fact1>baby born in 1996</fact1> would experience the year 1997, 1998, 1999, and <fact3>2000</fact3>. This means the <fact1>baby</fact1> would have lived through 4 years.  Therefore, in <fact3>2000</fact3>, the baby would be 4 years old, not <fact2>1 year old</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly calculates the age of the baby.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-140')">
            <div class="question-text">
                <div class="question-id">Question #140</div>
                Did Clark Gable marry more women once than Richard Burton?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-140">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Clark Gable marry more women once than Richard Burton?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Richard Burton was married to Elizabeth Taylor twice.  Richard Burton married Sally Burton, Suzy Hunt, and Sybil Williams once. Clark Gable was married to five different women, one time each.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Clark Gable</fact1> marry more women <fact2>once</fact2> than <fact3>Richard Burton</fact3>?
Answer: <fact1>Clark Gable</fact1> married five times. <fact3>Richard Burton</fact3> married twice, but to the same woman, Elizabeth Taylor, meaning he married her <fact2>once</fact2> and then remarried her again. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a significant logical error in calculating the number of times Richard Burton was married, leading to an incorrect conclusion.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Richard Burton married twice, but to the same woman, Elizabeth Taylor, meaning he married her once and then remarried her again.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning misinterprets the number of times Richard Burton was married. The reference states that Richard Burton was married to Elizabeth Taylor twice, and also married Sally Burton, Suzy Hunt, and Sybil Williams once each. This means he was married a total of 5 times, not twice.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Richard Burton married twice, but to the same woman, Elizabeth Taylor, meaning he married her once and then remarried her again.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Richard Burton was married to Elizabeth Taylor twice. Richard Burton married Sally Burton, Suzy Hunt, and Sybil Williams once.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-141')">
            <div class="question-text">
                <div class="question-id">Question #141</div>
                Is one blast from double-barreled shotgun likely to kill all squid brains?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-141">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is one blast from double-barreled shotgun likely to kill all squid brains?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A double-barreled shotgun fires two rounds in one single blast. Squids have three brains.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>one blast</fact1> from a <fact2>double-barreled shotgun</fact2> likely to kill <fact3>all squid brains</fact3>?
Answer: A <fact2>double-barreled shotgun</fact2> fires two shotshells at once, meaning <fact1>one blast</fact1> will deliver a wide spread of pellets.  <fact3>Squid</fact3> have a complex nervous system and multiple ganglia, not just one centralized brain. While a <fact1>shotgun blast</fact1> would certainly be lethal to a <fact3>squid</fact3> hit directly, it's unlikely to destroy *all* neural tissue with <fact1>a single blast</fact1> if the <fact3>squid</fact3> is large enough or the range is great enough to spread the pellets widely. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning contradicts the reference by stating that squids have a complex nervous system and multiple ganglia, not just one centralized brain, while the reference states that squids have three brains.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Squid have a complex nervous system and multiple ganglia, not just one centralized brain.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that squids have three brains. The generated reasoning states that squids have a complex nervous system and multiple ganglia, not just one centralized brain. This contradicts the reference.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Squid have a complex nervous system and multiple ganglia, not just one centralized brain.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Squids have three brains.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-142')">
            <div class="question-text">
                <div class="question-id">Question #142</div>
                Do women often need new shoes during their pregnancy?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-142">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do women often need new shoes during their pregnancy?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Pregnancy can cause swelling in the feet and legs. For safety and comfort, one needs to get new shoes if the size of their feet change.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>women</fact1> often need <fact2>new shoes</fact2> during their <fact3>pregnancy</fact3>?
Answer: During <fact3>pregnancy</fact3>, <fact1>women</fact1>'s feet often swell due to water retention and hormonal changes. This swelling can make their current shoes too tight and uncomfortable. Therefore, many <fact1>women</fact1> find they need <fact2>new shoes</fact2> in a larger size or with a wider fit to accommodate their swollen feet during <fact3>pregnancy</fact3>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, providing a clear and logical explanation for why women often need new shoes during pregnancy.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-143')">
            <div class="question-text">
                <div class="question-id">Question #143</div>
                Are some adherents to Christianity in China historic enemies of Catholic Church?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-143">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are some adherents to Christianity in China historic enemies of Catholic Church?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Christianity in China is comprised of several different groups including: Protestants, Catholics, Evangelicals, and Orthodox Christians. Catholics have been at war with Protestants throughout history. The 1572 St. Bartholomew's Day Massacre saw thousands of Protestants killed by Catholic mobs. English Protestant rulers killed many Irish Catholics during the Reformation.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are some adherents to <fact1>Christianity</fact1> in <fact2>China</fact2> historic enemies of the <fact3>Catholic Church</fact3>?
Answer: <fact1>Christianity</fact1> encompasses various denominations, including Protestantism and Catholicism.  The <fact3>Catholic Church</fact3>, specifically, has had a complex relationship with <fact2>China</fact2>.  Historically, there have been tensions and conflicts between the <fact3>Catholic Church</fact3> and other Christian groups, as well as between the <fact3>Catholic Church</fact3> and the Chinese government. Therefore, it's true that some adherents to <fact1>Christianity</fact1> in <fact2>China</fact2> have historically been at odds with the <fact3>Catholic Church</fact3>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning makes a logical error by broadening the scope of conflict beyond what is stated in the reference explanation. It introduces the idea of tensions between the Catholic Church and the Chinese government, which is not mentioned in the reference.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Historically, there have been tensions and conflicts between the Catholic Church and other Christian groups, as well as between the Catholic Church and the Chinese government.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Catholics have been at war with Protestants throughout history. The generated reasoning broadens this to tensions between the Catholic Church and other Christian groups, as well as the Chinese government. The reference does not mention tensions with the Chinese government.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Historically, there have been tensions and conflicts between the Catholic Church and other Christian groups, as well as between the Catholic Church and the Chinese government.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Catholics have been at war with Protestants throughout history.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-144')">
            <div class="question-text">
                <div class="question-id">Question #144</div>
                Is Chinese successor to Chevrolet Cruze name a town far from Milan?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-144">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Chinese successor to Chevrolet Cruze name a town far from Milan?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Chinese successor to Chevrolet Cruze is the Chevrolet Monza. Monza is a city near the north of Milan.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is the Chinese successor to the <fact1>Chevrolet Cruze</fact1> named after a town far from <fact2>Milan</fact2>?
Answer: The Chinese successor to the <fact1>Chevrolet Cruze</fact1> is the Chevrolet Monza. Monza is a city near <fact2>Milan</fact2>. Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies the Chinese successor to the Chevrolet Cruze as the Chevrolet Monza and accurately states that Monza is a city near Milan, aligning perfectly with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-145')">
            <div class="question-text">
                <div class="question-id">Question #145</div>
                Could the Dominican Order hypothetically defeat Blessed Gerard's order?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-145">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could the Dominican Order hypothetically defeat Blessed Gerard's order?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Dominican Order is a Catholic group of friars that several priestly vows. Blessed Gerard was the founder of the Order of St John of Jerusalem (Knights Hospitaller).  The Order of St John of Jerusalem (Knights Hospitaller) were a well trained Catholic military order that fought in the Crusades.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could the <fact1>Dominican Order</fact1> hypothetically defeat <fact2>Blessed Gerard's order</fact2>?
Answer: <fact2>Blessed Gerard</fact2> founded the <fact2>Order of the Knights of St. John of Jerusalem</fact2>, also known as the <fact2>Knights Hospitaller</fact2>.  The <fact2>Knights Hospitaller</fact2> were a military order. The <fact1>Dominican Order</fact1>, while influential, was a mendicant order focused on preaching and teaching, not military pursuits. In a hypothetical military conflict, the <fact2>Knights Hospitaller</fact2>, with their military training and experience, would likely defeat the <fact1>Dominican Order</fact1>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, correctly identifying the Dominican Order as a mendicant order focused on preaching and teaching, and the Knights Hospitaller as a military order. It logically concludes that the Knights Hospitaller would likely defeat the Dominican Order in a hypothetical military conflict.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-146')">
            <div class="question-text">
                <div class="question-id">Question #146</div>
                Is a pottery kiln inappropriate for use with glass blowing?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-146">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is a pottery kiln inappropriate for use with glass blowing?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Pottery kilns heat from the sides. Glass kilns heat from the top. Glass can be fused in a ceramic pottery kiln without trouble.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is a <fact1>pottery kiln</fact1> inappropriate for use with <fact2>glass blowing</fact2>?
Answer: <fact1>Pottery kilns</fact1> typically reach maximum temperatures of around 2,400¬∞F (1,315¬∞C).  <fact2>Glass blowing</fact2> requires temperatures much higher, often exceeding 2,800¬∞F (1,538¬∞C).  Because <fact1>pottery kilns</fact1> don't typically reach the required temperature for <fact2>glass blowing</fact2>, they are generally inappropriate. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain incorrectly claims that pottery kilns are inappropriate for glass blowing due to temperature limitations, contradicting the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Glass blowing requires temperatures much higher, often exceeding 2,800¬∞F (1,538¬∞C).  Because pottery kilns don't typically reach the required temperature for glass blowing, they are generally inappropriate.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that glass can be fused in a ceramic pottery kiln without trouble, contradicting the statement that pottery kilns are generally inappropriate for glass blowing due to temperature limitations.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Glass blowing requires temperatures much higher, often exceeding 2,800¬∞F (1,538¬∞C).  Because pottery kilns don't typically reach the required temperature for glass blowing, they are generally inappropriate.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Glass can be fused in a ceramic pottery kiln without trouble.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-147')">
            <div class="question-text">
                <div class="question-id">Question #147</div>
                Are there enough people in the Balkans to match the population of Japan?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-147">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are there enough people in the Balkans to match the population of Japan?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. There are approximately 55 million people in the Balkans. There are more than 125 million people in Japan.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are there enough people in the <fact1>Balkans</fact1> to match the <fact2>population</fact2> of <fact3>Japan</fact3>?
Answer: The <fact2>population</fact2> of <fact3>Japan</fact3> is about 125 million. The <fact2>population</fact2> of the <fact1>Balkans</fact1> is about 55 million.  Since 55 million is less than 125 million, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-148')">
            <div class="question-text">
                <div class="question-id">Question #148</div>
                Could Steven Spielberg send emails as a child?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-148">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Could Steven Spielberg send emails as a child?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Steven Spielberg was born in 1946. Email did not become available to the general public until 1995.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could <fact1>Steven Spielberg</fact1> send emails as a <fact2>child</fact2>?
Answer: <fact1>Steven Spielberg</fact1> was born in 1946. Email wasn't widely used until the 1990s.  A <fact2>child</fact2> in the 1950s and 60s would not have had access to email. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-149')">
            <div class="question-text">
                <div class="question-id">Question #149</div>
                Was Charles Manson's body unwanted?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-149">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Charles Manson's body unwanted?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Charles Manson's body was debated over for so long that he had to stay on ice. Charles Manson had four people fighting over his corpse.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Charles Manson's body</fact1> <fact2>unwanted</fact2>?
Answer: <fact1>Charles Manson's body</fact1> was initially <fact2>unclaimed</fact2> after his death.  <fact1>His grandson</fact1> eventually sought and won the right to <fact1>claim his remains</fact1>. Therefore, although initially <fact2>unclaimed</fact2>, <fact1>his body</fact1> was not ultimately <fact2>unwanted</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error that contradicts the reference explanation. The claim that Charles Manson's body was initially unclaimed is false, as the reference states that four people were fighting over his corpse.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Charles Manson's body was initially unclaimed after his death.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that Charles Manson's body was debated over for so long that he had to stay on ice and that four people were fighting over his corpse. This contradicts the statement that his body was initially unclaimed.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Charles Manson's body was initially unclaimed after his death.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Charles Manson had four people fighting over his corpse.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-150')">
            <div class="question-text">
                <div class="question-id">Question #150</div>
                Would a Beaver's teeth rival that of a Smilodon?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-150">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a Beaver's teeth rival that of a Smilodon?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A beaver has teeth measuring 25 mm on average. The Smilodon was a prehistoric saber-toothed tiger. The Smilodon's teeth were around 11 inches long.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>Beaver's</fact1> <fact2>teeth</fact2> rival that of a <fact3>Smilodon</fact3>?
Answer: <fact1>Beavers</fact1> have large, strong <fact2>teeth</fact2> adapted for gnawing wood.  <fact3>Smilodons</fact3>, also known as saber-toothed cats, had long, sharp canine <fact2>teeth</fact2> for hunting and killing large prey. While a <fact1>beaver's</fact1> <fact2>teeth</fact2> are impressive for their specific purpose, they would not rival the size, sharpness, or killing power of a <fact3>smilodon's</fact3> <fact2>teeth</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately compares the teeth of a beaver and a smilodon, correctly concluding that a beaver's teeth would not rival those of a smilodon.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-151')">
            <div class="question-text">
                <div class="question-id">Question #151</div>
                Is dysphoria around one's pelvis treatable without surgery?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-151">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is dysphoria around one's pelvis treatable without surgery?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. For individuals experiencing dysphoria around having a vagina, packers can relieve symptoms. For people experiencing dysphoria about having a penis, there are tucking underwear and comfort gaffs available.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>dysphoria</fact1> around one's <fact2>pelvis</fact2> treatable without <fact3>surgery</fact3>?
Answer: <fact1>Dysphoria</fact1> related to the <fact2>pelvis</fact2> can sometimes be treated without <fact3>surgery</fact3>.  Therapy, particularly gender-affirming therapy, can address the emotional distress associated with <fact1>dysphoria</fact1>.  Other non-surgical options might include hormone replacement therapy (HRT), which can alter secondary sex characteristics and potentially alleviate some <fact1>dysphoria</fact1> related to the <fact2>pelvic</fact2> region. However, for some individuals, <fact3>surgery</fact3> may be the most effective treatment to alleviate <fact1>dysphoria</fact1> and achieve bodily congruence.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning introduces hormone replacement therapy (HRT) as a potential non-surgical option, which is not mentioned in the reference explanation as a treatment for dysphoria specifically related to the pelvic region. The reference focuses on packers, tucking underwear, and comfort gaffs.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Other non-surgical options might include hormone replacement therapy (HRT), which can alter secondary sex characteristics and potentially alleviate some dysphoria related to the pelvic region.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation focuses on packers, tucking underwear, and comfort gaffs as non-surgical treatments for dysphoria around the pelvis. Hormone replacement therapy is not mentioned as a treatment for dysphoria specifically related to the pelvic region.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">hormone replacement therapy (HRT), which can alter secondary sex characteristics and potentially alleviate some dysphoria related to the pelvic region</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">packers can relieve symptoms. For people experiencing dysphoria about having a penis, there are tucking underwear and comfort gaffs available.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-152')">
            <div class="question-text">
                <div class="question-id">Question #152</div>
                Would members of Blue Lives Matter support every element of Grand Theft Auto III?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-152">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would members of Blue Lives Matter support every element of Grand Theft Auto III?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Blue Lives Matter is a countermovement in the United States that supports police officers and law enforcement personnel. Grand Theft Auto III allows for gratuitous violence against police officers in the game.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would members of <fact1>Blue Lives Matter</fact1> support every element of <fact2>Grand Theft Auto III</fact2>?
Answer: <fact1>Blue Lives Matter</fact1> is a pro-police movement.  <fact2>Grand Theft Auto III</fact2> is a video game where players can commit crimes, including violence against police officers.  It is highly unlikely members of <fact1>Blue Lives Matter</fact1>, a group supporting law enforcement, would endorse every element of a game like <fact2>Grand Theft Auto III</fact2> that allows players to engage in criminal activity, especially violence against police. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation and arrives at the correct conclusion without any hallucinations.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-153')">
            <div class="question-text">
                <div class="question-id">Question #153</div>
                Can the Dalai Lama fit in a car?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-153">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can the Dalai Lama fit in a car?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Dalai Lama is a person. Cars are designed for people to sit in them.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can the <fact1>Dalai Lama</fact1> fit in a <fact2>car</fact2>?
Answer:  The <fact1>Dalai Lama</fact1> is a human being.  Most <fact2>cars</fact2> are designed to fit human beings. Therefore, the <fact1>Dalai Lama</fact1> can likely fit in a <fact2>car</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, providing a logical and correct answer.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-154')">
            <div class="question-text">
                <div class="question-id">Question #154</div>
                Can actress Dafne Keen win the Eurovision Song Contest finals in 2020?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-154">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can actress Dafne Keen win the Eurovision Song Contest finals in 2020?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Contestants must be at least 16 years of age to compete in the finals of Eurovision Song Contest. Dafne Keen is 15 years old in 2020.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Could <fact1>Dafne Keen</fact1> win the <fact2>Eurovision Song Contest finals</fact2> in <fact3>2020</fact3>?
Answer: <fact2>The Eurovision Song Contest</fact2> did not take place in <fact3>2020</fact3> due to the COVID-19 pandemic.  Therefore, <fact1>Dafne Keen</fact1> could not have won. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain hallucinates that the Eurovision Song Contest did not take place in 2020 due to the COVID-19 pandemic. The reference explanation states that Dafne Keen was 15 years old in 2020 and contestants must be at least 16 years of age to compete in the finals of Eurovision Song Contest.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Eurovision Song Contest did not take place in 2020 due to the COVID-19 pandemic.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The Eurovision Song Contest did take place in 2020, although it was cancelled. The reference explanation states that Dafne Keen was 15 years old in 2020 and contestants must be at least 16 years of age to compete in the finals of Eurovision Song Contest.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Eurovision Song Contest did not take place in 2020 due to the COVID-19 pandemic.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Dafne Keen is 15 years old in 2020.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-155')">
            <div class="question-text">
                <div class="question-id">Question #155</div>
                Does United Airlines have a perfect operation record?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-155">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does United Airlines have a perfect operation record?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. An airline with a perfect operation record has no crashes or other damaging incidents. United Airlines has had over 30 crash incidents over several decades.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>United Airlines</fact1> have a <fact2>perfect operation record</fact2>?
Answer:  <fact1>United Airlines</fact1> has had several incidents and accidents throughout its operational history. A <fact2>perfect operation record</fact2> would imply no incidents or accidents. Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that United Airlines has had incidents and accidents, thus not having a perfect operation record.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-156')">
            <div class="question-text">
                <div class="question-id">Question #156</div>
                Can United States Secretary of State do crimes in U.K. without being arrested?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-156">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can United States Secretary of State do crimes in U.K. without being arrested?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Diplomatic Immunity allows for diplomats in other countries to not be tried for their transgressions. Countries that signed the Vienna Convention on Diplomatic Relations allow for Diplomatic Immunity. All UN member states besides Palau, The Solomon Islands, and South Sudan have signed the Vienna Convention on Diplomatic Relations treaty. The U.K. is one of the original UN member nations.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can <fact1>United States Secretary of State</fact1> do <fact2>crimes</fact2> in <fact3>U.K.</fact3> without being <fact4>arrested</fact4>?
Answer:  A <fact1>United States Secretary of State</fact1> is not above the law in the <fact3>U.K.</fact3>. If they commit <fact2>crimes</fact2> in the <fact3>U.K.</fact3> they can be <fact4>arrested</fact4> and prosecuted.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning directly contradicts the reference explanation by stating that a U.S. Secretary of State is not above the law in the U.K. and can be arrested, while the reference states that diplomatic immunity would prevent this.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">A United States Secretary of State is not above the law in the U.K.. If they commit crimes in the U.K. they can be arrested and prosecuted.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning contradicts the reference explanation, which states that diplomatic immunity would prevent the Secretary of State from being arrested and prosecuted.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">A United States Secretary of State is not above the law in the U.K.. If they commit crimes in the U.K. they can be arrested and prosecuted.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Diplomatic Immunity allows for diplomats in other countries to not be tried for their transgressions.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-157')">
            <div class="question-text">
                <div class="question-id">Question #157</div>
                Is myocardial infarction a brain problem?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-157">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is myocardial infarction a brain problem?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Myocardial infarction is a problem in the heart. The equivalent in the brain would be similar to a stroke.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>myocardial infarction</fact1> a <fact2>brain</fact2> problem?
Answer: <fact1>Myocardial infarction</fact1> is commonly known as a heart attack.  A heart attack occurs due to blockage of blood flow to the heart muscle. The <fact2>brain</fact2> is a separate organ from the heart. Therefore, <fact1>myocardial infarction</fact1> is not a <fact2>brain</fact2> problem. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why myocardial infarction is not a brain problem, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-158')">
            <div class="question-text">
                <div class="question-id">Question #158</div>
                Will Chick Fil A be open on Halloween 2021?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-158">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will Chick Fil A be open on Halloween 2021?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Chick Fil A restaurants close on Sundays. Halloween 2021 falls on a Sunday.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Will <fact1>Chick Fil A</fact1> be open on <fact2>Halloween 2021</fact2>?
Answer: <fact1>Chick Fil A</fact1> is generally open on most holidays, but it is closed on Sundays.  <fact2>Halloween 2021</fact2> fell on a Sunday. Therefore, <fact1>Chick Fil A</fact1> was closed on <fact2>Halloween 2021</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain contains a factual error about Chick Fil A's holiday hours, but correctly identifies that it is closed on Sundays and that Halloween 2021 was on a Sunday.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Chick Fil A is generally open on most holidays, but it is closed on Sundays.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">This statement contradicts the reference explanation. The reference explanation only states that Chick Fil A is closed on Sundays, and does not mention anything about holidays.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Chick Fil A is generally open on most holidays</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Chick Fil A restaurants close on Sundays.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-159')">
            <div class="question-text">
                <div class="question-id">Question #159</div>
                Was  Godfrey of Bouillon an Islamaphobe?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-159">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was  Godfrey of Bouillon an Islamaphobe?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes.  Godfrey of Bouillon lead troops during the Prince's Crusade. The Prince's Crusade was an attempt by Europeans to "take back" the city of Jerusalem from Islamic hands.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Godfrey of Bouillon</fact1> an <fact2>Islamaphobe</fact2>?
Answer: <fact1>Godfrey of Bouillon</fact1> was a leader of the First Crusade.  The First Crusade was a military expedition by European Christians to reclaim the Holy Land from Muslim control.  Historians generally agree that the Crusades were fueled, at least in part, by religious zeal and prejudice against Muslims. While the modern term "<fact2>Islamaphobe</fact2>" didn't exist then, <fact1>Godfrey of Bouillon's</fact1> actions and role in the Crusades strongly suggest hostility and intolerance towards Islam and Muslims, fitting the modern definition of the term. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, providing a clear and logical argument to support the conclusion. There are no contradictions, entity swaps, or logical errors.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-160')">
            <div class="question-text">
                <div class="question-id">Question #160</div>
                Is an espresso likely to assuage fear?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-160">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is an espresso likely to assuage fear?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Fear raises heart rate. Caffeine raises heart rate. Coffee may also increase symptoms such as jitteriness and nausea .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is an <fact1>espresso</fact1> likely to <fact2>assuage fear</fact2>?
Answer: An <fact1>espresso</fact1> contains caffeine. Caffeine is a stimulant. Stimulants can increase anxiety, which is the opposite of <fact2>assuaging fear</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that caffeine, a stimulant in espresso, can increase anxiety, which is the opposite of assuaging fear, aligning with the reference explanation that caffeine raises heart rate and may increase symptoms such as jitteriness.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-161')">
            <div class="question-text">
                <div class="question-id">Question #161</div>
                If you add water to rice pudding is it horchata?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-161">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">If you add water to rice pudding is it horchata?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Horchata is a drink made from soaking dry rice in water for hours, then pulverizing and straining the mixture and adding spices and sweetener. Rice pudding includes ingredients like eggs, and whole grains of cooked rice.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: If you add <fact1>water</fact1> to <fact2>rice pudding</fact2> is it <fact3>horchata</fact3>?
Answer: <fact2>Rice pudding</fact2> is a dish made from <fact1>water or milk</fact1>, rice, sugar, and sometimes spices. <fact3>Horchata</fact3> is a beverage made from soaked rice, nuts, seeds, or tigernuts blended with <fact1>water</fact1> with added sugar and spices. While both contain rice and <fact1>water</fact1>, <fact3>horchata</fact3> uses uncooked rice whereas <fact2>rice pudding</fact2> uses cooked rice. Simply adding <fact1>water</fact1> to <fact2>rice pudding</fact2> will not turn it into <fact3>horchata</fact3> due to this key difference in the preparation of the rice. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why adding water to rice pudding does not make it horchata, highlighting the key difference in the preparation of the rice (uncooked for horchata, cooked for rice pudding).</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-162')">
            <div class="question-text">
                <div class="question-id">Question #162</div>
                Did Bill Gates achieve Latin honors?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-162">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Bill Gates achieve Latin honors?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Bill Gates left Harvard after two years. Latin honors are Latin phrases used in some colleges and universities to indicate the level of distinction with which an academic degree has been earned. You cannot earn an academic degree if you drop out of the program.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Bill Gates</fact1> achieve <fact2>Latin honors</fact2>?
Answer: <fact1>Bill Gates</fact1> dropped out of Harvard University. <fact2>Latin honors</fact2> are awarded upon graduation. Since <fact1>Bill Gates</fact1> did not graduate, he did not achieve <fact2>Latin honors</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that Bill Gates dropped out of Harvard and therefore did not receive Latin honors, which are awarded upon graduation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-163')">
            <div class="question-text">
                <div class="question-id">Question #163</div>
                Was Superhero fiction invented in the digital format?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-163">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Superhero fiction invented in the digital format?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Golden Age of comics occurred between the 1930's and the 1950's. Shatter was the first digitally drawn, commercially published comic.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Superhero fiction</fact1> invented in the <fact2>digital format</fact2>?
Answer: <fact1>Superhero fiction</fact1> predates <fact2>digital formats</fact2>.  <fact1>Superhero comics</fact1>, a quintessential form of <fact1>superhero fiction</fact1>, originated in the 1930s, long before <fact2>digital technologies</fact2> existed.  Therefore, <fact1>superhero fiction</fact1> was not invented in the <fact2>digital format</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly deduces that superhero fiction was not invented in the digital format, accurately referencing the origin of superhero comics in the 1930s, which predates digital technologies. The reasoning aligns perfectly with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-164')">
            <div class="question-text">
                <div class="question-id">Question #164</div>
                Are any animals in Chinese calendar Chordata?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-164">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are any animals in Chinese calendar Chordata?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The chinese zodiac based on the Chinese calendar has a number of animals including dogs and pigs. Chordata is a scientific classification of an animals phylum. The phylum of pigs is Chordata.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are any animals in the <fact1>Chinese calendar</fact1> <fact2>Chordata</fact2>?
Answer: The animals in the <fact1>Chinese zodiac</fact1> are the Rat, Ox, Tiger, Rabbit, Dragon, Snake, Horse, Goat, Monkey, Rooster, Dog, and Pig.  All of these animals except for the mythical Dragon are <fact2>chordates</fact2> (vertebrates, to be more precise). So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning correctly identifies some animals in the Chinese zodiac as chordates but makes an unsupported claim about dragons not being chordates, which is a logical error.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">All of these animals except for the mythical Dragon are chordates (vertebrates, to be more precise).</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The statement implies that the mythical Dragon is not a chordate. However, the reference explanation only states that pigs are chordates, without making any claims about dragons or other animals in the Chinese zodiac. The generated reasoning makes an unsupported assumption about dragons not being chordates.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">All of these animals except for the mythical Dragon are chordates (vertebrates, to be more precise).</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The phylum of pigs is Chordata.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-165')">
            <div class="question-text">
                <div class="question-id">Question #165</div>
                Was Daniel thrown into the lion's den in the New Testament?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-165">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Daniel thrown into the lion's den in the New Testament?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Book of Daniel is a book in the Old Testament of the Bible. The Bible is divided into the Old Testament and the New Testament. The New Testament focuses on four Gospels regarding the life of Jesus.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Daniel</fact1> thrown into the <fact2>lion's den</fact2> in the <fact3>New Testament</fact3>?
Answer: The story of <fact1>Daniel</fact1> being thrown into the <fact2>lion's den</fact2> is found in the Book of Daniel, which is part of the Old Testament, not the <fact3>New Testament</fact3>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that the story of Daniel and the lion's den is in the Old Testament, not the New Testament, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-166')">
            <div class="question-text">
                <div class="question-id">Question #166</div>
                Will 2020 elephant pregnancy last past next year with 4 solar eclipses?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-166">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Will 2020 elephant pregnancy last past next year with 4 solar eclipses?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The gestation period of elephants are around 95 weeks. The year 2029 is the next year with 4 solar eclipses.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Will a <fact1>2020 elephant pregnancy</fact1> last past <fact2>next year</fact2> with <fact3>4 solar eclipses</fact3>?
Answer: Elephant pregnancies last around 22 months. A <fact1>pregnancy beginning in 2020</fact1> would likely end in late 2021 or early 2022. <fact2>Next year</fact2>, in reference to 2020, is 2021. The number of <fact3>solar eclipses</fact3> has no bearing on the length of an elephant pregnancy. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning is mostly correct, but the slight inaccuracy in the gestation period of elephants is a minor hallucination.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Elephant pregnancies last around 22 months.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that elephant pregnancies last around 95 weeks, which is approximately 21.8 months. While close, 22 months is not precise and could lead to incorrect calculations. It is close enough to be considered a low severity error.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Elephant pregnancies last around 22 months</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The gestation period of elephants are around 95 weeks</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-167')">
            <div class="question-text">
                <div class="question-id">Question #167</div>
                Does the word swastika have meaning in sanskrit?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-167">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does the word swastika have meaning in sanskrit?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. In Sanskrit, the word swastika is a combination of ‚Äòsu‚Äô (meaning ‚Äògood‚Äô) and ‚Äòasti‚Äô (meaning ‚Äòto exist‚Äô). This meaning of swastika  from Sanskrit this gets translated as ‚Äòall is well.‚Äô .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does the word <fact1>swastika</fact1> have meaning in <fact2>Sanskrit</fact2>?
Answer: The word <fact1>swastika</fact1> is derived from the <fact2>Sanskrit</fact2> word svastika, meaning "well-being." So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that the word swastika is derived from Sanskrit and means "well-being" or "all is well."</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-168')">
            <div class="question-text">
                <div class="question-id">Question #168</div>
                Did Sony definitively win the video game war against Sega?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-168">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Sony definitively win the video game war against Sega?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Sony is the maker of the Playstation which has sold over 108 million PS4 units by March 2020. Sega's last console, the Sega Dreamcast, was discontinued in 2001. Sony Playstation competed with Sega's Dreamcast and Saturn systems in the 1990s. Sega now makes games for its former competitor, Sony, including Team Sonic Racing in 2019. At the height of the console wars, Sega Saturn sold 9.5 million units while Sony Playstation sold 102 million units.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Sony</fact1> definitively win the <fact2>video game war</fact2> against <fact3>Sega</fact3>?
Answer: While <fact1>Sony</fact1>'s PlayStation significantly outsold <fact3>Sega</fact3>'s Saturn and Dreamcast, leading to <fact3>Sega</fact3> exiting the console hardware market,  "definitively win" is subjective. <fact3>Sega</fact3> remains a successful software publisher and maintains a dedicated fanbase. Therefore, while <fact1>Sony</fact1> dominated the <fact2>console market share</fact2> of that era, whether they *definitively* won the overall <fact2>video game war</fact2> is debatable.  The answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly acknowledges Sony's dominance in the console market while also pointing out that Sega still exists as a software publisher, making the idea of a 'definitive win' debatable. No hallucinations were detected.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-169')">
            <div class="question-text">
                <div class="question-id">Question #169</div>
                Would an ethics professor teach a class on Cezanne?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-169">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would an ethics professor teach a class on Cezanne?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Cezanne was an Impressionist painter. Aesthetics is the branch of philosophy that deals with the arts.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would an <fact1>ethics professor</fact1> teach a class on <fact2>Cezanne</fact2>?
Answer: <fact2>Cezanne</fact2> was a French artist.  <fact1>Ethics professors</fact1> teach about moral principles and conduct.  It is unlikely an <fact1>ethics professor</fact1> would teach about <fact2>Cezanne</fact2> unless there was a specific ethical dimension to his work or life being explored, such as art forgery or the ethics of art ownership. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a logical error by suggesting that an ethics professor might teach about Cezanne if there were ethical dimensions to his work, which is not supported by the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">It is unlikely an ethics professor would teach about Cezanne unless there was a specific ethical dimension to his work or life being explored, such as art forgery or the ethics of art ownership.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation states that Cezanne was an Impressionist painter and that aesthetics is the branch of philosophy that deals with the arts. It does not mention any ethical dimensions of Cezanne's work or life, so this is a misinterpretation of the reference facts.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">It is unlikely an ethics professor would teach about Cezanne unless there was a specific ethical dimension to his work or life being explored, such as art forgery or the ethics of art ownership.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Cezanne was an Impressionist painter. Aesthetics is the branch of philosophy that deals with the arts.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-170')">
            <div class="question-text">
                <div class="question-id">Question #170</div>
                Can a dolphin keep a diary?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-170">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a dolphin keep a diary?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. A diary is a written record. Dolphins cannot write.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can a <fact1>dolphin</fact1> keep a <fact2>diary</fact2>?
Answer: A <fact2>diary</fact2> requires the ability to write and record personal experiences.  <fact1>Dolphins</fact1> lack the physical dexterity to write and do not possess the cognitive capacity for the complex, reflective thought required for diary keeping. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a logical error by adding information not present in the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Dolphins lack the physical dexterity to write and do not possess the cognitive capacity for the complex, reflective thought required for diary keeping.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation only states that dolphins cannot write. The generated reasoning adds that dolphins do not possess the cognitive capacity for complex thought, which is not mentioned in the reference explanation.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Dolphins lack the physical dexterity to write and do not possess the cognitive capacity for the complex, reflective thought required for diary keeping.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Dolphins cannot write.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-171')">
            <div class="question-text">
                <div class="question-id">Question #171</div>
                Would Columbus have discovered Durian trees during his 1492 expedition?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-171">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Columbus have discovered Durian trees during his 1492 expedition?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Columbus ended up in the Americas. Durian only exists in Southeast Asia.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>Columbus</fact1> have discovered <fact2>Durian trees</fact2> during his <fact3>1492 expedition</fact3>?
Answer: <fact1>Columbus</fact1> sailed to the Americas in <fact3>1492</fact3>. <fact2>Durian trees</fact2> are native to Southeast Asia. Therefore, <fact1>Columbus</fact1> would not have encountered <fact2>Durian trees</fact2> in the Americas during his <fact3>1492 expedition</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that Columbus sailed to the Americas and Durian trees are native to Southeast Asia, thus he would not have encountered them during his expedition.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-172')">
            <div class="question-text">
                <div class="question-id">Question #172</div>
                Can you carry a Chrysler in a laptop bag?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-172">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can you carry a Chrysler in a laptop bag?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Chrysler manufactures automobiles, which weigh several thousand pounds. Laptop bags are designed to hold laptop computers, which typically weigh under ten pounds.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can you carry a <fact1>Chrysler</fact1> in a <fact2>laptop bag</fact2>?
Answer: A <fact1>Chrysler</fact1> is a car, which is a large and heavy object. A <fact2>laptop bag</fact2> is designed to carry a laptop, which is a relatively small and lightweight electronic device.  A <fact1>Chrysler</fact1> would not fit in a <fact2>laptop bag</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that a Chrysler is a car, which is large and heavy, while a laptop bag is designed for small, lightweight laptops. Therefore, a Chrysler would not fit in a laptop bag.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="logical_error">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-173')">
            <div class="question-text">
                <div class="question-id">Question #173</div>
                Has every astronaut survived their space journey?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-173">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Has every astronaut survived their space journey?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. In 1986, the space shuttle Challenger exploded during launch, killing all astronauts aboard. In 2003, the space shuttle Columbia also exploded, again killing its entire crew. Various other space flights have resulted in fatal disasters.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Has <fact1>every astronaut</fact1> <fact2>survived</fact2> their <fact3>space journey</fact3>?
Answer: Sadly, <fact1>not every astronaut</fact1> has <fact2>survived</fact2> their <fact3>space journey</fact3>.  There have been several fatal accidents in the history of space exploration, including the Apollo 1 fire, the Challenger explosion, and the Columbia disaster, where astronauts lost their lives.  Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain correctly identifies that not all astronauts have survived their space journeys but includes an event (Apollo 1 fire) that, while tragic, did not occur during a space journey, which is a misinterpretation of the prompt.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #3498db">logical_error</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">including the Apollo 1 fire, the Challenger explosion, and the Columbia disaster, where astronauts lost their lives.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation only mentions the Challenger and Columbia disasters. While the Apollo 1 fire was a tragedy, it did not occur during a space journey.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">including the Apollo 1 fire</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">In 1986, the space shuttle Challenger exploded during launch, killing all astronauts aboard. In 2003, the space shuttle Columbia also exploded, again killing its entire crew.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-174')">
            <div class="question-text">
                <div class="question-id">Question #174</div>
                Do members of the Supreme Court of the United States have longer terms than most senators?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-174">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do members of the Supreme Court of the United States have longer terms than most senators?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Senators, on average, serve for 10 years. Supreme Court Justices serve for their entire life. The average term for a Supreme court justice is 16 years.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do members of the <fact1>Supreme Court of the United States</fact1> have longer terms than <fact2>most senators</fact2>?
Answer: Members of the <fact1>Supreme Court</fact1> are appointed for life. <fact2>Senators</fact2> serve 6-year terms.  Therefore, members of the <fact1>Supreme Court</fact1> serve longer terms than <fact2>senators</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The reasoning chain contains a factual error about the average length of a senator's term.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Senators serve 6-year terms.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">Senators serve 6-year terms, but on average serve for 10 years due to re-election.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Senators serve 6-year terms.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Senators, on average, serve for 10 years.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-175')">
            <div class="question-text">
                <div class="question-id">Question #175</div>
                Would Dante have hypothetically placed Nostradamus in 3rd Circle of Hell?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-175">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would Dante have hypothetically placed Nostradamus in 3rd Circle of Hell?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Nostradamus was a famous seer and court astrologer. Dante's 3rd Circle of Hell is reserved for gluttons. The 8th Circle of Hell is reserved for frauds. Astrology was seen as a valuable skill during Dante's lifetime. Dante places the mystic and prophet Joachim of Flora in the heaven of the sun.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would <fact1>Dante</fact1> have hypothetically placed <fact2>Nostradamus</fact2> in the <fact3>3rd Circle of Hell</fact3>?
Answer: <fact1>Dante's</fact1> *Inferno* places the gluttonous in the <fact3>Third Circle of Hell</fact3>. <fact2>Nostradamus</fact2> was a physician and astrologer, not known for gluttony. Therefore, it's unlikely <fact1>Dante</fact1> would have placed <fact2>him</fact2> there. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Nostradamus was not known for gluttony and therefore would not be placed in the Third Circle of Hell, which is reserved for the gluttonous, according to Dante's *Inferno*.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-176')">
            <div class="question-text">
                <div class="question-id">Question #176</div>
                Was Mercedes-Benz associated with the Nazis?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-176">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Mercedes-Benz associated with the Nazis?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. During the 1930s, Mercedes-Benz produced the 770 model. The 770 was popular with Nazis, and Adolf Hitler used them as his personal vehicle.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Mercedes-Benz</fact1> associated with the <fact2>Nazis</fact2>?
Answer: <fact1>Mercedes-Benz</fact1>, then known as Daimler-Benz, used forced labor during World War II under the <fact2>Nazi regime</fact2>.  Therefore, the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly identifies Mercedes-Benz's association with the Nazi regime, although it focuses on forced labor during World War II, which is a valid but different aspect than the reference explanation's focus on the 770 model and Hitler's personal use.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-177')">
            <div class="question-text">
                <div class="question-id">Question #177</div>
                Is Disneyland Paris the largest Disney resort?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-177">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Disneyland Paris the largest Disney resort?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Disneyland Paris contains two parks, several hotels, and a shopping district. By comparison, Walt Disney World in Florida contains four parks, two waterparks, a shopping district, and many hotels. Disney World is bigger than Disneyland Paris Resort and Disneyland California Resort combined.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>Disneyland Paris</fact1> the <fact2>largest Disney resort</fact2>?
Answer: <fact2>Walt Disney World Resort</fact2> in Florida is the <fact2>largest Disney resort</fact2>.  Therefore, <fact1>Disneyland Paris</fact1> is not the <fact2>largest Disney resort</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies that Walt Disney World Resort in Florida is the largest Disney resort, and therefore Disneyland Paris is not the largest.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-178')">
            <div class="question-text">
                <div class="question-id">Question #178</div>
                Would a Rockette look odd with a moustache?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-178">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would a Rockette look odd with a moustache?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Rockettes are an American dance group made up of all women. In America, it is uncommon to see a woman with a moustache.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would a <fact1>Rockette</fact1> look odd with a <fact2>moustache</fact2>?
Answer: <fact1>Rockettes</fact1> are known for their glamorous and traditionally feminine appearance.  A <fact2>moustache</fact2> is generally considered a masculine facial feature. Therefore, a <fact2>moustache</fact2> would clash with the typical <fact1>Rockette</fact1> image, making it look odd. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning correctly explains why a Rockette would look odd with a moustache, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-179')">
            <div class="question-text">
                <div class="question-id">Question #179</div>
                Can a sea turtle play tennis using a tennis racket?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-179">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Can a sea turtle play tennis using a tennis racket?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. to play tennis, a human-like hand is needed to properly hold the tennis racket. sea turtles have flippers and not human-like hands.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Can a <fact1>sea turtle</fact1> play <fact2>tennis</fact2> using a <fact3>tennis racket</fact3>?
Answer: <fact2>Tennis</fact2> requires the player to hold a <fact3>tennis racket</fact3> and hit a ball over a net. <fact1>Sea turtles</fact1> have flippers, not hands, so they cannot grip a <fact3>tennis racket</fact3>. Therefore, a <fact1>sea turtle</fact1> cannot play <fact2>tennis</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the reference explanation, stating that sea turtles cannot play tennis because they have flippers instead of hands, which are needed to grip a tennis racket.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-180')">
            <div class="question-text">
                <div class="question-id">Question #180</div>
                Did Donald Trump come up with the idea for the New York Harbor?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-180">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did Donald Trump come up with the idea for the New York Harbor?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The New York Harbor is at the mouth of the Hudson River. A harbor is a sheltered body of water where boats and ships can be docked. The New York Harbor has been used since colonial era of the 1500s. Donald Trump is a failed business man and 2016 president elect. Donald Trump makes outrageous deceitful claims .</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>Donald Trump</fact1> come up with the idea for the <fact2>New York Harbor</fact2>?
Answer: <fact2>New York Harbor</fact2> has existed for centuries, long before <fact1>Donald Trump</fact1> was born. Therefore, <fact1>he</fact1> could not have conceived of the idea for the <fact2>New York Harbor</fact2>.  So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly deduces that Donald Trump could not have come up with the idea for the New York Harbor, as it existed long before he was born. The reasoning aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-181')">
            <div class="question-text">
                <div class="question-id">Question #181</div>
                Would it be unusual to use paypal for drug deals?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-181">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Would it be unusual to use paypal for drug deals?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Paypal prohibits the use of their platform for drugs or drug paraphernalia.  Using paypal leaves a digital footprint of any drug purchase.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Would it be unusual to use <fact1>paypal</fact1> for <fact2>drug deals</fact2>?
Answer: <fact1>Paypal</fact1> keeps records of transactions and user information.  Because <fact2>drug deals</fact2> are illegal, using a service like <fact1>Paypal</fact1> that creates a clear record of the transaction would be risky and unusual. Therefore, the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that using PayPal for drug deals would be risky and unusual due to the platform's record-keeping practices and the illegal nature of drug transactions.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-182')">
            <div class="question-text">
                <div class="question-id">Question #182</div>
                Is it safe to eat kidney?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-182">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is it safe to eat kidney?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Traditional British cuisine includes "Kidney Pie", or "Steak and Kidney Pie". Kidney Pie contains kidney.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is it safe to eat <fact1>kidney</fact1>?
Answer: <fact1>Kidney</fact1> is a nutrient-rich organ meat that is safe to eat when properly prepared.  It's important to source <fact1>kidneys</fact1> from healthy animals and to cook them thoroughly to eliminate any potential health risks.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning provides a reasonable explanation that kidney is safe to eat when properly prepared. It does not contradict the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-183')">
            <div class="question-text">
                <div class="question-id">Question #183</div>
                Do shrimp taste best when cooked for a long time?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-183">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Do shrimp taste best when cooked for a long time?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Shrimp becomes tough and rubbery if cooked for a long time. The ideal texture for shrimp is soft and easily chewed.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Do <fact1>shrimp</fact1> taste best when cooked for a <fact2>long time</fact2>?
Answer: <fact1>Shrimp</fact1> cook quickly.  If <fact1>shrimp</fact1> are cooked for a <fact2>long time</fact2>, they become tough and rubbery. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that shrimp becomes tough and rubbery if cooked for a long time.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-184')">
            <div class="question-text">
                <div class="question-id">Question #184</div>
                Hypothetically, will an African elephant be crushed by Hulk on its back?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-184">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Hypothetically, will an African elephant be crushed by Hulk on its back?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The Hulk is a Marvel comics character. The Hulk is said to be around 8 feet tall and weigh around 1400 pounds. An African elephant can carry up to 9,000 kg, or 19,841 pounds.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Hypothetically, will an <fact1>African elephant</fact1> be crushed by <fact2>Hulk</fact2> on its back?
Answer: An <fact1>African elephant</fact1> can weigh up to 13,000 pounds. The <fact2>Hulk</fact2> is immensely strong and can lift far more than 13,000 pounds. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error about the weight an African elephant can carry, which leads to a flawed comparison with the Hulk's lifting capacity.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">An African elephant can weigh up to 13,000 pounds.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that an African elephant can weigh up to 13,000 pounds, which contradicts the reference explanation that states that an African elephant can carry up to 19,841 pounds.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">An African elephant can weigh up to 13,000 pounds.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">An African elephant can carry up to 9,000 kg, or 19,841 pounds.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-185')">
            <div class="question-text">
                <div class="question-id">Question #185</div>
                Does Rupert Murdoch's alma mater have more history than the USA?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-185">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Rupert Murdoch's alma mater have more history than the USA?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Rupert Murdoch's alma mater is Worcester College. Worcester College was founded in 1714. The first documented use of the term the United States of America was in a January 2, 1776 letter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Rupert Murdoch's alma mater</fact1> have more history than the <fact2>USA</fact2>?
Answer: <fact1>Rupert Murdoch's alma mater</fact1> is Worcester College, Oxford.  Worcester College, Oxford was founded in 1714. The <fact2>USA</fact2> declared its independence in 1776.  Since 1714 is earlier than 1776, Worcester College has more history than the <fact2>USA</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately reflects the information provided in the reference explanation and arrives at the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-186')">
            <div class="question-text">
                <div class="question-id">Question #186</div>
                Is Saturn named after king of gods in Greek mythology?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-186">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Saturn named after king of gods in Greek mythology?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Saturn, the sixth planet from the sun is named after the Roman god Saturn. The Roman god Saturn is derived from its Greek equivalent, Kronos. The king of the gods in Greek mythology was Zeus. Kronos was Zeus's father, and was the leader of the Titans.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>Saturn</fact1> named after <fact2>king of gods</fact2> in <fact3>Greek mythology</fact3>?
Answer: In <fact3>Greek mythology</fact3>, the <fact2>king of the gods</fact2> is Zeus. <fact1>Saturn</fact1> is the Roman equivalent of the Greek god Cronus, who is Zeus's father and the former king of the Titans. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Saturn is not named after the king of the gods in Greek mythology, and accurately explains the relationship between Saturn, Cronus, and Zeus.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-187')">
            <div class="question-text">
                <div class="question-id">Question #187</div>
                Does American Independence Day occur during autumn?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-187">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does American Independence Day occur during autumn?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Autumn runs from about September 20 to about December 20. American Independence Day is July 4, over two months before autumn begins.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>American Independence Day</fact1> occur during <fact2>autumn</fact2>?
Answer: <fact1>American Independence Day</fact1> is celebrated on July 4th.  <fact2>Autumn</fact2> is typically considered to be the months of September, October, and November in the Northern Hemisphere. Since July is not in <fact2>autumn</fact2>, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately explains why American Independence Day does not occur during autumn, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-188')">
            <div class="question-text">
                <div class="question-id">Question #188</div>
                Is Albany, Georgia the most populous US Albany?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-188">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Albany, Georgia the most populous US Albany?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Albany, Georgia had a population of 75,249 in 2018. Albany, New York had a population of 97,279 in 2018.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>Albany, Georgia</fact1> the most populous US <fact2>Albany</fact2>?
Answer: <fact1>Albany, New York</fact1> has a population of about 99,000, whereas <fact1>Albany, Georgia</fact1> has about 70,000.  Since 99,000 is greater than 70,000, <fact1>Albany, Georgia</fact1> is not the most populous <fact2>Albany</fact2> in the US. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain contains a factual error regarding the population of Albany, New York and Albany, Georgia.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #f39c12">medium</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Albany, New York has a population of about 99,000, whereas Albany, Georgia has about 70,000.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning states that Albany, New York has a population of about 99,000 and Albany, Georgia has about 70,000. However, the reference explanation states that Albany, New York has a population of 97,279 and Albany, Georgia has a population of 75,249.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Albany, New York has a population of about 99,000, whereas Albany, Georgia has about 70,000</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Albany, New York had a population of 97,279 in 2018. Albany, Georgia had a population of 75,249 in 2018.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-189')">
            <div class="question-text">
                <div class="question-id">Question #189</div>
                Are the founders of Skype from Asia?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-189">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are the founders of Skype from Asia?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Skype was created by the Niklas Zennstr√∂m and the Dane Janus Friis. Niklas Zennstr√∂m and Dane Janus Friis are from Sweden. Sweden is located in Europe, not Asia.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are the <fact1>founders of Skype</fact1> from <fact2>Asia</fact2>?
Answer: The <fact1>founders of Skype</fact1> are Janus Friis and Niklas Zennstr√∂m, both from Europe.  <fact1>Friis</fact1> is from Denmark and <fact1>Zennstr√∂m</fact1> is from Sweden.  Since neither Denmark nor Sweden are in <fact2>Asia</fact2>, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the reference explanation, stating that the founders of Skype are from Europe (Denmark and Sweden), not Asia.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-190')">
            <div class="question-text">
                <div class="question-id">Question #190</div>
                Are all Wednesdays in a year enough to read Bible 15 times?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-190">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are all Wednesdays in a year enough to read Bible 15 times?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. There are 52 Wednesdays in a year. There are 1,248 hours over all the Wednesdays in a year. The Old Testament of the Bible takes an average of 52 hours to read. The New Testament of the Bible takes an average of 18 hours to read.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are all <fact1>Wednesdays</fact1> in a year enough to read the <fact2>Bible</fact2> <fact3>15 times</fact3>?
Answer: There are 52 or 53 <fact1>Wednesdays</fact1> in a year.  The <fact2>Bible</fact2> has approximately 783,137 words.  A fast reader can read about 300 words per minute. This means it would take about 2610 minutes or 43.5 hours to read the <fact2>Bible</fact2> once. To read it <fact3>15 times</fact3>, it would take 652.5 hours.  Even if there were 53 <fact1>Wednesdays</fact1>, that would only provide 1274 hours if someone spent all 24 hours of each Wednesday reading.  Since it only takes 652.5 hours to read the <fact2>Bible</fact2> <fact3>15 times</fact3>, all the <fact1>Wednesdays</fact1> in a year would be enough. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">fair</span></div>
                <div class="detail-content">The generated reasoning chain introduces an irrelevant and incorrect fact about the number of words in the Bible, which is not mentioned in the reference explanation. The rest of the reasoning is based on this hallucinated fact, but the final conclusion is still correct.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Bible has approximately 783,137 words.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference explanation does not mention the number of words in the Bible. Instead, it provides the average time it takes to read the Old and New Testaments.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Bible has approximately 783,137 words.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Old Testament of the Bible takes an average of 52 hours to read. The New Testament of the Bible takes an average of 18 hours to read.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-191')">
            <div class="question-text">
                <div class="question-id">Question #191</div>
                Did the butler Eugene Allen retire the same year a centuries-old war ended?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-191">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the butler Eugene Allen retire the same year a centuries-old war ended?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Eugene Allen was a butler at the White House for 34 years until 1986. The United Kingdom and the Kingdom of the Netherlands ended the Three Hundred and Thirty Five Years' Warnin 1986.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did <fact1>the butler Eugene Allen</fact1> retire the same year <fact2>a centuries-old war</fact2> ended?
Answer: <fact1>Eugene Allen</fact1> retired in 1986. The <fact2>Cold War</fact2>, which some historians date back to 1917, ended in 1991.  Since 1986 is not the same as 1991, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces an irrelevant entity (Cold War) and uses it to incorrectly answer the question.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Cold War, which some historians date back to 1917, ended in 1991.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The generated reasoning introduces the Cold War, which is not mentioned in the reference explanation. The reference mentions the Three Hundred and Thirty Five Years' War.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Cold War</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Three Hundred and Thirty Five Years' War</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-192')">
            <div class="question-text">
                <div class="question-id">Question #192</div>
                Did the writer of Christmas carol fast during Ramadan?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-192">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Did the writer of Christmas carol fast during Ramadan?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. The writer of Christmas carol is Charles Dickens, who is a Christian.  Christians do not fast during Ramadan.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Did the <fact1>writer of Christmas carol</fact1> fast during <fact2>Ramadan</fact2>?
Answer: The <fact1>writer of A Christmas Carol</fact1> was Charles Dickens. <fact2>Ramadan</fact2> is a Muslim holiday. Charles Dickens was Christian. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning correctly identifies Charles Dickens as the writer of A Christmas Carol, notes that Ramadan is a Muslim holiday, and states that Charles Dickens was Christian. This aligns with the reference explanation and leads to the correct conclusion.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="contradiction">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-193')">
            <div class="question-text">
                <div class="question-id">Question #193</div>
                Is entire Common Era minuscule to lifespan of some trees?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-193">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is entire Common Era minuscule to lifespan of some trees?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. The Common Era has lasted for over 2,000 years as of 2020. A tree named Methuselah, from California's White Mountains, is almost 5,000 years old.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is the entire <fact1>Common Era</fact1> minuscule to the lifespan of some <fact2>trees</fact2>?
Answer: The <fact1>Common Era</fact1> spans approximately 2023 years. Some <fact2>tree</fact2> species, such as the Great Basin Bristlecone Pine, can live for thousands of years, exceeding the length of the <fact1>Common Era</fact1>. Therefore, the <fact1>Common Era</fact1> could be considered minuscule compared to the lifespan of some <fact2>trees</fact2>. So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning is mostly correct and aligns with the reference explanation. However, it includes a slightly different number for the length of the Common Era, which is not directly from the reference.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #e74c3c">contradiction</span>
                <span class="severity-badge" style="background: #27ae60">low</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">The Common Era spans approximately 2023 years.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference states that the Common Era has lasted for over 2,000 years as of 2020. The generated reasoning states that the Common Era spans approximately 2023 years. While technically not incorrect, it is not the information provided in the reference explanation.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">The Common Era spans approximately 2023 years.</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">The Common Era has lasted for over 2,000 years as of 2020.</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-194')">
            <div class="question-text">
                <div class="question-id">Question #194</div>
                Is Tange Sazen hypothetically an ideal choice for a secretary job?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-194">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Tange Sazen hypothetically an ideal choice for a secretary job?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. Secretaries are required to type and also read copious amounts of notes. Tange Sazen is a one-eyed, one-armed swordsman in Japanese literature.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>Tange Sazen</fact1> hypothetically an ideal choice for a <fact2>secretary job</fact2>?
Answer: <fact1>Tange Sazen</fact1> is a fictional one-armed swordsman. A <fact2>secretary</fact2> performs administrative tasks, often involving typing and writing.  Since <fact1>Sazen</fact1> only has one arm, he would likely have difficulty performing these tasks. Therefore, <fact1>he</fact1> is not an ideal choice for a <fact2>secretary job</fact2>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Tange Sazen would not be a good secretary due to his physical limitations, which aligns with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-195')">
            <div class="question-text">
                <div class="question-id">Question #195</div>
                Are Brussels sprout particularly good for adrenal fatigue?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-195">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Are Brussels sprout particularly good for adrenal fatigue?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Adenal fatigue is a disorder in which the body does not produce enough hormones and people get tired. Brussels sprout are foods rich in vitamin C. When stress levels rise, the adrenal glands require more Vitamin C and it is used very quickly.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Are <fact1>Brussels sprouts</fact1> particularly good for <fact2>adrenal fatigue</fact2>?
Answer: <fact2>Adrenal fatigue</fact2> is a term applied to a collection of symptoms such as body aches, fatigue, nervousness, sleep disturbances and digestive problems.  <fact1>Brussels sprouts</fact1> are a good source of vitamin C, and some proponents of the idea of <fact2>adrenal fatigue</fact2> believe vitamin C can be helpful for this condition.  However, <fact2>adrenal fatigue</fact2> is not a medically recognized condition.  Mainstream medicine recognizes adrenal insufficiency, which has different causes and treatments. While there is limited scientific evidence to support the claim that <fact1>Brussels sprouts</fact1> are particularly good for <fact2>adrenal fatigue</fact2>, they are a nutritious vegetable that can contribute to overall health. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #f39c12">good</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Brussels sprouts are a good source of vitamin C and that vitamin C can be helpful for adrenal fatigue. It also correctly states that adrenal fatigue is not a medically recognized condition, but that Brussels sprouts are a nutritious vegetable that can contribute to overall health.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-196')">
            <div class="question-text">
                <div class="question-id">Question #196</div>
                Does Adam Sandler skip celebrating Easter?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-196">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does Adam Sandler skip celebrating Easter?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Adam Sandler is Jewish. Jewish religious people do not celebrate Easter.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>Adam Sandler</fact1> skip celebrating <fact2>Easter</fact2>?
Answer: <fact1>Adam Sandler</fact1> is Jewish.  <fact2>Easter</fact2> is a Christian holiday.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain correctly identifies that Adam Sandler is Jewish and Easter is a Christian holiday, which leads to the correct conclusion that he does not celebrate Easter.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-197')">
            <div class="question-text">
                <div class="question-id">Question #197</div>
                Does March begin on the same day of the week as February during leap years?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-197">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Does March begin on the same day of the week as February during leap years?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. During normal years, February has exactly 28 days, so March begins on the same day of the week as February. However, on leap years, February has an extra day, so March begins the next day of the week from whichever day started February.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Does <fact1>March</fact1> begin on the same day of the week as <fact2>February</fact2> during <fact3>leap years</fact3>?
Answer: <fact2>February</fact2> has 29 days during <fact3>leap years</fact3>.  Since there are 7 days in a week, adding 29 days shifts the day of the week by one (29 mod 7 = 1). Therefore, <fact1>March</fact1> will begin one day later in the week than <fact2>February</fact2> during <fact3>leap years</fact3>. So the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning chain accurately explains why March does not begin on the same day of the week as February during leap years, aligning with the reference explanation.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
    <div class="question-item" data-types="entity_swap">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-198')">
            <div class="question-text">
                <div class="question-id">Question #198</div>
                Is Shiva's divine dance an ancient physical fitness pose?
            </div>
            <span class="hallucination-count ">1 issue</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-198">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Is Shiva's divine dance an ancient physical fitness pose?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">No. In yoga as exercise, the pose called Natarajasara represents Shiva's divine dance. This pose is new, originating in the early 20th century. Exercise is an activity that maintains physical fitness.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Is <fact1>Shiva's divine dance</fact1> an <fact2>ancient physical fitness pose</fact2>?
Answer: <fact1>Shiva's divine dance</fact1>, Tandava, is an ancient Hindu tradition.  While some modern interpretations may incorporate elements of it into <fact2>physical fitness poses</fact2>, its primary purpose historically wasn't fitness. It represents cosmic cycles of creation and destruction, not a workout.  Therefore, the answer is {false}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #e74c3c">poor</span></div>
                <div class="detail-content">The generated reasoning introduces an entity swap by mentioning 'Tandava' instead of 'Natarajasara' as the pose representing Shiva's divine dance, which is a significant deviation from the reference explanation.</div>
            </div>
            <h3>Detected Issues (1)</h3>
        <div class="hallucination-item">
            <div class="hallucination-header">
                <span class="hallucination-type" style="background: #9b59b6">entity_swap</span>
                <span class="severity-badge" style="background: #e74c3c">high</span>
            </div>
            <div class="detail-section">
                <div class="detail-label">Statement</div>
                <div class="detail-content">Shiva's divine dance, Tandava, is an ancient Hindu tradition.</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Explanation</div>
                <div class="detail-content">The reference mentions Natarajasara as the pose representing Shiva's divine dance, not Tandava.</div>
            </div>
            <div class="span-label">Answer Span:</div><div class="span-highlight">Tandava</div>
            <div class="span-label">Reference/Question Span:</div><div class="span-highlight">Natarajasara</div>
        </div>
        
        </div>
    </div>
    
    <div class="question-item" data-types="">
        <div class="question-header" onclick="toggleQuestion('dataset-0-hot-199')">
            <div class="question-text">
                <div class="question-id">Question #199</div>
                Was Land of Israel in possession of an Islamic empire in 16th century?
            </div>
            <span class="hallucination-count none">Clean</span>
        </div>
        <div class="question-details" id="details-dataset-0-hot-199">
            <div class="detail-section">
                <div class="detail-label">Full Question</div>
                <div class="detail-content">Was Land of Israel in possession of an Islamic empire in 16th century?</div>
            </div>
            
        <div class="detail-section">
            <div class="detail-label">Ground Truth Explanation</div>
            <div class="detail-content">Yes. Land of Israel was controlled by the Ottoman Empire in 16th century.  The religion of Ottoman Empire was Sunni Islam.</div>
        </div>
        
            <div class="detail-section">
                <div class="detail-label">Generated Answer</div>
                <div class="detail-content">Reformatted Question: Was <fact1>Land of Israel</fact1> in possession of an <fact2>Islamic empire</fact2> in the <fact3>16th century</fact3>?
Answer: The <fact2>Ottoman Empire</fact2>, an <fact2>Islamic empire</fact2>, controlled <fact1>the Land of Israel</fact1> starting in 1517. The <fact3>16th century</fact3> covers the years 1501-1600.  So the answer is {true}.
</div>
            </div>
            <div class="detail-section">
                <div class="detail-label">Overall Quality: <span style="color: #27ae60">excellent</span></div>
                <div class="detail-content">The generated reasoning accurately reflects the information provided in the reference explanation. It correctly identifies the Ottoman Empire as an Islamic empire that controlled the Land of Israel in the 16th century.</div>
            </div>
            <p style="color: var(--accent-green)">‚úì No hallucinations detected</p>
        </div>
    </div>
    
        </div>
    </div>
    
        </div>
    </div>
    
        </div>
        
        
    <script>
        function toggleDataset(datasetId) {
            const content = document.getElementById('content-' + datasetId);
            const icon = document.getElementById('icon-' + datasetId);
            content.classList.toggle('active');
            icon.classList.toggle('rotated');
        }
        
        function toggleQuestion(questionId) {
            const details = document.getElementById('details-' + questionId);
            details.classList.toggle('active');
        }
        
        function switchMode(datasetId, mode) {
            // Update tab styles
            document.querySelectorAll(`#tabs-${datasetId} .mode-tab`).forEach(tab => {
                tab.classList.remove('active');
            });
            document.querySelector(`#tabs-${datasetId} .mode-tab[data-mode="${mode}"]`).classList.add('active');
            
            // Show/hide content
            document.querySelectorAll(`#content-${datasetId} .mode-content`).forEach(content => {
                content.style.display = 'none';
            });
            document.getElementById(`mode-${datasetId}-${mode}`).style.display = 'block';
        }
        
        function filterQuestions(datasetId, mode) {
            const searchText = document.getElementById(`search-${datasetId}-${mode}`).value.toLowerCase();
            const typeFilter = document.getElementById(`type-${datasetId}-${mode}`).value;
            
            const questions = document.querySelectorAll(`#mode-${datasetId}-${mode} .question-item`);
            
            questions.forEach(q => {
                const text = q.textContent.toLowerCase();
                const types = q.dataset.types || '';
                
                const matchesSearch = !searchText || text.includes(searchText);
                const matchesType = !typeFilter || types.includes(typeFilter);
                
                q.style.display = (matchesSearch && matchesType) ? 'block' : 'none';
            });
        }
    </script>
    
        
        <script>
            // Auto-expand first dataset and show first mode
            document.addEventListener('DOMContentLoaded', function() {
                const firstDataset = document.querySelector('.dataset-section');
                if (firstDataset) {
                    const datasetId = firstDataset.querySelector('.dataset-content').id.replace('content-', '');
                    toggleDataset(datasetId);
                    
                    const firstTab = firstDataset.querySelector('.mode-tab');
                    if (firstTab) {
                        const mode = firstTab.dataset.mode;
                        switchMode(datasetId, mode);
                    }
                }
            });
        </script>
    </body>
    </html>
    